openapi: 3.0.0
info:
  version: 2016-06-27
  x-release: v4
  title: Amazon Rekognition
  description: This is the Amazon Rekognition API reference.
  x-logo:
    url: https://twitter.com/awscloud/profile_image?size=original
    backgroundColor: "#FFFFFF"
  termsOfService: https://aws.amazon.com/service-terms/
  contact:
    name: Mike Ralphson
    email: mike.ralphson@gmail.com
    url: https://github.com/mermade/aws2openapi
    x-twitter: PermittedSoc
  license:
    name: Apache 2.0 License
    url: http://www.apache.org/licenses/
  x-providerName: amazonaws.com
  x-serviceName: rekognition
  x-origin:
    - contentType: application/json
      url: https://raw.githubusercontent.com/aws/aws-sdk-js/master/apis/rekognition-2016-06-27.normal.json
      converter:
        url: https://github.com/mermade/aws2openapi
        version: 1.0.0
      x-apisguru-direct: true
  x-apiClientRegistration:
    url: https://portal.aws.amazon.com/gp/aws/developer/registration/index.html?nc2=h_ct
  x-apisguru-categories:
    - cloud
  x-preferred: true
externalDocs:
  description: Amazon Web Services documentation
  url: https://docs.aws.amazon.com/rekognition/
x-hasEquivalentPaths: true
security:
  - hmac: []
paths:
  /#X-Amz-Target=RekognitionService.CompareFaces:
    post:
      operationId: CompareFaces
      description: <p>Compares a face in the <i>source</i> input image with each of the 100
        largest faces detected in the <i>target</i> input image. </p> <note> <p>
        If the source image contains multiple faces, the service detects the
        largest face and compares it with each face detected in the target
        image. </p> </note> <p>You pass the input and target images either as
        base64-encoded image bytes or as references to images in an Amazon S3
        bucket. If you use the AWS CLI to call Amazon Rekognition operations,
        passing image bytes isn't supported. The image must be formatted as a
        PNG or JPEG file. </p> <p>In response, the operation returns an array of
        face matches ordered by similarity score in descending order. For each
        face match, the response provides a bounding box of the face, facial
        landmarks, pose details (pitch, role, and yaw), quality (brightness and
        sharpness), and confidence value (indicating the level of confidence
        that the bounding box contains a face). The response also provides a
        similarity score, which indicates how closely the faces match. </p>
        <note> <p>By default, only faces with a similarity score of greater than
        or equal to 80% are returned in the response. You can change this value
        by specifying the <code>SimilarityThreshold</code> parameter.</p>
        </note> <p> <code>CompareFaces</code> also returns an array of faces
        that don't match the source image. For each face, it returns a bounding
        box, confidence value, landmarks, pose details, and quality. The
        response also returns information about the face in the source image,
        including the bounding box of the face and confidence value.</p> <p>If
        the image doesn't contain Exif metadata, <code>CompareFaces</code>
        returns orientation information for the source and target images. Use
        these values to display the images with the correct image
        orientation.</p> <p>If no faces are detected in the source or target
        images, <code>CompareFaces</code> returns an
        <code>InvalidParameterException</code> error. </p> <note> <p> This is a
        stateless API operation. That is, data returned by this operation
        doesn't persist.</p> </note> <p>For an example, see Comparing Faces in
        Images in the Amazon Rekognition Developer Guide.</p> <p>This operation
        requires permissions to perform the
        <code>rekognition:CompareFaces</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CompareFacesResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.CompareFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CompareFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.CreateCollection:
    post:
      operationId: CreateCollection
      description: <p>Creates a collection in an AWS Region. You can add faces to the
        collection using the <a>IndexFaces</a> operation. </p> <p>For example,
        you might create collections, one for each of your application users. A
        user can then index faces using the <code>IndexFaces</code> operation
        and persist results in a specific collection. Then, a user can search
        the collection for faces in the user-specific container. </p> <p>When
        you create a collection, it is associated with the latest version of the
        face model version.</p> <note> <p>Collection names are
        case-sensitive.</p> </note> <p>This operation requires permissions to
        perform the <code>rekognition:CreateCollection</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateCollectionResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceAlreadyExistsException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceAlreadyExistsException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.CreateCollection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateCollectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.CreateStreamProcessor:
    post:
      operationId: CreateStreamProcessor
      description: <p>Creates an Amazon Rekognition stream processor that you can use to
        detect and recognize faces in a streaming video.</p> <p>Amazon
        Rekognition Video is a consumer of live video from Amazon Kinesis Video
        Streams. Amazon Rekognition Video sends analysis results to Amazon
        Kinesis Data Streams.</p> <p>You provide as input a Kinesis video stream
        (<code>Input</code>) and a Kinesis data stream (<code>Output</code>)
        stream. You also specify the face recognition criteria in
        <code>Settings</code>. For example, the collection containing faces that
        you want to recognize. Use <code>Name</code> to assign an identifier for
        the stream processor. You use <code>Name</code> to manage the stream
        processor. For example, you can start processing the source video by
        calling <a>StartStreamProcessor</a> with the <code>Name</code> field.
        </p> <p>After you have finished analyzing a streaming video, use
        <a>StopStreamProcessor</a> to stop processing. You can delete the stream
        processor by calling <a>DeleteStreamProcessor</a>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/CreateStreamProcessorResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "485":
          description: ResourceInUseException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceInUseException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.CreateStreamProcessor
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CreateStreamProcessorRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DeleteCollection:
    post:
      operationId: DeleteCollection
      description: <p>Deletes the specified collection. Note that this operation removes
        all faces in the collection. For an example, see
        <a>delete-collection-procedure</a>.</p> <p>This operation requires
        permissions to perform the <code>rekognition:DeleteCollection</code>
        action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteCollectionResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DeleteCollection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DeleteCollectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DeleteFaces:
    post:
      operationId: DeleteFaces
      description: <p>Deletes faces from a collection. You specify a collection ID and an
        array of face IDs to remove from the collection.</p> <p>This operation
        requires permissions to perform the <code>rekognition:DeleteFaces</code>
        action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteFacesResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DeleteFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DeleteFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DeleteStreamProcessor:
    post:
      operationId: DeleteStreamProcessor
      description: Deletes the stream processor identified by <code>Name</code>. You assign
        the value for <code>Name</code> when you create the stream processor
        with <a>CreateStreamProcessor</a>. You might not be able to use the same
        name for a stream processor for a few seconds after calling
        <code>DeleteStreamProcessor</code>.
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DeleteStreamProcessorResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "485":
          description: ResourceInUseException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceInUseException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DeleteStreamProcessor
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DeleteStreamProcessorRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DescribeCollection:
    post:
      operationId: DescribeCollection
      description: <p>Describes the specified collection. You can use
        <code>DescribeCollection</code> to get information, such as the number
        of faces indexed into a collection and the version of the model used by
        the collection for face detection.</p> <p>For more information, see
        Describing a Collection in the Amazon Rekognition Developer Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DescribeCollectionResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DescribeCollection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DescribeCollectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DescribeStreamProcessor:
    post:
      operationId: DescribeStreamProcessor
      description: Provides information about a stream processor created by
        <a>CreateStreamProcessor</a>. You can get information about the input
        and output streams, the input parameters for the face recognition being
        performed, and the current status of the stream processor.
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DescribeStreamProcessorResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "485":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DescribeStreamProcessor
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DescribeStreamProcessorRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DetectFaces:
    post:
      operationId: DetectFaces
      description: <p>Detects faces within an image that is provided as input.</p> <p>
        <code>DetectFaces</code> detects the 100 largest faces in the image. For
        each face detected, the operation returns face details. These details
        include a bounding box of the face, a confidence value (that the
        bounding box contains a face), and a fixed set of attributes such as
        facial landmarks (for example, coordinates of eye and mouth), gender,
        presence of beard, sunglasses, and so on. </p> <p>The face-detection
        algorithm is most effective on frontal faces. For non-frontal or
        obscured faces, the algorithm might not detect the faces or might detect
        faces with lower confidence. </p> <p>You pass the input image either as
        base64-encoded image bytes or as a reference to an image in an Amazon S3
        bucket. If you use the to call Amazon Rekognition operations, passing
        image bytes is not supported. The image must be either a PNG or JPEG
        formatted file. </p> <note> <p>This is a stateless API operation. That
        is, the operation does not persist any data.</p> </note> <p>This
        operation requires permissions to perform the
        <code>rekognition:DetectFaces</code> action. </p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DetectFacesResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DetectFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DetectFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DetectLabels:
    post:
      operationId: DetectLabels
      description: "<p>Detects instances of real-world entities within an image (JPEG or
        PNG) provided as input. This includes objects like flower, tree, and
        table; events like wedding, graduation, and birthday party; and concepts
        like landscape, evening, and nature. </p> <p>For an example, see
        Analyzing Images Stored in an Amazon S3 Bucket in the Amazon Rekognition
        Developer Guide.</p> <note> <p> <code>DetectLabels</code> does not
        support the detection of activities. However, activity detection is
        supported for label detection in videos. For more information, see
        StartLabelDetection in the Amazon Rekognition Developer Guide.</p>
        </note> <p>You pass the input image as base64-encoded image bytes or as
        a reference to an image in an Amazon S3 bucket. If you use the AWS CLI
        to call Amazon Rekognition operations, passing image bytes is not
        supported. The image must be either a PNG or JPEG formatted file. </p>
        <p> For each object, scene, and concept the API returns one or more
        labels. Each label provides the object name, and the level of confidence
        that the image contains the object. For example, suppose the input image
        has a lighthouse, the sea, and a rock. The response includes all three
        labels, one for each object. </p> <p> <code>{Name: lighthouse,
        Confidence: 98.4629}</code> </p> <p> <code>{Name: rock,Confidence:
        79.2097}</code> </p> <p> <code> {Name: sea,Confidence: 75.061}</code>
        </p> <p>In the preceding example, the operation returns one label for
        each of the three objects. The operation can also return multiple labels
        for the same object in the image. For example, if the input image shows
        a flower (for example, a tulip), the operation might return the
        following three labels. </p> <p> <code>{Name: flower,Confidence:
        99.0562}</code> </p> <p> <code>{Name: plant,Confidence: 99.0562}</code>
        </p> <p> <code>{Name: tulip,Confidence: 99.0562}</code> </p> <p>In this
        example, the detection algorithm more precisely identifies the flower as
        a tulip.</p> <p>In response, the API returns an array of labels. In
        addition, the response also includes the orientation correction.
        Optionally, you can specify <code>MinConfidence</code> to control the
        confidence threshold for the labels returned. The default is 55%. You
        can also add the <code>MaxLabels</code> parameter to limit the number of
        labels returned. </p> <note> <p>If the object detected is a person, the
        operation doesn't provide the same facial details that the
        <a>DetectFaces</a> operation provides.</p> </note> <p>
        <code>DetectLabels</code> returns bounding boxes for instances of common
        object labels in an array of <a>Instance</a> objects. An
        <code>Instance</code> object contains a <a>BoundingBox</a> object, for
        the location of the label on the image. It also includes the confidence
        by which the bounding box was detected.</p> <p>
        <code>DetectLabels</code> also returns a hierarchical taxonomy of
        detected labels. For example, a detected car might be assigned the label
        <i>car</i>. The label <i>car</i> has two parent labels: <i>Vehicle</i>
        (its parent) and <i>Transportation</i> (its grandparent). The response
        returns the entire list of ancestors for a label. Each ancestor is a
        unique label in the response. In the previous example, <i>Car</i>,
        <i>Vehicle</i>, and <i>Transportation</i> are returned as unique labels
        in the response. </p> <p>This is a stateless API operation. That is, the
        operation does not persist any data.</p> <p>This operation requires
        permissions to perform the <code>rekognition:DetectLabels</code> action.
        </p>"
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DetectLabelsResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DetectLabels
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DetectLabelsRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DetectModerationLabels:
    post:
      operationId: DetectModerationLabels
      description: <p>Detects unsafe content in a specified JPEG or PNG format image. Use
        <code>DetectModerationLabels</code> to moderate images depending on your
        requirements. For example, you might want to filter images that contain
        nudity, but not images containing suggestive content.</p> <p>To filter
        images, use the labels returned by <code>DetectModerationLabels</code>
        to determine which types of content are appropriate.</p> <p>For
        information about moderation labels, see Detecting Unsafe Content in the
        Amazon Rekognition Developer Guide.</p> <p>You pass the input image
        either as base64-encoded image bytes or as a reference to an image in an
        Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition
        operations, passing image bytes is not supported. The image must be
        either a PNG or JPEG formatted file. </p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DetectModerationLabelsResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DetectModerationLabels
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DetectModerationLabelsRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.DetectText:
    post:
      operationId: DetectText
      description: <p>Detects text in the input image and converts it into machine-readable
        text.</p> <p>Pass the input image as base64-encoded image bytes or as a
        reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
        call Amazon Rekognition operations, you must pass it as a reference to
        an image in an Amazon S3 bucket. For the AWS CLI, passing image bytes is
        not supported. The image must be either a .png or .jpeg formatted file.
        </p> <p>The <code>DetectText</code> operation returns text in an array
        of <a>TextDetection</a> elements, <code>TextDetections</code>. Each
        <code>TextDetection</code> element provides information about a single
        word or line of text that was detected in the image. </p> <p>A word is
        one or more ISO basic latin script characters that are not separated by
        spaces. <code>DetectText</code> can detect up to 50 words in an
        image.</p> <p>A line is a string of equally spaced words. A line isn't
        necessarily a complete sentence. For example, a driver's license number
        is detected as a line. A line ends when there is no aligned text after
        it. Also, a line ends when there is a large gap between words, relative
        to the length of the words. This means, depending on the gap between
        words, Amazon Rekognition may detect multiple lines in text aligned in
        the same direction. Periods don't represent the end of a line. If a
        sentence spans multiple lines, the <code>DetectText</code> operation
        returns multiple lines.</p> <p>To determine whether a
        <code>TextDetection</code> element is a line of text or a word, use the
        <code>TextDetection</code> object <code>Type</code> field. </p> <p>To be
        detected, text must be within +/- 90 degrees orientation of the
        horizontal axis.</p> <p>For more information, see DetectText in the
        Amazon Rekognition Developer Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/DetectTextResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.DetectText
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DetectTextRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetCelebrityInfo:
    post:
      operationId: GetCelebrityInfo
      description: <p>Gets the name and additional information about a celebrity based on
        his or her Amazon Rekognition ID. The additional information is returned
        as an array of URLs. If there is no additional information about the
        celebrity, this list is empty.</p> <p>For more information, see
        Recognizing Celebrities in an Image in the Amazon Rekognition Developer
        Guide.</p> <p>This operation requires permissions to perform the
        <code>rekognition:GetCelebrityInfo</code> action. </p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetCelebrityInfoResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetCelebrityInfo
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetCelebrityInfoRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetCelebrityRecognition:
    post:
      operationId: GetCelebrityRecognition
      description: <p>Gets the celebrity recognition results for a Amazon Rekognition Video
        analysis started by <a>StartCelebrityRecognition</a>.</p> <p>Celebrity
        recognition in a video is an asynchronous operation. Analysis is started
        by a call to <a>StartCelebrityRecognition</a> which returns a job
        identifier (<code>JobId</code>). When the celebrity recognition
        operation finishes, Amazon Rekognition Video publishes a completion
        status to the Amazon Simple Notification Service topic registered in the
        initial call to <code>StartCelebrityRecognition</code>. To get the
        results of the celebrity recognition analysis, first check that the
        status value published to the Amazon SNS topic is
        <code>SUCCEEDED</code>. If so, call <code>GetCelebrityDetection</code>
        and pass the job identifier (<code>JobId</code>) from the initial call
        to <code>StartCelebrityDetection</code>. </p> <p>For more information,
        see Working With Stored Videos in the Amazon Rekognition Developer
        Guide.</p> <p> <code>GetCelebrityRecognition</code> returns detected
        celebrities and the time(s) they are detected in an array
        (<code>Celebrities</code>) of <a>CelebrityRecognition</a> objects. Each
        <code>CelebrityRecognition</code> contains information about the
        celebrity in a <a>CelebrityDetail</a> object and the time,
        <code>Timestamp</code>, the celebrity was detected. </p> <note> <p>
        <code>GetCelebrityRecognition</code> only returns the default facial
        attributes (<code>BoundingBox</code>, <code>Confidence</code>,
        <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>).
        The other facial attributes listed in the <code>Face</code> object of
        the following response syntax are not returned. For more information,
        see FaceDetail in the Amazon Rekognition Developer Guide. </p> </note>
        <p>By default, the <code>Celebrities</code> array is sorted by time
        (milliseconds from the start of the video). You can also sort the array
        by celebrity by specifying the value <code>ID</code> in the
        <code>SortBy</code> input parameter.</p> <p>The
        <code>CelebrityDetail</code> object includes the celebrity identifer and
        additional information urls. If you don't store the additional
        information urls, you can get them later by calling
        <a>GetCelebrityInfo</a> with the celebrity identifer.</p> <p>No
        information is returned for faces not recognized as celebrities.</p>
        <p>Use MaxResults parameter to limit the number of labels returned. If
        there are more results than specified in <code>MaxResults</code>, the
        value of <code>NextToken</code> in the operation response contains a
        pagination token for getting the next set of results. To get the next
        page of results, call <code>GetCelebrityDetection</code> and populate
        the <code>NextToken</code> request parameter with the token value
        returned from the previous call to
        <code>GetCelebrityRecognition</code>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetCelebrityRecognitionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetCelebrityRecognition
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetCelebrityRecognitionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetContentModeration:
    post:
      operationId: GetContentModeration
      description: <p>Gets the unsafe content analysis results for a Amazon Rekognition
        Video analysis started by <a>StartContentModeration</a>.</p> <p>Unsafe
        content analysis of a video is an asynchronous operation. You start
        analysis by calling <a>StartContentModeration</a> which returns a job
        identifier (<code>JobId</code>). When analysis finishes, Amazon
        Rekognition Video publishes a completion status to the Amazon Simple
        Notification Service topic registered in the initial call to
        <code>StartContentModeration</code>. To get the results of the unsafe
        content analysis, first check that the status value published to the
        Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <code>GetContentModeration</code> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartContentModeration</code>. </p> <p>For more information, see
        Working with Stored Videos in the Amazon Rekognition Devlopers
        Guide.</p> <p> <code>GetContentModeration</code> returns detected unsafe
        content labels, and the time they are detected, in an array,
        <code>ModerationLabels</code>, of <a>ContentModerationDetection</a>
        objects. </p> <p>By default, the moderated labels are returned sorted by
        time, in milliseconds from the start of the video. You can also sort
        them by moderated label by specifying <code>NAME</code> for the
        <code>SortBy</code> input parameter. </p> <p>Since video analysis can
        return a large number of results, use the <code>MaxResults</code>
        parameter to limit the number of labels returned in a single call to
        <code>GetContentModeration</code>. If there are more results than
        specified in <code>MaxResults</code>, the value of
        <code>NextToken</code> in the operation response contains a pagination
        token for getting the next set of results. To get the next page of
        results, call <code>GetContentModeration</code> and populate the
        <code>NextToken</code> request parameter with the value of
        <code>NextToken</code> returned from the previous call to
        <code>GetContentModeration</code>.</p> <p>For more information, see
        Detecting Unsafe Content in the Amazon Rekognition Developer Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetContentModerationResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetContentModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetContentModerationRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetFaceDetection:
    post:
      operationId: GetFaceDetection
      description: <p>Gets face detection results for a Amazon Rekognition Video analysis
        started by <a>StartFaceDetection</a>.</p> <p>Face detection with Amazon
        Rekognition Video is an asynchronous operation. You start face detection
        by calling <a>StartFaceDetection</a> which returns a job identifier
        (<code>JobId</code>). When the face detection operation finishes, Amazon
        Rekognition Video publishes a completion status to the Amazon Simple
        Notification Service topic registered in the initial call to
        <code>StartFaceDetection</code>. To get the results of the face
        detection operation, first check that the status value published to the
        Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <a>GetFaceDetection</a> and pass the job identifier (<code>JobId</code>)
        from the initial call to <code>StartFaceDetection</code>.</p> <p>
        <code>GetFaceDetection</code> returns an array of detected faces
        (<code>Faces</code>) sorted by the time the faces were detected. </p>
        <p>Use MaxResults parameter to limit the number of labels returned. If
        there are more results than specified in <code>MaxResults</code>, the
        value of <code>NextToken</code> in the operation response contains a
        pagination token for getting the next set of results. To get the next
        page of results, call <code>GetFaceDetection</code> and populate the
        <code>NextToken</code> request parameter with the token value returned
        from the previous call to <code>GetFaceDetection</code>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetFaceDetectionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetFaceDetection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetFaceDetectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetFaceSearch:
    post:
      operationId: GetFaceSearch
      description: <p>Gets the face search results for Amazon Rekognition Video face search
        started by <a>StartFaceSearch</a>. The search returns faces in a
        collection that match the faces of persons detected in a video. It also
        includes the time(s) that faces are matched in the video.</p> <p>Face
        search in a video is an asynchronous operation. You start face search by
        calling to <a>StartFaceSearch</a> which returns a job identifier
        (<code>JobId</code>). When the search operation finishes, Amazon
        Rekognition Video publishes a completion status to the Amazon Simple
        Notification Service topic registered in the initial call to
        <code>StartFaceSearch</code>. To get the search results, first check
        that the status value published to the Amazon SNS topic is
        <code>SUCCEEDED</code>. If so, call <code>GetFaceSearch</code> and pass
        the job identifier (<code>JobId</code>) from the initial call to
        <code>StartFaceSearch</code>.</p> <p>For more information, see Searching
        Faces in a Collection in the Amazon Rekognition Developer Guide.</p>
        <p>The search results are retured in an array, <code>Persons</code>, of
        <a>PersonMatch</a> objects. Each<code>PersonMatch</code> element
        contains details about the matching faces in the input collection,
        person information (facial attributes, bounding boxes, and person
        identifer) for the matched person, and the time the person was matched
        in the video.</p> <note> <p> <code>GetFaceSearch</code> only returns the
        default facial attributes (<code>BoundingBox</code>,
        <code>Confidence</code>, <code>Landmarks</code>, <code>Pose</code>, and
        <code>Quality</code>). The other facial attributes listed in the
        <code>Face</code> object of the following response syntax are not
        returned. For more information, see FaceDetail in the Amazon Rekognition
        Developer Guide. </p> </note> <p>By default, the <code>Persons</code>
        array is sorted by the time, in milliseconds from the start of the
        video, persons are matched. You can also sort by persons by specifying
        <code>INDEX</code> for the <code>SORTBY</code> input parameter.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetFaceSearchResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetFaceSearch
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetFaceSearchRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetLabelDetection:
    post:
      operationId: GetLabelDetection
      description: <p>Gets the label detection results of a Amazon Rekognition Video
        analysis started by <a>StartLabelDetection</a>. </p> <p>The label
        detection operation is started by a call to <a>StartLabelDetection</a>
        which returns a job identifier (<code>JobId</code>). When the label
        detection operation finishes, Amazon Rekognition publishes a completion
        status to the Amazon Simple Notification Service topic registered in the
        initial call to <code>StartlabelDetection</code>. To get the results of
        the label detection operation, first check that the status value
        published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <a>GetLabelDetection</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartLabelDetection</code>.</p> <p> <code>GetLabelDetection</code>
        returns an array of detected labels (<code>Labels</code>) sorted by the
        time the labels were detected. You can also sort by the label name by
        specifying <code>NAME</code> for the <code>SortBy</code> input
        parameter.</p> <p>The labels returned include the label name, the
        percentage confidence in the accuracy of the detected label, and the
        time the label was detected in the video.</p> <p>The returned labels
        also include bounding box information for common objects, a hierarchical
        taxonomy of detected labels, and the version of the label model used for
        detection.</p> <p>Use MaxResults parameter to limit the number of labels
        returned. If there are more results than specified in
        <code>MaxResults</code>, the value of <code>NextToken</code> in the
        operation response contains a pagination token for getting the next set
        of results. To get the next page of results, call
        <code>GetlabelDetection</code> and populate the <code>NextToken</code>
        request parameter with the token value returned from the previous call
        to <code>GetLabelDetection</code>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetLabelDetectionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetLabelDetection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetLabelDetectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.GetPersonTracking:
    post:
      operationId: GetPersonTracking
      description: <p>Gets the path tracking results of a Amazon Rekognition Video analysis
        started by <a>StartPersonTracking</a>.</p> <p>The person path tracking
        operation is started by a call to <code>StartPersonTracking</code> which
        returns a job identifier (<code>JobId</code>). When the operation
        finishes, Amazon Rekognition Video publishes a completion status to the
        Amazon Simple Notification Service topic registered in the initial call
        to <code>StartPersonTracking</code>.</p> <p>To get the results of the
        person path tracking operation, first check that the status value
        published to the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <a>GetPersonTracking</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartPersonTracking</code>.</p> <p> <code>GetPersonTracking</code>
        returns an array, <code>Persons</code>, of tracked persons and the
        time(s) their paths were tracked in the video. </p> <note> <p>
        <code>GetPersonTracking</code> only returns the default facial
        attributes (<code>BoundingBox</code>, <code>Confidence</code>,
        <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>).
        The other facial attributes listed in the <code>Face</code> object of
        the following response syntax are not returned. </p> <p>For more
        information, see FaceDetail in the Amazon Rekognition Developer
        Guide.</p> </note> <p>By default, the array is sorted by the time(s) a
        person's path is tracked in the video. You can sort by tracked persons
        by specifying <code>INDEX</code> for the <code>SortBy</code> input
        parameter.</p> <p>Use the <code>MaxResults</code> parameter to limit the
        number of items returned. If there are more results than specified in
        <code>MaxResults</code>, the value of <code>NextToken</code> in the
        operation response contains a pagination token for getting the next set
        of results. To get the next page of results, call
        <code>GetPersonTracking</code> and populate the <code>NextToken</code>
        request parameter with the token value returned from the previous call
        to <code>GetPersonTracking</code>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/GetPersonTrackingResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.GetPersonTracking
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetPersonTrackingRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.IndexFaces:
    post:
      operationId: IndexFaces
      description: "<p>Detects faces in the input image and adds them to the specified
        collection. </p> <p>Amazon Rekognition doesn't save the actual faces
        that are detected. Instead, the underlying detection algorithm first
        detects the faces in the input image. For each face, the algorithm
        extracts facial features into a feature vector, and stores it in the
        backend database. Amazon Rekognition uses feature vectors when it
        performs face match and search operations using the <a>SearchFaces</a>
        and <a>SearchFacesByImage</a> operations.</p> <p>For more information,
        see Adding Faces to a Collection in the Amazon Rekognition Developer
        Guide.</p> <p>To get the number of faces in a collection, call
        <a>DescribeCollection</a>. </p> <p>If you're using version 1.0 of the
        face detection model, <code>IndexFaces</code> indexes the 15 largest
        faces in the input image. Later versions of the face detection model
        index the 100 largest faces in the input image. </p> <p>If you're using
        version 4 or later of the face model, image orientation information is
        not returned in the <code>OrientationCorrection</code> field. </p> <p>To
        determine which version of the model you're using, call
        <a>DescribeCollection</a> and supply the collection ID. You can also get
        the model version from the value of <code>FaceModelVersion</code> in the
        response from <code>IndexFaces</code> </p> <p>For more information, see
        Model Versioning in the Amazon Rekognition Developer Guide.</p> <p>If
        you provide the optional <code>ExternalImageID</code> for the input
        image you provided, Amazon Rekognition associates this ID with all faces
        that it detects. When you call the <a>ListFaces</a> operation, the
        response returns the external ID. You can use this external image ID to
        create a client-side index to associate the faces with each image. You
        can then use the index to find all faces in an image.</p> <p>You can
        specify the maximum number of faces to index with the
        <code>MaxFaces</code> input parameter. This is useful when you want to
        index the largest faces in an image and don't want to index smaller
        faces, such as those belonging to people standing in the background.</p>
        <p>The <code>QualityFilter</code> input parameter allows you to filter
        out detected faces that don’t meet the required quality bar chosen by
        Amazon Rekognition. The quality bar is based on a variety of common use
        cases. By default, <code>IndexFaces</code> filters detected faces. You
        can also explicitly filter detected faces by specifying
        <code>AUTO</code> for the value of <code>QualityFilter</code>. If you do
        not want to filter detected faces, specify <code>NONE</code>. </p>
        <note> <p>To use quality filtering, you need a collection associated
        with version 3 of the face model. To get the version of the face model
        associated with a collection, call <a>DescribeCollection</a>. </p>
        </note> <p>Information about faces detected in an image, but not
        indexed, is returned in an array of <a>UnindexedFace</a> objects,
        <code>UnindexedFaces</code>. Faces aren't indexed for reasons such
        as:</p> <ul> <li> <p>The number of faces detected exceeds the value of
        the <code>MaxFaces</code> request parameter.</p> </li> <li> <p>The face
        is too small compared to the image dimensions.</p> </li> <li> <p>The
        face is too blurry.</p> </li> <li> <p>The image is too dark.</p> </li>
        <li> <p>The face has an extreme pose.</p> </li> </ul> <p>In response,
        the <code>IndexFaces</code> operation returns an array of metadata for
        all detected faces, <code>FaceRecords</code>. This includes: </p> <ul>
        <li> <p>The bounding box, <code>BoundingBox</code>, of the detected
        face. </p> </li> <li> <p>A confidence value, <code>Confidence</code>,
        which indicates the confidence that the bounding box contains a
        face.</p> </li> <li> <p>A face ID, <code>FaceId</code>, assigned by the
        service for each face that's detected and stored.</p> </li> <li> <p>An
        image ID, <code>ImageId</code>, assigned by the service for the input
        image.</p> </li> </ul> <p>If you request all facial attributes (by using
        the <code>detectionAttributes</code> parameter), Amazon Rekognition
        returns detailed facial attributes, such as facial landmarks (for
        example, location of eye and mouth) and other facial attributes like
        gender. If you provide the same image, specify the same collection, and
        use the same external ID in the <code>IndexFaces</code> operation,
        Amazon Rekognition doesn't save duplicate face metadata.</p> <p/> <p>The
        input image is passed either as base64-encoded image bytes, or as a
        reference to an image in an Amazon S3 bucket. If you use the AWS CLI to
        call Amazon Rekognition operations, passing image bytes isn't supported.
        The image must be formatted as a PNG or JPEG file. </p> <p>This
        operation requires permissions to perform the
        <code>rekognition:IndexFaces</code> action.</p>"
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IndexFacesResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "488":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.IndexFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/IndexFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.ListCollections:
    post:
      operationId: ListCollections
      description: <p>Returns list of collection IDs in your account. If the result is
        truncated, the response also provides a <code>NextToken</code> that you
        can use in the subsequent request to fetch the next set of collection
        IDs.</p> <p>For an example, see Listing Collections in the Amazon
        Rekognition Developer Guide.</p> <p>This operation requires permissions
        to perform the <code>rekognition:ListCollections</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListCollectionsResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "486":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.ListCollections
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ListCollectionsRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.ListFaces:
    post:
      operationId: ListFaces
      description: <p>Returns metadata for faces in the specified collection. This metadata
        includes information such as the bounding box coordinates, the
        confidence (that the bounding box contains a face), and face ID. For an
        example, see Listing Faces in a Collection in the Amazon Rekognition
        Developer Guide.</p> <p>This operation requires permissions to perform
        the <code>rekognition:ListFaces</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListFacesResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "486":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.ListFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ListFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.ListStreamProcessors:
    post:
      operationId: ListStreamProcessors
      description: "Gets a list of stream processors that you have created with
        <a>CreateStreamProcessor</a>. "
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ListStreamProcessorsResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: InvalidPaginationTokenException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidPaginationTokenException"
        "485":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: MaxResults
          in: query
          description: Pagination limit
          required: false
          schema:
            type: string
        - name: NextToken
          in: query
          description: Pagination token
          required: false
          schema:
            type: string
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.ListStreamProcessors
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/ListStreamProcessorsRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.RecognizeCelebrities:
    post:
      operationId: RecognizeCelebrities
      description: <p>Returns an array of celebrities recognized in the input image. For
        more information, see Recognizing Celebrities in the Amazon Rekognition
        Developer Guide. </p> <p> <code>RecognizeCelebrities</code> returns the
        100 largest faces in the image. It lists recognized celebrities in the
        <code>CelebrityFaces</code> array and unrecognized faces in the
        <code>UnrecognizedFaces</code> array. <code>RecognizeCelebrities</code>
        doesn't return celebrities whose faces aren't among the largest 100
        faces in the image.</p> <p>For each celebrity recognized,
        <code>RecognizeCelebrities</code> returns a <code>Celebrity</code>
        object. The <code>Celebrity</code> object contains the celebrity name,
        ID, URL links to additional information, match confidence, and a
        <code>ComparedFace</code> object that you can use to locate the
        celebrity's face on the image.</p> <p>Amazon Rekognition doesn't retain
        information about which images a celebrity has been recognized in. Your
        application must store this information and use the
        <code>Celebrity</code> ID property as a unique identifier for the
        celebrity. If you don't store the celebrity name or additional
        information URLs returned by <code>RecognizeCelebrities</code>, you will
        need the ID to identify the celebrity in a call to the
        <a>GetCelebrityInfo</a> operation.</p> <p>You pass the input image
        either as base64-encoded image bytes or as a reference to an image in an
        Amazon S3 bucket. If you use the AWS CLI to call Amazon Rekognition
        operations, passing image bytes is not supported. The image must be
        either a PNG or JPEG formatted file. </p> <p>For an example, see
        Recognizing Celebrities in an Image in the Amazon Rekognition Developer
        Guide.</p> <p>This operation requires permissions to perform the
        <code>rekognition:RecognizeCelebrities</code> operation.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/RecognizeCelebritiesResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
        "483":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "484":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "485":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "486":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "487":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "488":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.RecognizeCelebrities
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/RecognizeCelebritiesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.SearchFaces:
    post:
      operationId: SearchFaces
      description: <p>For a given input face ID, searches for matching faces in the
        collection the face belongs to. You get a face ID when you add a face to
        the collection using the <a>IndexFaces</a> operation. The operation
        compares the features of the input face with faces in the specified
        collection. </p> <note> <p>You can also search faces without indexing
        faces by using the <code>SearchFacesByImage</code> operation.</p>
        </note> <p> The operation response returns an array of faces that match,
        ordered by similarity score with the highest similarity first. More
        specifically, it is an array of metadata for each face match that is
        found. Along with the metadata, the response also includes a
        <code>confidence</code> value for each face match, indicating the
        confidence that the specific face matches the input face. </p> <p>For an
        example, see Searching for a Face Using Its Face ID in the Amazon
        Rekognition Developer Guide.</p> <p>This operation requires permissions
        to perform the <code>rekognition:SearchFaces</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/SearchFacesResponse"
        "480":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "481":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "482":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "483":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "484":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "485":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.SearchFaces
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SearchFacesRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.SearchFacesByImage:
    post:
      operationId: SearchFacesByImage
      description: <p>For a given input image, first detects the largest face in the image,
        and then searches the specified collection for matching faces. The
        operation compares the features of the input face with faces in the
        specified collection. </p> <note> <p>To search for all faces in an input
        image, you might first call the <a>IndexFaces</a> operation, and then
        use the face IDs returned in subsequent calls to the <a>SearchFaces</a>
        operation. </p> <p> You can also call the <code>DetectFaces</code>
        operation and use the bounding boxes in the response to make face crops,
        which then you can pass in to the <code>SearchFacesByImage</code>
        operation. </p> </note> <p>You pass the input image either as
        base64-encoded image bytes or as a reference to an image in an Amazon S3
        bucket. If you use the AWS CLI to call Amazon Rekognition operations,
        passing image bytes is not supported. The image must be either a PNG or
        JPEG formatted file. </p> <p> The response returns an array of faces
        that match, ordered by similarity score with the highest similarity
        first. More specifically, it is an array of metadata for each face match
        found. Along with the metadata, the response also includes a
        <code>similarity</code> indicating how similar the face is to the input
        face. In the response, the operation also returns the bounding box (and
        a confidence level that the bounding box contains a face) of the face
        that Amazon Rekognition used for the input image. </p> <p>For an
        example, Searching for a Face Using an Image in the Amazon Rekognition
        Developer Guide.</p> <p>This operation requires permissions to perform
        the <code>rekognition:SearchFacesByImage</code> action.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/SearchFacesByImageResponse"
        "480":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "481":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "482":
          description: ImageTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ImageTooLargeException"
        "483":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "488":
          description: InvalidImageFormatException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidImageFormatException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.SearchFacesByImage
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SearchFacesByImageRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartCelebrityRecognition:
    post:
      operationId: StartCelebrityRecognition
      description: <p>Starts asynchronous recognition of celebrities in a stored video.</p>
        <p>Amazon Rekognition Video can detect celebrities in a video must be
        stored in an Amazon S3 bucket. Use <a>Video</a> to specify the bucket
        name and the filename of the video.
        <code>StartCelebrityRecognition</code> returns a job identifier
        (<code>JobId</code>) which you use to get the results of the analysis.
        When celebrity recognition analysis is finished, Amazon Rekognition
        Video publishes a completion status to the Amazon Simple Notification
        Service topic that you specify in <code>NotificationChannel</code>. To
        get the results of the celebrity recognition analysis, first check that
        the status value published to the Amazon SNS topic is
        <code>SUCCEEDED</code>. If so, call <a>GetCelebrityRecognition</a> and
        pass the job identifier (<code>JobId</code>) from the initial call to
        <code>StartCelebrityRecognition</code>. </p> <p>For more information,
        see Recognizing Celebrities in the Amazon Rekognition Developer
        Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartCelebrityRecognitionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartCelebrityRecognition
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartCelebrityRecognitionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartContentModeration:
    post:
      operationId: StartContentModeration
      description: <p> Starts asynchronous detection of unsafe content in a stored
        video.</p> <p>Amazon Rekognition Video can moderate content in a video
        stored in an Amazon S3 bucket. Use <a>Video</a> to specify the bucket
        name and the filename of the video. <code>StartContentModeration</code>
        returns a job identifier (<code>JobId</code>) which you use to get the
        results of the analysis. When unsafe content analysis is finished,
        Amazon Rekognition Video publishes a completion status to the Amazon
        Simple Notification Service topic that you specify in
        <code>NotificationChannel</code>.</p> <p>To get the results of the
        unsafe content analysis, first check that the status value published to
        the Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <a>GetContentModeration</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartContentModeration</code>. </p> <p>For more information, see
        Detecting Unsafe Content in the Amazon Rekognition Developer Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartContentModerationResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartContentModeration
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartContentModerationRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartFaceDetection:
    post:
      operationId: StartFaceDetection
      description: <p>Starts asynchronous detection of faces in a stored video.</p>
        <p>Amazon Rekognition Video can detect faces in a video stored in an
        Amazon S3 bucket. Use <a>Video</a> to specify the bucket name and the
        filename of the video. <code>StartFaceDetection</code> returns a job
        identifier (<code>JobId</code>) that you use to get the results of the
        operation. When face detection is finished, Amazon Rekognition Video
        publishes a completion status to the Amazon Simple Notification Service
        topic that you specify in <code>NotificationChannel</code>. To get the
        results of the face detection operation, first check that the status
        value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If
        so, call <a>GetFaceDetection</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartFaceDetection</code>.</p> <p>For more information, see
        Detecting Faces in a Stored Video in the Amazon Rekognition Developer
        Guide.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartFaceDetectionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartFaceDetection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartFaceDetectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartFaceSearch:
    post:
      operationId: StartFaceSearch
      description: <p>Starts the asynchronous search for faces in a collection that match
        the faces of persons detected in a stored video.</p> <p>The video must
        be stored in an Amazon S3 bucket. Use <a>Video</a> to specify the bucket
        name and the filename of the video. <code>StartFaceSearch</code> returns
        a job identifier (<code>JobId</code>) which you use to get the search
        results once the search has completed. When searching is finished,
        Amazon Rekognition Video publishes a completion status to the Amazon
        Simple Notification Service topic that you specify in
        <code>NotificationChannel</code>. To get the search results, first check
        that the status value published to the Amazon SNS topic is
        <code>SUCCEEDED</code>. If so, call <a>GetFaceSearch</a> and pass the
        job identifier (<code>JobId</code>) from the initial call to
        <code>StartFaceSearch</code>. For more information, see
        <a>procedure-person-search-videos</a>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartFaceSearchResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "489":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartFaceSearch
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartFaceSearchRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartLabelDetection:
    post:
      operationId: StartLabelDetection
      description: <p>Starts asynchronous detection of labels in a stored video.</p>
        <p>Amazon Rekognition Video can detect labels in a video. Labels are
        instances of real-world entities. This includes objects like flower,
        tree, and table; events like wedding, graduation, and birthday party;
        concepts like landscape, evening, and nature; and activities like a
        person getting out of a car or a person skiing.</p> <p>The video must be
        stored in an Amazon S3 bucket. Use <a>Video</a> to specify the bucket
        name and the filename of the video. <code>StartLabelDetection</code>
        returns a job identifier (<code>JobId</code>) which you use to get the
        results of the operation. When label detection is finished, Amazon
        Rekognition Video publishes a completion status to the Amazon Simple
        Notification Service topic that you specify in
        <code>NotificationChannel</code>.</p> <p>To get the results of the label
        detection operation, first check that the status value published to the
        Amazon SNS topic is <code>SUCCEEDED</code>. If so, call
        <a>GetLabelDetection</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartLabelDetection</code>.</p> <p/>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartLabelDetectionResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartLabelDetection
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartLabelDetectionRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartPersonTracking:
    post:
      operationId: StartPersonTracking
      description: <p>Starts the asynchronous tracking of a person's path in a stored
        video.</p> <p>Amazon Rekognition Video can track the path of people in a
        video stored in an Amazon S3 bucket. Use <a>Video</a> to specify the
        bucket name and the filename of the video.
        <code>StartPersonTracking</code> returns a job identifier
        (<code>JobId</code>) which you use to get the results of the operation.
        When label detection is finished, Amazon Rekognition publishes a
        completion status to the Amazon Simple Notification Service topic that
        you specify in <code>NotificationChannel</code>. </p> <p>To get the
        results of the person detection operation, first check that the status
        value published to the Amazon SNS topic is <code>SUCCEEDED</code>. If
        so, call <a>GetPersonTracking</a> and pass the job identifier
        (<code>JobId</code>) from the initial call to
        <code>StartPersonTracking</code>.</p>
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartPersonTrackingResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: IdempotentParameterMismatchException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/IdempotentParameterMismatchException"
        "482":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "483":
          description: InvalidS3ObjectException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidS3ObjectException"
        "484":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "485":
          description: VideoTooLargeException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/VideoTooLargeException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
        "487":
          description: LimitExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/LimitExceededException"
        "488":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartPersonTracking
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartPersonTrackingRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StartStreamProcessor:
    post:
      operationId: StartStreamProcessor
      description: Starts processing a stream processor. You create a stream processor by
        calling <a>CreateStreamProcessor</a>. To tell
        <code>StartStreamProcessor</code> which stream processor to start, use
        the value of the <code>Name</code> field specified in the call to
        <code>CreateStreamProcessor</code>.
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StartStreamProcessorResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "485":
          description: ResourceInUseException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceInUseException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StartStreamProcessor
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StartStreamProcessorRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
  /#X-Amz-Target=RekognitionService.StopStreamProcessor:
    post:
      operationId: StopStreamProcessor
      description: Stops a running stream processor that was created by
        <a>CreateStreamProcessor</a>.
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/StopStreamProcessorResponse"
        "480":
          description: AccessDeniedException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/AccessDeniedException"
        "481":
          description: InternalServerError
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InternalServerError"
        "482":
          description: ThrottlingException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ThrottlingException"
        "483":
          description: InvalidParameterException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/InvalidParameterException"
        "484":
          description: ResourceNotFoundException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceNotFoundException"
        "485":
          description: ResourceInUseException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ResourceInUseException"
        "486":
          description: ProvisionedThroughputExceededException
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/ProvisionedThroughputExceededException"
      parameters:
        - name: X-Amz-Target
          in: header
          required: true
          schema:
            type: string
            enum:
              - RekognitionService.StopStreamProcessor
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/StopStreamProcessorRequest"
        required: true
    parameters:
      - $ref: "#/components/parameters/X-Amz-Content-Sha256"
      - $ref: "#/components/parameters/X-Amz-Date"
      - $ref: "#/components/parameters/X-Amz-Algorithm"
      - $ref: "#/components/parameters/X-Amz-Credential"
      - $ref: "#/components/parameters/X-Amz-Security-Token"
      - $ref: "#/components/parameters/X-Amz-Signature"
      - $ref: "#/components/parameters/X-Amz-SignedHeaders"
servers:
  - url: http://rekognition.{region}.amazonaws.com
    variables:
      region:
        description: The AWS region
        enum:
          - us-east-1
          - us-east-2
          - us-west-1
          - us-west-2
          - us-gov-west-1
          - us-gov-east-1
          - ca-central-1
          - eu-north-1
          - eu-west-1
          - eu-west-2
          - eu-west-3
          - eu-central-1
          - ap-northeast-1
          - ap-northeast-2
          - ap-northeast-3
          - ap-southeast-1
          - ap-southeast-2
          - ap-south-1
          - sa-east-1
        default: us-east-1
    description: The Amazon Rekognition multi-region endpoint
  - url: https://rekognition.{region}.amazonaws.com
    variables:
      region:
        description: The AWS region
        enum:
          - us-east-1
          - us-east-2
          - us-west-1
          - us-west-2
          - us-gov-west-1
          - us-gov-east-1
          - ca-central-1
          - eu-north-1
          - eu-west-1
          - eu-west-2
          - eu-west-3
          - eu-central-1
          - ap-northeast-1
          - ap-northeast-2
          - ap-northeast-3
          - ap-southeast-1
          - ap-southeast-2
          - ap-south-1
          - sa-east-1
        default: us-east-1
    description: The Amazon Rekognition multi-region endpoint
  - url: http://rekognition.{region}.amazonaws.com.cn
    variables:
      region:
        description: The AWS region
        enum:
          - cn-north-1
          - cn-northwest-1
        default: cn-north-1
    description: The Amazon Rekognition endpoint for China (Beijing) and China (Ningxia)
  - url: https://rekognition.{region}.amazonaws.com.cn
    variables:
      region:
        description: The AWS region
        enum:
          - cn-north-1
          - cn-northwest-1
        default: cn-north-1
    description: The Amazon Rekognition endpoint for China (Beijing) and China (Ningxia)
components:
  parameters:
    X-Amz-Content-Sha256:
      name: X-Amz-Content-Sha256
      in: header
      required: false
      schema:
        type: string
    X-Amz-Date:
      name: X-Amz-Date
      in: header
      required: false
      schema:
        type: string
    X-Amz-Algorithm:
      name: X-Amz-Algorithm
      in: header
      required: false
      schema:
        type: string
    X-Amz-Credential:
      name: X-Amz-Credential
      in: header
      required: false
      schema:
        type: string
    X-Amz-Security-Token:
      name: X-Amz-Security-Token
      in: header
      required: false
      schema:
        type: string
    X-Amz-Signature:
      name: X-Amz-Signature
      in: header
      required: false
      schema:
        type: string
    X-Amz-SignedHeaders:
      name: X-Amz-SignedHeaders
      in: header
      required: false
      schema:
        type: string
  securitySchemes:
    hmac:
      type: apiKey
      name: Authorization
      in: header
      description: Amazon Signature authorization v4
      x-amazon-apigateway-authtype: awsSigv4
  schemas:
    CompareFacesResponse:
      type: object
      example:
        FaceMatches:
          - Face:
              BoundingBox:
                Height: 0.33481481671333313
                Left: 0.31888890266418457
                Top: 0.4933333396911621
                Width: 0.25
              Confidence: 99.9991226196289
            Similarity: 100
        SourceImageFace:
          BoundingBox:
            Height: 0.33481481671333313
            Left: 0.31888890266418457
            Top: 0.4933333396911621
            Width: 0.25
          Confidence: 99.9991226196289
      properties:
        SourceImageFace:
          $ref: "#/components/schemas/ComparedSourceImageFace"
        FaceMatches:
          $ref: "#/components/schemas/CompareFacesMatchList"
        UnmatchedFaces:
          $ref: "#/components/schemas/CompareFacesUnmatchList"
        SourceImageOrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
        TargetImageOrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
    CompareFacesRequest:
      type: object
      required:
        - SourceImage
        - TargetImage
      properties:
        SourceImage:
          $ref: "#/components/schemas/Image"
        TargetImage:
          $ref: "#/components/schemas/Image"
        SimilarityThreshold:
          $ref: "#/components/schemas/Percent"
    InvalidParameterException: {}
    InvalidS3ObjectException: {}
    ImageTooLargeException: {}
    AccessDeniedException: {}
    InternalServerError: {}
    ThrottlingException: {}
    ProvisionedThroughputExceededException: {}
    InvalidImageFormatException: {}
    CreateCollectionResponse:
      type: object
      example:
        CollectionArn: aws:rekognition:us-west-2:123456789012:collection/myphotos
        StatusCode: 200
      properties:
        StatusCode:
          $ref: "#/components/schemas/UInteger"
        CollectionArn:
          $ref: "#/components/schemas/String"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
    CreateCollectionRequest:
      type: object
      required:
        - CollectionId
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
    ResourceAlreadyExistsException: {}
    CreateStreamProcessorResponse:
      type: object
      properties:
        StreamProcessorArn:
          $ref: "#/components/schemas/StreamProcessorArn"
    CreateStreamProcessorRequest:
      type: object
      required:
        - Input
        - Output
        - Name
        - Settings
        - RoleArn
      properties:
        Input:
          $ref: "#/components/schemas/StreamProcessorInput"
        Output:
          $ref: "#/components/schemas/StreamProcessorOutput"
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
        Settings:
          $ref: "#/components/schemas/StreamProcessorSettings"
        RoleArn:
          $ref: "#/components/schemas/RoleArn"
    LimitExceededException: {}
    ResourceInUseException: {}
    DeleteCollectionResponse:
      type: object
      example:
        StatusCode: 200
      properties:
        StatusCode:
          $ref: "#/components/schemas/UInteger"
    DeleteCollectionRequest:
      type: object
      required:
        - CollectionId
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
    ResourceNotFoundException: {}
    DeleteFacesResponse:
      type: object
      example:
        DeletedFaces:
          - ff43d742-0c13-5d16-a3e8-03d3f58e980b
      properties:
        DeletedFaces:
          $ref: "#/components/schemas/FaceIdList"
    DeleteFacesRequest:
      type: object
      required:
        - CollectionId
        - FaceIds
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        FaceIds:
          $ref: "#/components/schemas/FaceIdList"
    DeleteStreamProcessorResponse:
      type: object
      properties: {}
    DeleteStreamProcessorRequest:
      type: object
      required:
        - Name
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
    DescribeCollectionResponse:
      type: object
      properties:
        FaceCount:
          $ref: "#/components/schemas/ULong"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
        CollectionARN:
          $ref: "#/components/schemas/String"
        CreationTimestamp:
          $ref: "#/components/schemas/DateTime"
    DescribeCollectionRequest:
      type: object
      required:
        - CollectionId
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
    DescribeStreamProcessorResponse:
      type: object
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
        StreamProcessorArn:
          $ref: "#/components/schemas/StreamProcessorArn"
        Status:
          $ref: "#/components/schemas/StreamProcessorStatus"
        StatusMessage:
          $ref: "#/components/schemas/String"
        CreationTimestamp:
          $ref: "#/components/schemas/DateTime"
        LastUpdateTimestamp:
          $ref: "#/components/schemas/DateTime"
        Input:
          $ref: "#/components/schemas/StreamProcessorInput"
        Output:
          $ref: "#/components/schemas/StreamProcessorOutput"
        RoleArn:
          $ref: "#/components/schemas/RoleArn"
        Settings:
          $ref: "#/components/schemas/StreamProcessorSettings"
    DescribeStreamProcessorRequest:
      type: object
      required:
        - Name
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
    DetectFacesResponse:
      type: object
      example:
        FaceDetails:
          - BoundingBox:
              Height: 0.18000000715255737
              Left: 0.5555555820465088
              Top: 0.33666667342185974
              Width: 0.23999999463558197
            Confidence: 100
            Landmarks:
              - Type: eyeLeft
                X: 0.6394737362861633
                Y: 0.40819624066352844
              - Type: eyeRight
                X: 0.7266660928726196
                Y: 0.41039225459098816
              - Type: eyeRight
                X: 0.6912462115287781
                Y: 0.44240960478782654
              - Type: mouthDown
                X: 0.6306198239326477
                Y: 0.46700039505958557
              - Type: mouthUp
                X: 0.7215608954429626
                Y: 0.47114261984825134
            Pose:
              Pitch: 4.050806522369385
              Roll: 0.9950747489929199
              Yaw: 13.693790435791016
            Quality:
              Brightness: 37.60169982910156
              Sharpness: 80
        OrientationCorrection: ROTATE_0
      properties:
        FaceDetails:
          $ref: "#/components/schemas/FaceDetailList"
        OrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
    DetectFacesRequest:
      type: object
      required:
        - Image
      properties:
        Image:
          $ref: "#/components/schemas/Image"
        Attributes:
          $ref: "#/components/schemas/Attributes"
    DetectLabelsResponse:
      type: object
      example:
        Labels:
          - Confidence: 99.25072479248047
            Name: People
          - Confidence: 99.25074005126953
            Name: Person
      properties:
        Labels:
          $ref: "#/components/schemas/Labels"
        OrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
        LabelModelVersion:
          $ref: "#/components/schemas/String"
    DetectLabelsRequest:
      type: object
      required:
        - Image
      properties:
        Image:
          $ref: "#/components/schemas/Image"
        MaxLabels:
          $ref: "#/components/schemas/UInteger"
        MinConfidence:
          $ref: "#/components/schemas/Percent"
    DetectModerationLabelsResponse:
      type: object
      properties:
        ModerationLabels:
          $ref: "#/components/schemas/ModerationLabels"
        ModerationModelVersion:
          $ref: "#/components/schemas/String"
    DetectModerationLabelsRequest:
      type: object
      required:
        - Image
      properties:
        Image:
          $ref: "#/components/schemas/Image"
        MinConfidence:
          $ref: "#/components/schemas/Percent"
    DetectTextResponse:
      type: object
      properties:
        TextDetections:
          $ref: "#/components/schemas/TextDetectionList"
    DetectTextRequest:
      type: object
      required:
        - Image
      properties:
        Image:
          $ref: "#/components/schemas/Image"
    GetCelebrityInfoResponse:
      type: object
      properties:
        Urls:
          $ref: "#/components/schemas/Urls"
        Name:
          $ref: "#/components/schemas/String"
    GetCelebrityInfoRequest:
      type: object
      required:
        - Id
      properties:
        Id:
          $ref: "#/components/schemas/RekognitionUniqueId"
    GetCelebrityRecognitionResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        Celebrities:
          $ref: "#/components/schemas/CelebrityRecognitions"
    GetCelebrityRecognitionRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        SortBy:
          $ref: "#/components/schemas/CelebrityRecognitionSortBy"
    InvalidPaginationTokenException: {}
    GetContentModerationResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        ModerationLabels:
          $ref: "#/components/schemas/ContentModerationDetections"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        ModerationModelVersion:
          $ref: "#/components/schemas/String"
    GetContentModerationRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        SortBy:
          $ref: "#/components/schemas/ContentModerationSortBy"
    GetFaceDetectionResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        Faces:
          $ref: "#/components/schemas/FaceDetections"
    GetFaceDetectionRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
    GetFaceSearchResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        Persons:
          $ref: "#/components/schemas/PersonMatches"
    GetFaceSearchRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        SortBy:
          $ref: "#/components/schemas/FaceSearchSortBy"
    GetLabelDetectionResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        Labels:
          $ref: "#/components/schemas/LabelDetections"
        LabelModelVersion:
          $ref: "#/components/schemas/String"
    GetLabelDetectionRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        SortBy:
          $ref: "#/components/schemas/LabelDetectionSortBy"
    GetPersonTrackingResponse:
      type: object
      properties:
        JobStatus:
          $ref: "#/components/schemas/VideoJobStatus"
        StatusMessage:
          $ref: "#/components/schemas/StatusMessage"
        VideoMetadata:
          $ref: "#/components/schemas/VideoMetadata"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        Persons:
          $ref: "#/components/schemas/PersonDetections"
    GetPersonTrackingRequest:
      type: object
      required:
        - JobId
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        SortBy:
          $ref: "#/components/schemas/PersonTrackingSortBy"
    IndexFacesResponse:
      type: object
      example:
        FaceRecords:
          - Face:
              BoundingBox:
                Height: 0.33481481671333313
                Left: 0.31888890266418457
                Top: 0.4933333396911621
                Width: 0.25
              Confidence: 99.9991226196289
              FaceId: ff43d742-0c13-5d16-a3e8-03d3f58e980b
              ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
            FaceDetail:
              BoundingBox:
                Height: 0.33481481671333313
                Left: 0.31888890266418457
                Top: 0.4933333396911621
                Width: 0.25
              Confidence: 99.9991226196289
              Landmarks:
                - Type: eyeLeft
                  X: 0.3976764678955078
                  Y: 0.6248345971107483
                - Type: eyeRight
                  X: 0.4810936450958252
                  Y: 0.6317117214202881
                - Type: noseLeft
                  X: 0.41986238956451416
                  Y: 0.7111940383911133
                - Type: mouthDown
                  X: 0.40525302290916443
                  Y: 0.7497701048851013
                - Type: mouthUp
                  X: 0.4753248989582062
                  Y: 0.7558549642562866
              Pose:
                Pitch: -9.713645935058594
                Roll: 4.707281112670898
                Yaw: -24.438663482666016
              Quality:
                Brightness: 29.23358917236328
                Sharpness: 80
          - Face:
              BoundingBox:
                Height: 0.32592591643333435
                Left: 0.5144444704055786
                Top: 0.15111111104488373
                Width: 0.24444444477558136
              Confidence: 99.99950408935547
              FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
              ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
            FaceDetail:
              BoundingBox:
                Height: 0.32592591643333435
                Left: 0.5144444704055786
                Top: 0.15111111104488373
                Width: 0.24444444477558136
              Confidence: 99.99950408935547
              Landmarks:
                - Type: eyeLeft
                  X: 0.6006892323493958
                  Y: 0.290842205286026
                - Type: eyeRight
                  X: 0.6808141469955444
                  Y: 0.29609042406082153
                - Type: noseLeft
                  X: 0.6395332217216492
                  Y: 0.3522595763206482
                - Type: mouthDown
                  X: 0.5892083048820496
                  Y: 0.38689887523651123
                - Type: mouthUp
                  X: 0.674560010433197
                  Y: 0.394125759601593
              Pose:
                Pitch: -4.683138370513916
                Roll: 2.1029529571533203
                Yaw: 6.716655254364014
              Quality:
                Brightness: 34.951698303222656
                Sharpness: 160
        OrientationCorrection: ROTATE_0
      properties:
        FaceRecords:
          $ref: "#/components/schemas/FaceRecordList"
        OrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
        UnindexedFaces:
          $ref: "#/components/schemas/UnindexedFaces"
    IndexFacesRequest:
      type: object
      required:
        - CollectionId
        - Image
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        Image:
          $ref: "#/components/schemas/Image"
        ExternalImageId:
          $ref: "#/components/schemas/ExternalImageId"
        DetectionAttributes:
          $ref: "#/components/schemas/Attributes"
        MaxFaces:
          $ref: "#/components/schemas/MaxFacesToIndex"
        QualityFilter:
          $ref: "#/components/schemas/QualityFilter"
    ListCollectionsResponse:
      type: object
      example:
        CollectionIds:
          - myphotos
      properties:
        CollectionIds:
          $ref: "#/components/schemas/CollectionIdList"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        FaceModelVersions:
          $ref: "#/components/schemas/FaceModelVersionList"
    ListCollectionsRequest:
      type: object
      properties:
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        MaxResults:
          $ref: "#/components/schemas/PageSize"
    ListFacesResponse:
      type: object
      example:
        Faces:
          - BoundingBox:
              Height: 0.18000000715255737
              Left: 0.5555559992790222
              Top: 0.336667001247406
              Width: 0.23999999463558197
            Confidence: 100
            FaceId: 1c62e8b5-69a7-5b7d-b3cd-db4338a8a7e7
            ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
          - BoundingBox:
              Height: 0.16555599868297577
              Left: 0.30963000655174255
              Top: 0.7066670060157776
              Width: 0.22074100375175476
            Confidence: 100
            FaceId: 29a75abe-397b-5101-ba4f-706783b2246c
            ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
          - BoundingBox:
              Height: 0.3234420120716095
              Left: 0.3233329951763153
              Top: 0.5
              Width: 0.24222199618816376
            Confidence: 99.99829864501953
            FaceId: 38271d79-7bc2-5efb-b752-398a8d575b85
            ImageId: d5631190-d039-54e4-b267-abd22c8647c5
          - BoundingBox:
              Height: 0.03555560111999512
              Left: 0.37388700246810913
              Top: 0.2477779984474182
              Width: 0.04747769981622696
            Confidence: 99.99210357666016
            FaceId: 3b01bef0-c883-5654-ba42-d5ad28b720b3
            ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
          - BoundingBox:
              Height: 0.05333330109715462
              Left: 0.2937690019607544
              Top: 0.35666701197624207
              Width: 0.07121659815311432
            Confidence: 99.99919891357422
            FaceId: 4839a608-49d0-566c-8301-509d71b534d1
            ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
          - BoundingBox:
              Height: 0.3249259889125824
              Left: 0.5155559778213501
              Top: 0.1513350009918213
              Width: 0.24333299696445465
            Confidence: 99.99949645996094
            FaceId: 70008e50-75e4-55d0-8e80-363fb73b3a14
            ImageId: d5631190-d039-54e4-b267-abd22c8647c5
          - BoundingBox:
              Height: 0.03777780011296272
              Left: 0.7002969980239868
              Top: 0.18777799606323242
              Width: 0.05044509842991829
            Confidence: 99.92639923095703
            FaceId: 7f5f88ed-d684-5a88-b0df-01e4a521552b
            ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
          - BoundingBox:
              Height: 0.05555560067296028
              Left: 0.13946600258350372
              Top: 0.46333301067352295
              Width: 0.07270029932260513
            Confidence: 99.99469757080078
            FaceId: 895b4e2c-81de-5902-a4bd-d1792bda00b2
            ImageId: 812d9f04-86f9-54fc-9275-8d0dcbcb6784
          - BoundingBox:
              Height: 0.3259260058403015
              Left: 0.5144439935684204
              Top: 0.15111100673675537
              Width: 0.24444399774074554
            Confidence: 99.99949645996094
            FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
            ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
          - BoundingBox:
              Height: 0.18888899683952332
              Left: 0.3783380091190338
              Top: 0.2355560064315796
              Width: 0.25222599506378174
            Confidence: 99.9999008178711
            FaceId: 908544ad-edc3-59df-8faf-6a87cc256cf5
            ImageId: 3c731605-d772-541a-a5e7-0375dbc68a07
          - BoundingBox:
              Height: 0.33481499552726746
              Left: 0.31888899207115173
              Top: 0.49333301186561584
              Width: 0.25
            Confidence: 99.99909973144531
            FaceId: ff43d742-0c13-5d16-a3e8-03d3f58e980b
            ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
      properties:
        Faces:
          $ref: "#/components/schemas/FaceList"
        NextToken:
          $ref: "#/components/schemas/String"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
    ListFacesRequest:
      type: object
      required:
        - CollectionId
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        MaxResults:
          $ref: "#/components/schemas/PageSize"
    ListStreamProcessorsResponse:
      type: object
      properties:
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        StreamProcessors:
          $ref: "#/components/schemas/StreamProcessorList"
    ListStreamProcessorsRequest:
      type: object
      properties:
        NextToken:
          $ref: "#/components/schemas/PaginationToken"
        MaxResults:
          $ref: "#/components/schemas/MaxResults"
    RecognizeCelebritiesResponse:
      type: object
      properties:
        CelebrityFaces:
          $ref: "#/components/schemas/CelebrityList"
        UnrecognizedFaces:
          $ref: "#/components/schemas/ComparedFaceList"
        OrientationCorrection:
          $ref: "#/components/schemas/OrientationCorrection"
    RecognizeCelebritiesRequest:
      type: object
      required:
        - Image
      properties:
        Image:
          $ref: "#/components/schemas/Image"
    SearchFacesResponse:
      type: object
      example:
        FaceMatches:
          - Face:
              BoundingBox:
                Height: 0.3259260058403015
                Left: 0.5144439935684204
                Top: 0.15111100673675537
                Width: 0.24444399774074554
              Confidence: 99.99949645996094
              FaceId: 8be04dba-4e58-520d-850e-9eae4af70eb2
              ImageId: 465f4e93-763e-51d0-b030-b9667a2d94b1
            Similarity: 99.97222137451172
          - Face:
              BoundingBox:
                Height: 0.16555599868297577
                Left: 0.30963000655174255
                Top: 0.7066670060157776
                Width: 0.22074100375175476
              Confidence: 100
              FaceId: 29a75abe-397b-5101-ba4f-706783b2246c
              ImageId: 147fdf82-7a71-52cf-819b-e786c7b9746e
            Similarity: 97.04154968261719
          - Face:
              BoundingBox:
                Height: 0.18888899683952332
                Left: 0.3783380091190338
                Top: 0.2355560064315796
                Width: 0.25222599506378174
              Confidence: 99.9999008178711
              FaceId: 908544ad-edc3-59df-8faf-6a87cc256cf5
              ImageId: 3c731605-d772-541a-a5e7-0375dbc68a07
            Similarity: 95.94520568847656
        SearchedFaceId: 70008e50-75e4-55d0-8e80-363fb73b3a14
      properties:
        SearchedFaceId:
          $ref: "#/components/schemas/FaceId"
        FaceMatches:
          $ref: "#/components/schemas/FaceMatchList"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
    SearchFacesRequest:
      type: object
      required:
        - CollectionId
        - FaceId
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        FaceId:
          $ref: "#/components/schemas/FaceId"
        MaxFaces:
          $ref: "#/components/schemas/MaxFaces"
        FaceMatchThreshold:
          $ref: "#/components/schemas/Percent"
    SearchFacesByImageResponse:
      type: object
      example:
        FaceMatches:
          - Face:
              BoundingBox:
                Height: 0.3234420120716095
                Left: 0.3233329951763153
                Top: 0.5
                Width: 0.24222199618816376
              Confidence: 99.99829864501953
              FaceId: 38271d79-7bc2-5efb-b752-398a8d575b85
              ImageId: d5631190-d039-54e4-b267-abd22c8647c5
            Similarity: 99.97036743164062
        SearchedFaceBoundingBox:
          Height: 0.33481481671333313
          Left: 0.31888890266418457
          Top: 0.4933333396911621
          Width: 0.25
        SearchedFaceConfidence: 99.9991226196289
      properties:
        SearchedFaceBoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        SearchedFaceConfidence:
          $ref: "#/components/schemas/Percent"
        FaceMatches:
          $ref: "#/components/schemas/FaceMatchList"
        FaceModelVersion:
          $ref: "#/components/schemas/String"
    SearchFacesByImageRequest:
      type: object
      required:
        - CollectionId
        - Image
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        Image:
          $ref: "#/components/schemas/Image"
        MaxFaces:
          $ref: "#/components/schemas/MaxFaces"
        FaceMatchThreshold:
          $ref: "#/components/schemas/Percent"
    StartCelebrityRecognitionResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartCelebrityRecognitionRequest:
      type: object
      required:
        - Video
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    IdempotentParameterMismatchException: {}
    VideoTooLargeException: {}
    StartContentModerationResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartContentModerationRequest:
      type: object
      required:
        - Video
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        MinConfidence:
          $ref: "#/components/schemas/Percent"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    StartFaceDetectionResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartFaceDetectionRequest:
      type: object
      required:
        - Video
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        FaceAttributes:
          $ref: "#/components/schemas/FaceAttributes"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    StartFaceSearchResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartFaceSearchRequest:
      type: object
      required:
        - Video
        - CollectionId
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        FaceMatchThreshold:
          $ref: "#/components/schemas/Percent"
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    StartLabelDetectionResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartLabelDetectionRequest:
      type: object
      required:
        - Video
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        MinConfidence:
          $ref: "#/components/schemas/Percent"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    StartPersonTrackingResponse:
      type: object
      properties:
        JobId:
          $ref: "#/components/schemas/JobId"
    StartPersonTrackingRequest:
      type: object
      required:
        - Video
      properties:
        Video:
          $ref: "#/components/schemas/Video"
        ClientRequestToken:
          $ref: "#/components/schemas/ClientRequestToken"
        NotificationChannel:
          $ref: "#/components/schemas/NotificationChannel"
        JobTag:
          $ref: "#/components/schemas/JobTag"
    StartStreamProcessorResponse:
      type: object
      properties: {}
    StartStreamProcessorRequest:
      type: object
      required:
        - Name
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
    StopStreamProcessorResponse:
      type: object
      properties: {}
    StopStreamProcessorRequest:
      type: object
      required:
        - Name
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
    UInteger:
      type: integer
      minimum: 0
    AgeRange:
      type: object
      properties:
        Low:
          $ref: "#/components/schemas/UInteger"
        High:
          $ref: "#/components/schemas/UInteger"
      description: <p>Structure containing the estimated age range, in years, for a
        face.</p> <p>Amazon Rekognition estimates an age range for faces
        detected in the input image. Estimated age ranges can overlap. A face of
        a 5-year-old might have an estimated range of 4-6, while the face of a
        6-year-old might have an estimated range of 4-8.</p>
    Attribute:
      type: string
      enum:
        - DEFAULT
        - ALL
    Attributes:
      type: array
      items:
        $ref: "#/components/schemas/Attribute"
    Boolean:
      type: boolean
    Percent:
      type: number
      format: float
      minimum: 0
      maximum: 100
    Beard:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the face has a beard, and the confidence level
        in the determination.
    Float:
      type: number
      format: float
    BoundingBox:
      type: object
      properties:
        Width:
          $ref: "#/components/schemas/Float"
        Height:
          $ref: "#/components/schemas/Float"
        Left:
          $ref: "#/components/schemas/Float"
        Top:
          $ref: "#/components/schemas/Float"
      description: <p>Identifies the bounding box around the label, face, or text. The
        <code>left</code> (x-coordinate) and <code>top</code> (y-coordinate) are
        coordinates representing the top and left sides of the bounding box.
        Note that the upper-left corner of the image is the origin (0,0). </p>
        <p>The <code>top</code> and <code>left</code> values returned are ratios
        of the overall image size. For example, if the input image is 700x200
        pixels, and the top-left coordinate of the bounding box is 350x50
        pixels, the API returns a <code>left</code> value of 0.5 (350/700) and a
        <code>top</code> value of 0.25 (50/200).</p> <p>The <code>width</code>
        and <code>height</code> values represent the dimensions of the bounding
        box as a ratio of the overall image dimension. For example, if the input
        image is 700x200 pixels, and the bounding box width is 70 pixels, the
        width returned is 0.1. </p> <note> <p> The bounding box coordinates can
        have negative values. For example, if Amazon Rekognition is able to
        detect a face that is at the image edge and is only partially visible,
        the service can return coordinates that are outside the image bounds
        and, depending on the image edge, you might get negative values or
        values greater than 1 for the <code>left</code> or <code>top</code>
        values. </p> </note>
    Urls:
      type: array
      items:
        $ref: "#/components/schemas/Url"
    String:
      type: string
    RekognitionUniqueId:
      type: string
      pattern: "[0-9A-Za-z]*"
    ComparedFace:
      type: object
      properties:
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Confidence:
          $ref: "#/components/schemas/Percent"
        Landmarks:
          $ref: "#/components/schemas/Landmarks"
        Pose:
          $ref: "#/components/schemas/Pose"
        Quality:
          $ref: "#/components/schemas/ImageQuality"
      description: Provides face metadata for target image faces that are analyzed by
        <code>CompareFaces</code> and <code>RecognizeCelebrities</code>.
    Celebrity:
      type: object
      properties:
        Urls:
          $ref: "#/components/schemas/Urls"
        Name:
          $ref: "#/components/schemas/String"
        Id:
          $ref: "#/components/schemas/RekognitionUniqueId"
        Face:
          $ref: "#/components/schemas/ComparedFace"
        MatchConfidence:
          $ref: "#/components/schemas/Percent"
      description: Provides information about a celebrity recognized by the
        <a>RecognizeCelebrities</a> operation.
    FaceDetail:
      type: object
      properties:
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        AgeRange:
          $ref: "#/components/schemas/AgeRange"
        Smile:
          $ref: "#/components/schemas/Smile"
        Eyeglasses:
          $ref: "#/components/schemas/Eyeglasses"
        Sunglasses:
          $ref: "#/components/schemas/Sunglasses"
        Gender:
          $ref: "#/components/schemas/Gender"
        Beard:
          $ref: "#/components/schemas/Beard"
        Mustache:
          $ref: "#/components/schemas/Mustache"
        EyesOpen:
          $ref: "#/components/schemas/EyeOpen"
        MouthOpen:
          $ref: "#/components/schemas/MouthOpen"
        Emotions:
          $ref: "#/components/schemas/Emotions"
        Landmarks:
          $ref: "#/components/schemas/Landmarks"
        Pose:
          $ref: "#/components/schemas/Pose"
        Quality:
          $ref: "#/components/schemas/ImageQuality"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: <p>Structure containing attributes of the face that the algorithm
        detected.</p> <p>A <code>FaceDetail</code> object contains either the
        default facial attributes or all facial attributes. The default
        attributes are <code>BoundingBox</code>, <code>Confidence</code>,
        <code>Landmarks</code>, <code>Pose</code>, and <code>Quality</code>.</p>
        <p> <a>GetFaceDetection</a> is the only Amazon Rekognition Video stored
        video operation that can return a <code>FaceDetail</code> object with
        all attributes. To specify which attributes to return, use the
        <code>FaceAttributes</code> input parameter for
        <a>StartFaceDetection</a>. The following Amazon Rekognition Video
        operations return only the default attributes. The corresponding Start
        operations don't have a <code>FaceAttributes</code> input parameter.</p>
        <ul> <li> <p>GetCelebrityRecognition</p> </li> <li>
        <p>GetPersonTracking</p> </li> <li> <p>GetFaceSearch</p> </li> </ul>
        <p>The Amazon Rekognition Image <a>DetectFaces</a> and <a>IndexFaces</a>
        operations can return all facial attributes. To specify which attributes
        to return, use the <code>Attributes</code> input parameter for
        <code>DetectFaces</code>. For <code>IndexFaces</code>, use the
        <code>DetectAttributes</code> input parameter.</p>
    CelebrityDetail:
      type: object
      properties:
        Urls:
          $ref: "#/components/schemas/Urls"
        Name:
          $ref: "#/components/schemas/String"
        Id:
          $ref: "#/components/schemas/RekognitionUniqueId"
        Confidence:
          $ref: "#/components/schemas/Percent"
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Face:
          $ref: "#/components/schemas/FaceDetail"
      description: Information about a recognized celebrity.
    CelebrityList:
      type: array
      items:
        $ref: "#/components/schemas/Celebrity"
    Timestamp:
      type: integer
    CelebrityRecognition:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        Celebrity:
          $ref: "#/components/schemas/CelebrityDetail"
      description: Information about a detected celebrity and the time the celebrity was
        detected in a stored video. For more information, see
        GetCelebrityRecognition in the Amazon Rekognition Developer Guide.
    CelebrityRecognitionSortBy:
      type: string
      enum:
        - ID
        - TIMESTAMP
    CelebrityRecognitions:
      type: array
      items:
        $ref: "#/components/schemas/CelebrityRecognition"
    ClientRequestToken:
      type: string
      pattern: ^[a-zA-Z0-9-_]+$
      minLength: 1
      maxLength: 64
    CollectionId:
      type: string
      pattern: "[a-zA-Z0-9_.\\-]+"
      minLength: 1
      maxLength: 255
    CollectionIdList:
      type: array
      items:
        $ref: "#/components/schemas/CollectionId"
    CompareFacesMatch:
      type: object
      properties:
        Similarity:
          $ref: "#/components/schemas/Percent"
        Face:
          $ref: "#/components/schemas/ComparedFace"
      description: Provides information about a face in a target image that matches the
        source image face analyzed by <code>CompareFaces</code>. The
        <code>Face</code> property contains the bounding box of the face in the
        target image. The <code>Similarity</code> property is the confidence
        that the source image face matches the face in the bounding box.
    CompareFacesMatchList:
      type: array
      items:
        $ref: "#/components/schemas/CompareFacesMatch"
    Image:
      type: object
      properties:
        Bytes:
          $ref: "#/components/schemas/ImageBlob"
        S3Object:
          $ref: "#/components/schemas/S3Object"
      description: <p>Provides the input image either as bytes or an S3 object.</p> <p>You
        pass image bytes to an Amazon Rekognition API operation by using the
        <code>Bytes</code> property. For example, you would use the
        <code>Bytes</code> property to pass an image loaded from a local file
        system. Image bytes passed by using the <code>Bytes</code> property must
        be base64-encoded. Your code may not need to encode image bytes if you
        are using an AWS SDK to call Amazon Rekognition API operations. </p>
        <p>For more information, see Analyzing an Image Loaded from a Local File
        System in the Amazon Rekognition Developer Guide.</p> <p> You pass
        images stored in an S3 bucket to an Amazon Rekognition API operation by
        using the <code>S3Object</code> property. Images stored in an S3 bucket
        do not need to be base64-encoded.</p> <p>The region for the S3 bucket
        containing the S3 object must match the region you use for Amazon
        Rekognition operations.</p> <p>If you use the AWS CLI to call Amazon
        Rekognition operations, passing image bytes using the Bytes property is
        not supported. You must first upload the image to an Amazon S3 bucket
        and then call the operation using the S3Object property.</p> <p>For
        Amazon Rekognition to process an S3 object, the user must have
        permission to access the S3 object. For more information, see Resource
        Based Policies in the Amazon Rekognition Developer Guide. </p>
    ComparedSourceImageFace:
      type: object
      properties:
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: "Type that describes the face Amazon Rekognition chose to compare with
        the faces in the target. This contains a bounding box for the selected
        face and confidence level that the bounding box contains a face. Note
        that Amazon Rekognition selects the largest face in the source image for
        this comparison. "
    CompareFacesUnmatchList:
      type: array
      items:
        $ref: "#/components/schemas/ComparedFace"
    OrientationCorrection:
      type: string
      enum:
        - ROTATE_0
        - ROTATE_90
        - ROTATE_180
        - ROTATE_270
    Landmarks:
      type: array
      items:
        $ref: "#/components/schemas/Landmark"
    Pose:
      type: object
      properties:
        Roll:
          $ref: "#/components/schemas/Degree"
        Yaw:
          $ref: "#/components/schemas/Degree"
        Pitch:
          $ref: "#/components/schemas/Degree"
      description: Indicates the pose of the face as determined by its pitch, roll, and yaw.
    ImageQuality:
      type: object
      properties:
        Brightness:
          $ref: "#/components/schemas/Float"
        Sharpness:
          $ref: "#/components/schemas/Float"
      description: "Identifies face image brightness and sharpness. "
    ComparedFaceList:
      type: array
      items:
        $ref: "#/components/schemas/ComparedFace"
    ModerationLabel:
      type: object
      properties:
        Confidence:
          $ref: "#/components/schemas/Percent"
        Name:
          $ref: "#/components/schemas/String"
        ParentName:
          $ref: "#/components/schemas/String"
      description: Provides information about a single type of unsafe content found in an
        image or video. Each type of moderated content has a label within a
        hierarchical taxonomy. For more information, see Detecting Unsafe
        Content in the Amazon Rekognition Developer Guide.
    ContentModerationDetection:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        ModerationLabel:
          $ref: "#/components/schemas/ModerationLabel"
      description: Information about an unsafe content label detection in a stored video.
    ContentModerationDetections:
      type: array
      items:
        $ref: "#/components/schemas/ContentModerationDetection"
    ContentModerationSortBy:
      type: string
      enum:
        - NAME
        - TIMESTAMP
    StreamProcessorInput:
      type: object
      properties:
        KinesisVideoStream:
          $ref: "#/components/schemas/KinesisVideoStream"
      description: "Information about the source streaming video. "
    StreamProcessorOutput:
      type: object
      properties:
        KinesisDataStream:
          $ref: "#/components/schemas/KinesisDataStream"
      description: Information about the Amazon Kinesis Data Streams stream to which a
        Amazon Rekognition Video stream processor streams the results of a video
        analysis. For more information, see CreateStreamProcessor in the Amazon
        Rekognition Developer Guide.
    StreamProcessorName:
      type: string
      pattern: "[a-zA-Z0-9_.\\-]+"
      minLength: 1
      maxLength: 128
    StreamProcessorSettings:
      type: object
      properties:
        FaceSearch:
          $ref: "#/components/schemas/FaceSearchSettings"
      description: Input parameters used to recognize faces in a streaming video analyzed
        by a Amazon Rekognition stream processor.
    RoleArn:
      type: string
      pattern: arn:aws:iam::\d{12}:role/?[a-zA-Z_0-9+=,.@\-_/]+
    StreamProcessorArn:
      type: string
      pattern: (^arn:[a-z\d-]+:rekognition:[a-z\d-]+:\d{12}:streamprocessor\/.+$)
    DateTime:
      type: string
      format: date-time
    Degree:
      type: number
      format: float
      minimum: -180
      maximum: 180
    FaceIdList:
      type: array
      items:
        $ref: "#/components/schemas/FaceId"
      minItems: 1
      maxItems: 4096
    ULong:
      type: integer
      minimum: 0
    StreamProcessorStatus:
      type: string
      enum:
        - STOPPED
        - STARTING
        - RUNNING
        - FAILED
        - STOPPING
    FaceDetailList:
      type: array
      items:
        $ref: "#/components/schemas/FaceDetail"
    Labels:
      type: array
      items:
        $ref: "#/components/schemas/Label"
    ModerationLabels:
      type: array
      items:
        $ref: "#/components/schemas/ModerationLabel"
    TextDetectionList:
      type: array
      items:
        $ref: "#/components/schemas/TextDetection"
    EmotionName:
      type: string
      enum:
        - HAPPY
        - SAD
        - ANGRY
        - CONFUSED
        - DISGUSTED
        - SURPRISED
        - CALM
        - UNKNOWN
        - FEAR
    Emotion:
      type: object
      properties:
        Type:
          $ref: "#/components/schemas/EmotionName"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: The emotions that appear to be expressed on the face, and the confidence
        level in the determination. The API is only making a determination of
        the physical appearance of a person's face. It is not a determination of
        the person’s internal emotional state and should not be used in such a
        way. For example, a person pretending to have a sad face might not be
        sad emotionally.
    Emotions:
      type: array
      items:
        $ref: "#/components/schemas/Emotion"
    ExternalImageId:
      type: string
      pattern: "[a-zA-Z0-9_.\\-:]+"
      minLength: 1
      maxLength: 255
    EyeOpen:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the eyes on the face are open, and the
        confidence level in the determination.
    Eyeglasses:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the face is wearing eye glasses, and the
        confidence level in the determination.
    FaceId:
      type: string
      pattern: "[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"
    ImageId:
      type: string
      pattern: "[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}"
    Face:
      type: object
      properties:
        FaceId:
          $ref: "#/components/schemas/FaceId"
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        ImageId:
          $ref: "#/components/schemas/ImageId"
        ExternalImageId:
          $ref: "#/components/schemas/ExternalImageId"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: "Describes the face properties such as the bounding box, face ID, image
        ID of the input image, and external image ID that you assigned. "
    FaceAttributes:
      type: string
      enum:
        - DEFAULT
        - ALL
    Smile:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the face is smiling, and the confidence level
        in the determination.
    Sunglasses:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the face is wearing sunglasses, and the
        confidence level in the determination.
    Gender:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/GenderType"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Gender of the face and the confidence level in the determination.
    Mustache:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the face has a mustache, and the confidence
        level in the determination.
    MouthOpen:
      type: object
      properties:
        Value:
          $ref: "#/components/schemas/Boolean"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: Indicates whether or not the mouth on the face is open, and the
        confidence level in the determination.
    FaceDetection:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        Face:
          $ref: "#/components/schemas/FaceDetail"
      description: "Information about a face detected in a video analysis request and the
        time the face was detected in the video. "
    FaceDetections:
      type: array
      items:
        $ref: "#/components/schemas/FaceDetection"
    FaceList:
      type: array
      items:
        $ref: "#/components/schemas/Face"
    FaceMatch:
      type: object
      properties:
        Similarity:
          $ref: "#/components/schemas/Percent"
        Face:
          $ref: "#/components/schemas/Face"
      description: Provides face metadata. In addition, it also provides the confidence in
        the match of this face with the input face.
    FaceMatchList:
      type: array
      items:
        $ref: "#/components/schemas/FaceMatch"
    FaceModelVersionList:
      type: array
      items:
        $ref: "#/components/schemas/String"
    FaceRecord:
      type: object
      properties:
        Face:
          $ref: "#/components/schemas/Face"
        FaceDetail:
          $ref: "#/components/schemas/FaceDetail"
      description: Object containing both the face metadata (stored in the backend
        database), and facial attributes that are detected but aren't stored in
        the database.
    FaceRecordList:
      type: array
      items:
        $ref: "#/components/schemas/FaceRecord"
    FaceSearchSettings:
      type: object
      properties:
        CollectionId:
          $ref: "#/components/schemas/CollectionId"
        FaceMatchThreshold:
          $ref: "#/components/schemas/Percent"
      description: Input face recognition parameters for an Amazon Rekognition stream
        processor. <code>FaceRecognitionSettings</code> is a request parameter
        for <a>CreateStreamProcessor</a>.
    FaceSearchSortBy:
      type: string
      enum:
        - INDEX
        - TIMESTAMP
    GenderType:
      type: string
      enum:
        - Male
        - Female
    Polygon:
      type: array
      items:
        $ref: "#/components/schemas/Point"
    Geometry:
      type: object
      properties:
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Polygon:
          $ref: "#/components/schemas/Polygon"
      description: Information about where the text detected by <a>DetectText</a> is
        located on an image.
    JobId:
      type: string
      pattern: ^[a-zA-Z0-9-_]+$
      minLength: 1
      maxLength: 64
    MaxResults:
      type: integer
      minimum: 1
    PaginationToken:
      type: string
      maxLength: 255
    VideoJobStatus:
      type: string
      enum:
        - IN_PROGRESS
        - SUCCEEDED
        - FAILED
    StatusMessage:
      type: string
    VideoMetadata:
      type: object
      properties:
        Codec:
          $ref: "#/components/schemas/String"
        DurationMillis:
          $ref: "#/components/schemas/ULong"
        Format:
          $ref: "#/components/schemas/String"
        FrameRate:
          $ref: "#/components/schemas/Float"
        FrameHeight:
          $ref: "#/components/schemas/ULong"
        FrameWidth:
          $ref: "#/components/schemas/ULong"
      description: Information about a video that Amazon Rekognition analyzed.
        <code>Videometadata</code> is returned in every page of paginated
        responses from a Amazon Rekognition video operation.
    PersonMatches:
      type: array
      items:
        $ref: "#/components/schemas/PersonMatch"
    LabelDetectionSortBy:
      type: string
      enum:
        - NAME
        - TIMESTAMP
    LabelDetections:
      type: array
      items:
        $ref: "#/components/schemas/LabelDetection"
    PersonTrackingSortBy:
      type: string
      enum:
        - INDEX
        - TIMESTAMP
    PersonDetections:
      type: array
      items:
        $ref: "#/components/schemas/PersonDetection"
    ImageBlob:
      type: string
      minLength: 1
      maxLength: 5242880
    S3Object:
      type: object
      properties:
        Bucket:
          $ref: "#/components/schemas/S3Bucket"
        Name:
          $ref: "#/components/schemas/S3ObjectName"
        Version:
          $ref: "#/components/schemas/S3ObjectVersion"
      description: <p>Provides the S3 bucket name and object name.</p> <p>The region for
        the S3 bucket containing the S3 object must match the region you use for
        Amazon Rekognition operations.</p> <p>For Amazon Rekognition to process
        an S3 object, the user must have permission to access the S3 object. For
        more information, see Resource-Based Policies in the Amazon Rekognition
        Developer Guide. </p>
    MaxFacesToIndex:
      type: integer
      minimum: 1
    QualityFilter:
      type: string
      enum:
        - NONE
        - AUTO
    UnindexedFaces:
      type: array
      items:
        $ref: "#/components/schemas/UnindexedFace"
    Instance:
      type: object
      properties:
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Confidence:
          $ref: "#/components/schemas/Percent"
      description: An instance of a label returned by Amazon Rekognition Image
        (<a>DetectLabels</a>) or by Amazon Rekognition Video
        (<a>GetLabelDetection</a>).
    Instances:
      type: array
      items:
        $ref: "#/components/schemas/Instance"
    JobTag:
      type: string
      pattern: "[a-zA-Z0-9_.\\-:]+"
      minLength: 1
      maxLength: 256
    KinesisDataArn:
      type: string
      pattern: (^arn:([a-z\d-]+):kinesis:([a-z\d-]+):\d{12}:.+$)
    KinesisDataStream:
      type: object
      properties:
        Arn:
          $ref: "#/components/schemas/KinesisDataArn"
      description: The Kinesis data stream Amazon Rekognition to which the analysis results
        of a Amazon Rekognition stream processor are streamed. For more
        information, see CreateStreamProcessor in the Amazon Rekognition
        Developer Guide.
    KinesisVideoArn:
      type: string
      pattern: (^arn:([a-z\d-]+):kinesisvideo:([a-z\d-]+):\d{12}:.+$)
    KinesisVideoStream:
      type: object
      properties:
        Arn:
          $ref: "#/components/schemas/KinesisVideoArn"
      description: Kinesis video stream stream that provides the source streaming video for
        a Amazon Rekognition Video stream processor. For more information, see
        CreateStreamProcessor in the Amazon Rekognition Developer Guide.
    Parents:
      type: array
      items:
        $ref: "#/components/schemas/Parent"
    Label:
      type: object
      properties:
        Name:
          $ref: "#/components/schemas/String"
        Confidence:
          $ref: "#/components/schemas/Percent"
        Instances:
          $ref: "#/components/schemas/Instances"
        Parents:
          $ref: "#/components/schemas/Parents"
      description: <p>Structure containing details about the detected label, including the
        name, detected instances, parent labels, and level of confidence.</p>
        <p> </p>
    LabelDetection:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        Label:
          $ref: "#/components/schemas/Label"
      description: "Information about a label detected in a video analysis request and the
        time the label was detected in the video. "
    LandmarkType:
      type: string
      enum:
        - eyeLeft
        - eyeRight
        - nose
        - mouthLeft
        - mouthRight
        - leftEyeBrowLeft
        - leftEyeBrowRight
        - leftEyeBrowUp
        - rightEyeBrowLeft
        - rightEyeBrowRight
        - rightEyeBrowUp
        - leftEyeLeft
        - leftEyeRight
        - leftEyeUp
        - leftEyeDown
        - rightEyeLeft
        - rightEyeRight
        - rightEyeUp
        - rightEyeDown
        - noseLeft
        - noseRight
        - mouthUp
        - mouthDown
        - leftPupil
        - rightPupil
        - upperJawlineLeft
        - midJawlineLeft
        - chinBottom
        - midJawlineRight
        - upperJawlineRight
    Landmark:
      type: object
      properties:
        Type:
          $ref: "#/components/schemas/LandmarkType"
        X:
          $ref: "#/components/schemas/Float"
        Y:
          $ref: "#/components/schemas/Float"
      description: Indicates the location of the landmark on the face.
    PageSize:
      type: integer
      minimum: 0
      maximum: 4096
    StreamProcessorList:
      type: array
      items:
        $ref: "#/components/schemas/StreamProcessor"
    MaxFaces:
      type: integer
      minimum: 1
      maximum: 4096
    SNSTopicArn:
      type: string
      pattern: (^arn:aws:sns:.*:\w{12}:.+$)
    NotificationChannel:
      type: object
      required:
        - SNSTopicArn
        - RoleArn
      properties:
        SNSTopicArn:
          $ref: "#/components/schemas/SNSTopicArn"
        RoleArn:
          $ref: "#/components/schemas/RoleArn"
      description: The Amazon Simple Notification Service topic to which Amazon Rekognition
        publishes the completion status of a video analysis operation. For more
        information, see <a>api-video</a>.
    Parent:
      type: object
      properties:
        Name:
          $ref: "#/components/schemas/String"
      description: "A parent label for a label. A label can have 0, 1, or more parents. "
    PersonIndex:
      type: integer
    PersonDetail:
      type: object
      properties:
        Index:
          $ref: "#/components/schemas/PersonIndex"
        BoundingBox:
          $ref: "#/components/schemas/BoundingBox"
        Face:
          $ref: "#/components/schemas/FaceDetail"
      description: Details about a person detected in a video analysis request.
    PersonDetection:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        Person:
          $ref: "#/components/schemas/PersonDetail"
      description: <p>Details and path tracking information for a single time a person's
        path is tracked in a video. Amazon Rekognition operations that track
        people's paths return an array of <code>PersonDetection</code> objects
        with elements for each time a person's path is tracked in a video. </p>
        <p>For more information, see GetPersonTracking in the Amazon Rekognition
        Developer Guide. </p>
    PersonMatch:
      type: object
      properties:
        Timestamp:
          $ref: "#/components/schemas/Timestamp"
        Person:
          $ref: "#/components/schemas/PersonDetail"
        FaceMatches:
          $ref: "#/components/schemas/FaceMatchList"
      description: "Information about a person whose face matches a face(s) in an Amazon
        Rekognition collection. Includes information about the faces in the
        Amazon Rekognition collection (<a>FaceMatch</a>), information about the
        person (<a>PersonDetail</a>), and the time stamp for when the person was
        detected in a video. An array of <code>PersonMatch</code> objects is
        returned by <a>GetFaceSearch</a>. "
    Point:
      type: object
      properties:
        X:
          $ref: "#/components/schemas/Float"
        Y:
          $ref: "#/components/schemas/Float"
      description: <p>The X and Y coordinates of a point on an image. The X and Y values
        returned are ratios of the overall image size. For example, if the input
        image is 700x200 and the operation returns X=0.5 and Y=0.25, then the
        point is at the (350,50) pixel coordinate on the image.</p> <p>An array
        of <code>Point</code> objects, <code>Polygon</code>, is returned by
        <a>DetectText</a>. <code>Polygon</code> represents a fine-grained
        polygon around detected text. For more information, see Geometry in the
        Amazon Rekognition Developer Guide. </p>
    Reason:
      type: string
      enum:
        - EXCEEDS_MAX_FACES
        - EXTREME_POSE
        - LOW_BRIGHTNESS
        - LOW_SHARPNESS
        - LOW_CONFIDENCE
        - SMALL_BOUNDING_BOX
    Reasons:
      type: array
      items:
        $ref: "#/components/schemas/Reason"
    S3Bucket:
      type: string
      pattern: "[0-9A-Za-z\\.\\-_]*"
      minLength: 3
      maxLength: 255
    S3ObjectName:
      type: string
      minLength: 1
      maxLength: 1024
    S3ObjectVersion:
      type: string
      minLength: 1
      maxLength: 1024
    Video:
      type: object
      properties:
        S3Object:
          $ref: "#/components/schemas/S3Object"
      description: Video file stored in an Amazon S3 bucket. Amazon Rekognition video start
        operations such as <a>StartLabelDetection</a> use <code>Video</code> to
        specify a video for analysis. The supported file formats are .mp4, .mov
        and .avi.
    StreamProcessor:
      type: object
      properties:
        Name:
          $ref: "#/components/schemas/StreamProcessorName"
        Status:
          $ref: "#/components/schemas/StreamProcessorStatus"
      description: "An object that recognizes faces in a streaming video. An Amazon
        Rekognition stream processor is created by a call to
        <a>CreateStreamProcessor</a>. The request parameters for
        <code>CreateStreamProcessor</code> describe the Kinesis video stream
        source for the streaming video, face recognition parameters, and where
        to stream the analysis resullts. "
    TextTypes:
      type: string
      enum:
        - LINE
        - WORD
    TextDetection:
      type: object
      properties:
        DetectedText:
          $ref: "#/components/schemas/String"
        Type:
          $ref: "#/components/schemas/TextTypes"
        Id:
          $ref: "#/components/schemas/UInteger"
        ParentId:
          $ref: "#/components/schemas/UInteger"
        Confidence:
          $ref: "#/components/schemas/Percent"
        Geometry:
          $ref: "#/components/schemas/Geometry"
      description: <p>Information about a word or line of text detected by
        <a>DetectText</a>.</p> <p>The <code>DetectedText</code> field contains
        the text that Amazon Rekognition detected in the image. </p> <p>Every
        word and line has an identifier (<code>Id</code>). Each word belongs to
        a line and has a parent identifier (<code>ParentId</code>) that
        identifies the line of text in which the word appears. The word
        <code>Id</code> is also an index for the word within a line of words.
        </p> <p>For more information, see Detecting Text in the Amazon
        Rekognition Developer Guide.</p>
    UnindexedFace:
      type: object
      properties:
        Reasons:
          $ref: "#/components/schemas/Reasons"
        FaceDetail:
          $ref: "#/components/schemas/FaceDetail"
      description: A face that <a>IndexFaces</a> detected, but didn't index. Use the
        <code>Reasons</code> response attribute to determine why a face wasn't
        indexed.
    Url:
      type: string
