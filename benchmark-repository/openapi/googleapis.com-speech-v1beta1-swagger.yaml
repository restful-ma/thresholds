openapi: 3.0.0
info:
  contact:
    name: Google
    url: https://google.com
  description: Converts audio to text by applying powerful neural network models.
  title: Cloud Speech
  version: v1beta1
  x-apiClientRegistration:
    url: https://console.developers.google.com
  x-apisguru-categories:
    - machine_learning
  x-logo:
    url: https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png
  x-origin:
    - converter:
        url: https://github.com/lucybot/api-spec-converter
        version: 2.6.2
      format: google
      url: https://speech.googleapis.com/$discovery/rest?version=v1beta1
      version: v1
  x-preferred: false
  x-providerName: googleapis.com
  x-serviceName: speech
externalDocs:
  url: https://cloud.google.com/speech/
tags:
  - name: operations
  - name: speech
paths:
  "/v1beta1/operations/{name}":
    get:
      description: >-
        Gets the latest state of a long-running operation.  Clients can use this

        method to poll the operation result at intervals as recommended by the API

        service.
      operationId: speech.operations.get
      parameters:
        - description: The name of the operation resource.
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - operations
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/bearer_token"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/pp"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
  /v1beta1/speech:asyncrecognize:
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/bearer_token"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/pp"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: |-
        Performs asynchronous speech recognition: receive results via the
        [google.longrunning.Operations]
        (/speech/reference/rest/v1beta1/operations#Operation)
        interface. Returns either an
        `Operation.error` or an `Operation.response` which contains
        an `AsyncRecognizeResponse` message.
      operationId: speech.speech.asyncrecognize
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/AsyncRecognizeRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - speech
  /v1beta1/speech:syncrecognize:
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/bearer_token"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/pp"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: |-
        Performs synchronous speech recognition: receive results after all audio
        has been sent and processed.
      operationId: speech.speech.syncrecognize
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SyncRecognizeRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/SyncRecognizeResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - speech
servers:
  - url: https://speech.googleapis.com/
components:
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
        default: json
    bearer_token:
      description: OAuth bearer token.
      in: query
      name: bearer_token
      schema:
        type: string
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: API key. Your API key identifies your project and provides you with API
        access, quota, and reports. Required unless you provide an OAuth 2.0
        token.
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    pp:
      description: Pretty-print response.
      in: query
      name: pp
      schema:
        type: boolean
        default: true
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
        default: true
    quotaUser:
      description: Available to use for quota purposes for server-side applications. Can be
        any arbitrary string assigned to a user, but should not exceed 40
        characters.
      in: query
      name: quotaUser
      schema:
        type: string
    uploadType:
      description: Legacy upload protocol for media (e.g. "media", "multipart").
      in: query
      name: uploadType
      schema:
        type: string
    upload_protocol:
      description: Upload protocol for media (e.g. "raw", "multipart").
      in: query
      name: upload_protocol
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - "1"
          - "2"
  securitySchemes:
    Oauth2:
      description: Oauth 2.0 authentication
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes:
            https://www.googleapis.com/auth/cloud-platform: View and manage your data across Google Cloud Platform services
  schemas:
    AsyncRecognizeRequest:
      description: The top-level message sent by the client for the `AsyncRecognize` method.
      properties:
        audio:
          $ref: "#/components/schemas/RecognitionAudio"
        config:
          $ref: "#/components/schemas/RecognitionConfig"
      type: object
    Operation:
      description: >-
        This resource represents a long-running operation that is the result of
        a

        network API call.
      properties:
        done:
          description: >-
            If the value is `false`, it means the operation is still in
            progress.

            If `true`, the operation is completed, and either `error` or `response` is

            available.
          type: boolean
        error:
          $ref: "#/components/schemas/Status"
        metadata:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: >-
            Service-specific metadata associated with the operation.  It
            typically

            contains progress information and common metadata such as create time.

            Some services might not provide such metadata.  Any method that returns a

            long-running operation should document the metadata type, if any.
          type: object
        name:
          description: >-
            The server-assigned name, which is only unique within the same
            service that

            originally returns it. If you use the default HTTP mapping, the

            `name` should have the format of `operations/some/unique/name`.
          type: string
        response:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: >-
            The normal response of the operation in case of success.  If the
            original

            method returns no data on success, such as `Delete`, the response is

            `google.protobuf.Empty`.  If the original method is standard

            `Get`/`Create`/`Update`, the response should be the resource.  For other

            methods, the response should have the type `XxxResponse`, where `Xxx`

            is the original method name.  For example, if the original method name

            is `TakeSnapshot()`, the inferred response type is

            `TakeSnapshotResponse`.
          type: object
      type: object
    RecognitionAudio:
      description: >-
        Contains audio data in the encoding specified in the
        `RecognitionConfig`.

        Either `content` or `uri` must be supplied. Supplying both or neither

        returns google.rpc.Code.INVALID_ARGUMENT. See

        [audio limits](https://cloud.google.com/speech/limits#content).
      properties:
        content:
          description: >-
            The audio data bytes encoded as specified in

            `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a

            pure binary representation, whereas JSON representations use base64.
          format: byte
          type: string
        uri:
          description: >-
            URI that points to a file that contains audio data bytes as
            specified in

            `RecognitionConfig`. Currently, only Google Cloud Storage URIs are

            supported, which must be specified in the following format:

            `gs://bucket_name/object_name` (other URI formats return

            google.rpc.Code.INVALID_ARGUMENT). For more information, see

            [Request URIs](https://cloud.google.com/storage/docs/reference-uris).
          type: string
      type: object
    RecognitionConfig:
      description: |-
        Provides information to the recognizer that specifies how to process the
        request.
      properties:
        encoding:
          description: "*Required* Encoding of audio data sent in all `RecognitionAudio`
            messages."
          enum:
            - ENCODING_UNSPECIFIED
            - LINEAR16
            - FLAC
            - MULAW
            - AMR
            - AMR_WB
          type: string
        languageCode:
          description: >-
            *Optional* The language of the supplied audio as a BCP-47 language
            tag.

            Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt

            If omitted, defaults to "en-US". See

            [Language Support](https://cloud.google.com/speech/docs/languages)

            for a list of the currently supported language codes.
          type: string
        maxAlternatives:
          description: >-
            *Optional* Maximum number of recognition hypotheses to be returned.

            Specifically, the maximum number of `SpeechRecognitionAlternative` messages

            within each `SpeechRecognitionResult`.

            The server may return fewer than `max_alternatives`.

            Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of

            one. If omitted, will return a maximum of one.
          format: int32
          type: integer
        profanityFilter:
          description: >-
            *Optional* If set to `true`, the server will attempt to filter out

            profanities, replacing all but the initial character in each filtered word

            with asterisks, e.g. "f***". If set to `false` or omitted, profanities

            won't be filtered out.
          type: boolean
        sampleRate:
          description: >-
            *Required* Sample rate in Hertz of the audio data sent in all

            `RecognitionAudio` messages. Valid values are: 8000-48000.

            16000 is optimal. For best results, set the sampling rate of the audio

            source to 16000 Hz. If that's not possible, use the native sample rate of

            the audio source (instead of re-sampling).
          format: int32
          type: integer
        speechContext:
          $ref: "#/components/schemas/SpeechContext"
      type: object
    SpeechContext:
      description: >-
        Provides "hints" to the speech recognizer to favor specific words and
        phrases

        in the results.
      properties:
        phrases:
          description: >-
            *Optional* A list of strings containing words and phrases "hints" so
            that

            the speech recognition is more likely to recognize them. This can be used

            to improve the accuracy for specific words and phrases, for example, if

            specific commands are typically spoken by the user. This can also be used

            to add additional words to the vocabulary of the recognizer. See

            [usage limits](https://cloud.google.com/speech/limits#content).
          items:
            type: string
          type: array
      type: object
    SpeechRecognitionAlternative:
      description: Alternative hypotheses (a.k.a. n-best list).
      properties:
        confidence:
          description: >-
            *Output-only* The confidence estimate between 0.0 and 1.0. A higher
            number

            indicates an estimated greater likelihood that the recognized words are

            correct. This field is typically provided only for the top hypothesis, and

            only for `is_final=true` results. Clients should not rely on the

            `confidence` field as it is not guaranteed to be accurate, or even set, in

            any of the results.

            The default of 0.0 is a sentinel value indicating `confidence` was not set.
          format: float
          type: number
        transcript:
          description: "*Output-only* Transcript text representing the words that the user
            spoke."
          type: string
      type: object
    SpeechRecognitionResult:
      description: A speech recognition result corresponding to a portion of the audio.
      properties:
        alternatives:
          description: >-
            *Output-only* May contain one or more recognition hypotheses (up to
            the

            maximum specified in `max_alternatives`).
          items:
            $ref: "#/components/schemas/SpeechRecognitionAlternative"
          type: array
      type: object
    Status:
      description: >-
        The `Status` type defines a logical error model that is suitable for
        different

        programming environments, including REST APIs and RPC APIs. It is used by

        [gRPC](https://github.com/grpc). The error model is designed to be:


        - Simple to use and understand for most users

        - Flexible enough to meet unexpected needs


        # Overview


        The `Status` message contains three pieces of data: error code, error message,

        and error details. The error code should be an enum value of

        google.rpc.Code, but it may accept additional error codes if needed.  The

        error message should be a developer-facing English message that helps

        developers *understand* and *resolve* the error. If a localized user-facing

        error message is needed, put the localized message in the error details or

        localize it in the client. The optional error details may contain arbitrary

        information about the error. There is a predefined set of error detail types

        in the package `google.rpc` that can be used for common error conditions.


        # Language mapping


        The `Status` message is the logical representation of the error model, but it

        is not necessarily the actual wire format. When the `Status` message is

        exposed in different client libraries and different wire protocols, it can be

        mapped differently. For example, it will likely be mapped to some exceptions

        in Java, but more likely mapped to some error codes in C.


        # Other uses


        The error model and the `Status` message can be used in a variety of

        environments, either with or without APIs, to provide a

        consistent developer experience across different environments.


        Example uses of this error model include:


        - Partial errors. If a service needs to return partial errors to the client,
            it may embed the `Status` in the normal response to indicate the partial
            errors.

        - Workflow errors. A typical workflow has multiple steps. Each step may
            have a `Status` message for error reporting.

        - Batch operations. If a client uses batch request and batch response, the
            `Status` message should be used directly inside batch response, one for
            each error sub-response.

        - Asynchronous operations. If an API call embeds asynchronous operation
            results in its response, the status of those operations should be
            represented directly using the `Status` message.

        - Logging. If some API errors are stored in logs, the message `Status` could
            be used directly after any stripping needed for security/privacy reasons.
      properties:
        code:
          description: The status code, which should be an enum value of google.rpc.Code.
          format: int32
          type: integer
        details:
          description: >-
            A list of messages that carry the error details.  There is a common
            set of

            message types for APIs to use.
          items:
            additionalProperties:
              description: Properties of the object. Contains field @type with type URL.
            type: object
          type: array
        message:
          description: |-
            A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
          type: string
      type: object
    SyncRecognizeRequest:
      description: The top-level message sent by the client for the `SyncRecognize` method.
      properties:
        audio:
          $ref: "#/components/schemas/RecognitionAudio"
        config:
          $ref: "#/components/schemas/RecognitionConfig"
      type: object
    SyncRecognizeResponse:
      description: |-
        The only message returned to the client by `SyncRecognize`. method. It
        contains the result as zero or more sequential `SpeechRecognitionResult`
        messages.
      properties:
        results:
          description: >-
            *Output-only* Sequential list of transcription results corresponding
            to

            sequential portions of audio.
          items:
            $ref: "#/components/schemas/SpeechRecognitionResult"
          type: array
      type: object
