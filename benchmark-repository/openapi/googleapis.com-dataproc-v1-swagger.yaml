openapi: 3.0.0
info:
  contact:
    name: Google
    url: https://google.com
  description: Manages Hadoop-based clusters and jobs on Google Cloud Platform.
  license:
    name: Creative Commons Attribution 3.0
    url: http://creativecommons.org/licenses/by/3.0/
  termsOfService: https://developers.google.com/terms/
  title: Cloud Dataproc
  version: v1
  x-apiClientRegistration:
    url: https://console.developers.google.com
  x-logo:
    url: https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png
  x-origin:
    - converter:
        url: https://github.com/lucybot/api-spec-converter
        version: 2.7.31
      format: google
      url: https://dataproc.googleapis.com/$discovery/rest?version=v1
      version: v1
  x-preferred: true
  x-providerName: googleapis.com
  x-serviceName: dataproc
externalDocs:
  url: https://cloud.google.com/dataproc/
tags:
  - name: projects
paths:
  "/v1/projects/{projectId}/regions/{region}/clusters":
    get:
      description: Lists all regions/{region}/clusters in a project.
      operationId: dataproc.projects.regions.clusters.list
      parameters:
        - description: "Optional. A filter constraining the clusters to list. Filters are
            case-sensitive and have the following syntax:field = value AND field
            = value ...where field is one of status.state, clusterName, or
            labels.[KEY], and [KEY] is a label key. value can be * to match all
            values. status.state can be one of the following: ACTIVE, INACTIVE,
            CREATING, RUNNING, ERROR, DELETING, or UPDATING. ACTIVE contains the
            CREATING, UPDATING, and RUNNING states. INACTIVE contains the
            DELETING and ERROR states. clusterName is the name of the cluster
            provided at creation time. Only the logical AND operator is
            supported; space-separated items are treated as having an implicit
            AND operator.Example filter:status.state = ACTIVE AND clusterName =
            mycluster AND labels.env = staging AND labels.starred = *"
          in: query
          name: filter
          schema:
            type: string
        - description: Optional. The standard List page size.
          in: query
          name: pageSize
          schema:
            type: integer
        - description: Optional. The standard List page token.
          in: query
          name: pageToken
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the
            cluster belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/ListClustersResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Creates a cluster in a project. The returned Operation.metadata will be
        ClusterOperationMetadata.
      operationId: dataproc.projects.regions.clusters.create
      parameters:
        - description: Required. The ID of the Google Cloud Platform project that the
            cluster belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
        - description: Optional. A unique id used to identify the request. If the server
            receives two CreateClusterRequest requests with the same id, then
            the second request will be ignored and the first
            google.longrunning.Operation created and stored in the backend is
            returned.It is recommended to always set this value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id
            must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          in: query
          name: requestId
          schema:
            type: string
      requestBody:
        $ref: "#/components/requestBodies/Cluster"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/projects/{projectId}/regions/{region}/clusters/{clusterName}":
    delete:
      description: Deletes a cluster in a project. The returned Operation.metadata will be
        ClusterOperationMetadata.
      operationId: dataproc.projects.regions.clusters.delete
      parameters:
        - description: Required. The cluster name.
          in: path
          name: clusterName
          required: true
          schema:
            type: string
        - description: Optional. Specifying the cluster_uuid means the RPC should fail
            (with error NOT_FOUND) if cluster with specified UUID does not
            exist.
          in: query
          name: clusterUuid
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the
            cluster belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
        - description: Optional. A unique id used to identify the request. If the server
            receives two DeleteClusterRequest requests with the same id, then
            the second request will be ignored and the first
            google.longrunning.Operation created and stored in the backend is
            returned.It is recommended to always set this value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id
            must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          in: query
          name: requestId
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    get:
      description: Gets the resource representation for a cluster in a project.
      operationId: dataproc.projects.regions.clusters.get
      parameters:
        - description: Required. The cluster name.
          in: path
          name: clusterName
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the
            cluster belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Cluster"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    patch:
      description: Updates a cluster in a project. The returned Operation.metadata will be
        ClusterOperationMetadata.
      operationId: dataproc.projects.regions.clusters.patch
      parameters:
        - description: Required. The cluster name.
          in: path
          name: clusterName
          required: true
          schema:
            type: string
        - description: Optional. Timeout for graceful YARN decomissioning. Graceful
            decommissioning allows removing nodes from the cluster without
            interrupting jobs in progress. Timeout specifies how long to wait
            for jobs in progress to finish before forcefully removing nodes (and
            potentially interrupting jobs). Default timeout is 0 (for forceful
            decommission), and the maximum allowed timeout is 1 day.Only
            supported on Dataproc image versions 1.2 and higher.
          in: query
          name: gracefulDecommissionTimeout
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project the cluster
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
        - description: Optional. A unique id used to identify the request. If the server
            receives two UpdateClusterRequest requests with the same id, then
            the second request will be ignored and the first
            google.longrunning.Operation created and stored in the backend is
            returned.It is recommended to always set this value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id
            must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          in: query
          name: requestId
          schema:
            type: string
        - description: >-
            Required. Specifies the path, relative to Cluster, of the field to
            update. For example, to change the number of workers in a cluster to
            5, the update_mask parameter would be specified as
            config.worker_config.num_instances, and the PATCH request body would
            specify the new value, as follows:

            {
              "config":{
                "workerConfig":{
                  "numInstances":"5"
                }
              }
            }

            Similarly, to change the number of preemptible workers in a cluster to 5, the update_mask parameter would be config.secondary_worker_config.num_instances, and the PATCH request body would be set as follows:

            {
              "config":{
                "secondaryWorkerConfig":{
                  "numInstances":"5"
                }
              }
            }

            <strong>Note:</strong> Currently, only the following fields can be updated:<table>  <tbody>  <tr>  <td><strong>Mask</strong></td>  <td><strong>Purpose</strong></td>  </tr>  <tr>  <td><strong><em>labels</em></strong></td>  <td>Update labels</td>  </tr>  <tr>  <td><strong><em>config.worker_config.num_instances</em></strong></td>  <td>Resize primary worker group</td>  </tr>  <tr>  <td><strong><em>config.secondary_worker_config.num_instances</em></strong></td>  <td>Resize secondary worker group</td>  </tr>  </tbody>  </table>
          in: query
          name: updateMask
          schema:
            type: string
      requestBody:
        $ref: "#/components/requestBodies/Cluster"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/projects/{projectId}/regions/{region}/clusters/{clusterName}:diagnose":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Gets cluster diagnostic information. The returned Operation.metadata
        will be ClusterOperationMetadata. After the operation completes,
        Operation.response contains DiagnoseClusterResults.
      operationId: dataproc.projects.regions.clusters.diagnose
      parameters:
        - description: Required. The cluster name.
          in: path
          name: clusterName
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the
            cluster belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/DiagnoseClusterRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/projects/{projectId}/regions/{region}/jobs":
    get:
      description: Lists regions/{region}/jobs in a project.
      operationId: dataproc.projects.regions.jobs.list
      parameters:
        - description: Optional. If set, the returned jobs list includes only jobs that
            were submitted to the named cluster.
          in: query
          name: clusterName
          schema:
            type: string
        - description: Optional. A filter constraining the jobs to list. Filters are
            case-sensitive and have the following syntax:field = value AND field
            = value ...where field is status.state or labels.[KEY], and [KEY] is
            a label key. value can be * to match all values. status.state can be
            either ACTIVE or NON_ACTIVE. Only the logical AND operator is
            supported; space-separated items are treated as having an implicit
            AND operator.Example filter:status.state = ACTIVE AND labels.env =
            staging AND labels.starred = *
          in: query
          name: filter
          schema:
            type: string
        - description: Optional. Specifies enumerated categories of jobs to list. (default
            = match ALL jobs).If filter is provided, jobStateMatcher will be
            ignored.
          in: query
          name: jobStateMatcher
          schema:
            type: string
            enum:
              - ALL
              - ACTIVE
              - NON_ACTIVE
        - description: Optional. The number of results to return in each response.
          in: query
          name: pageSize
          schema:
            type: integer
        - description: Optional. The page token, returned by a previous call, to request
            the next page of results.
          in: query
          name: pageToken
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/ListJobsResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
  "/v1/projects/{projectId}/regions/{region}/jobs/{jobId}":
    delete:
      description: Deletes the job from the project. If the job is active, the delete
        fails, and the response returns FAILED_PRECONDITION.
      operationId: dataproc.projects.regions.jobs.delete
      parameters:
        - description: Required. The job ID.
          in: path
          name: jobId
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Empty"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    get:
      description: Gets the resource representation for a job in a project.
      operationId: dataproc.projects.regions.jobs.get
      parameters:
        - description: Required. The job ID.
          in: path
          name: jobId
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Job"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    patch:
      description: Updates a job in a project.
      operationId: dataproc.projects.regions.jobs.patch
      parameters:
        - description: Required. The job ID.
          in: path
          name: jobId
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
        - description: Required. Specifies the path, relative to <code>Job</code>, of the
            field to update. For example, to update the labels of a Job the
            <code>update_mask</code> parameter would be specified as
            <code>labels</code>, and the PATCH request body would specify the
            new value. <strong>Note:</strong> Currently, <code>labels</code> is
            the only field that can be updated.
          in: query
          name: updateMask
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/Job"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Job"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/projects/{projectId}/regions/{region}/jobs/{jobId}:cancel":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Starts a job cancellation request. To access the job resource after
        cancellation, call regions/{region}/jobs.list or
        regions/{region}/jobs.get.
      operationId: dataproc.projects.regions.jobs.cancel
      parameters:
        - description: Required. The job ID.
          in: path
          name: jobId
          required: true
          schema:
            type: string
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/CancelJobRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Job"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/projects/{projectId}/regions/{region}/jobs:submit":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Submits a job to a cluster.
      operationId: dataproc.projects.regions.jobs.submit
      parameters:
        - description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          in: path
          name: projectId
          required: true
          schema:
            type: string
        - description: Required. The Cloud Dataproc region in which to handle the request.
          in: path
          name: region
          required: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SubmitJobRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Job"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{name}":
    delete:
      description: Deletes a workflow template. It does not cancel in-progress workflows.
      operationId: dataproc.projects.locations.workflowTemplates.delete
      parameters:
        - description: >-
            Required. The resource name of the workflow template, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates.delete, the resource name of the template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates.instantiate, the resource name  of the template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
        - description: Optional. The version of workflow template to delete. If specified,
            will only delete the template if the current server version matches
            specified version.
          in: query
          name: version
          schema:
            type: integer
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Empty"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    get:
      description: Retrieves the latest workflow template.Can retrieve previously
        instantiated template by specifying optional version parameter.
      operationId: dataproc.projects.locations.workflowTemplates.get
      parameters:
        - description: >-
            Required. The resource name of the workflow template, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates.get, the resource name of the  template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates.get, the resource name of the  template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
        - description: The standard list page size.
          in: query
          name: pageSize
          schema:
            type: integer
        - description: The standard list page token.
          in: query
          name: pageToken
          schema:
            type: string
        - description: Optional. The version of workflow template to retrieve. Only
            previously instantiated versions can be retrieved.If unspecified,
            retrieves the current version.
          in: query
          name: version
          schema:
            type: integer
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/WorkflowTemplate"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    put:
      description: Updates (replaces) workflow template. The updated template must contain
        version that matches the current server version.
      operationId: dataproc.projects.locations.workflowTemplates.update
      parameters:
        - description: >-
            Output only. The resource name of the workflow template, as
            described in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        $ref: "#/components/requestBodies/WorkflowTemplate"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/WorkflowTemplate"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{name}:cancel":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Starts asynchronous cancellation on a long-running operation. The server
        makes a best effort to cancel the operation, but success is not
        guaranteed. If the server doesn't support this method, it returns
        google.rpc.Code.UNIMPLEMENTED. Clients can use Operations.GetOperation
        or other methods to check whether the cancellation succeeded or whether
        the operation completed despite cancellation. On successful
        cancellation, the operation is not deleted; instead, it becomes an
        operation with an Operation.error value with a google.rpc.Status.code of
        1, corresponding to Code.CANCELLED.
      operationId: dataproc.projects.regions.operations.cancel
      parameters:
        - description: The name of the operation resource to be cancelled.
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Empty"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{name}:instantiate":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Instantiates a template and begins execution.The returned Operation can
        be used to track execution of workflow by polling operations.get. The
        Operation will complete when entire workflow is finished.The running
        workflow can be aborted via operations.cancel. This will cause any
        inflight jobs to be cancelled and workflow-owned clusters to be
        deleted.The Operation.metadata will be WorkflowMetadata. Also see Using
        WorkflowMetadata.On successful completion, Operation.response will be
        Empty.
      operationId: dataproc.projects.locations.workflowTemplates.instantiate
      parameters:
        - description: >-
            Required. The resource name of the workflow template, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates.instantiate, the resource name of the template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates.instantiate, the resource name  of the template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          in: path
          name: name
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/InstantiateWorkflowTemplateRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{parent}/autoscalingPolicies":
    get:
      description: Lists autoscaling policies in the project.
      operationId: dataproc.projects.locations.autoscalingPolicies.list
      parameters:
        - description: Optional. The maximum number of results to return in each response.
            Must be less than or equal to 1000. Defaults to 100.
          in: query
          name: pageSize
          schema:
            type: integer
        - description: Optional. The page token, returned by a previous call, to request
            the next page of results.
          in: query
          name: pageToken
          schema:
            type: string
        - description: >-
            Required. The "resource name" of the region or location, as
            described in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.autoscalingPolicies.list, the resource name  of the region has the following format:  projects/{project_id}/regions/{region}

            For projects.locations.autoscalingPolicies.list, the resource name  of the location has the following format:  projects/{project_id}/locations/{location}
          in: path
          name: parent
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/ListAutoscalingPoliciesResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Creates new autoscaling policy.
      operationId: dataproc.projects.locations.autoscalingPolicies.create
      parameters:
        - description: >-
            Required. The "resource name" of the region or location, as
            described in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.autoscalingPolicies.create, the resource name  of the region has the following format:  projects/{project_id}/regions/{region}

            For projects.locations.autoscalingPolicies.create, the resource name  of the location has the following format:  projects/{project_id}/locations/{location}
          in: path
          name: parent
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/AutoscalingPolicy"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/AutoscalingPolicy"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{parent}/workflowTemplates":
    get:
      description: Lists workflows that match the specified filter in the request.
      operationId: dataproc.projects.locations.workflowTemplates.list
      parameters:
        - description: Optional. The maximum number of results to return in each response.
          in: query
          name: pageSize
          schema:
            type: integer
        - description: Optional. The page token, returned by a previous call, to request
            the next page of results.
          in: query
          name: pageToken
          schema:
            type: string
        - description: >-
            Required. The resource name of the region or location, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates,list, the resource  name of the region has the following format:  projects/{project_id}/regions/{region}

            For projects.locations.workflowTemplates.list, the  resource name of the location has the following format:  projects/{project_id}/locations/{location}
          in: path
          name: parent
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/ListWorkflowTemplatesResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Creates new workflow template.
      operationId: dataproc.projects.locations.workflowTemplates.create
      parameters:
        - description: >-
            Required. The resource name of the region or location, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates,create, the resource name of the  region has the following format:  projects/{project_id}/regions/{region}

            For projects.locations.workflowTemplates.create, the resource name of  the location has the following format:  projects/{project_id}/locations/{location}
          in: path
          name: parent
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        $ref: "#/components/requestBodies/WorkflowTemplate"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/WorkflowTemplate"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{parent}/workflowTemplates:instantiateInline":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Instantiates a template and begins execution.This method is equivalent
        to executing the sequence CreateWorkflowTemplate,
        InstantiateWorkflowTemplate, DeleteWorkflowTemplate.The returned
        Operation can be used to track execution of workflow by polling
        operations.get. The Operation will complete when entire workflow is
        finished.The running workflow can be aborted via operations.cancel. This
        will cause any inflight jobs to be cancelled and workflow-owned clusters
        to be deleted.The Operation.metadata will be WorkflowMetadata. Also see
        Using WorkflowMetadata.On successful completion, Operation.response will
        be Empty.
      operationId: dataproc.projects.locations.workflowTemplates.instantiateInline
      parameters:
        - description: >-
            Required. The resource name of the region or location, as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates,instantiateinline, the resource  name of the region has the following format:  projects/{project_id}/regions/{region}

            For projects.locations.workflowTemplates.instantiateinline, the  resource name of the location has the following format:  projects/{project_id}/locations/{location}
          in: path
          name: parent
          required: true
          x-reservedExpansion: true
          schema:
            type: string
        - description: Optional. A tag that prevents multiple concurrent workflow instances
            with the same tag from running. This mitigates risk of concurrent
            instances started due to retries.It is recommended to always set
            this value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The
            tag must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          in: query
          name: requestId
          schema:
            type: string
      requestBody:
        $ref: "#/components/requestBodies/WorkflowTemplate"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{resource}:getIamPolicy":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Gets the access control policy for a resource. Returns an empty policy
        if the resource exists and does not have a policy set.
      operationId: dataproc.projects.locations.workflowTemplates.getIamPolicy
      parameters:
        - description: "REQUIRED: The resource for which the policy is being requested. See
            the operation documentation for the appropriate value for this
            field."
          in: path
          name: resource
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GetIamPolicyRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Policy"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{resource}:setIamPolicy":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: Sets the access control policy on the specified resource. Replaces any
        existing policy.
      operationId: dataproc.projects.locations.workflowTemplates.setIamPolicy
      parameters:
        - description: "REQUIRED: The resource for which the policy is being specified. See
            the operation documentation for the appropriate value for this
            field."
          in: path
          name: resource
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SetIamPolicyRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/Policy"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
  "/v1/{resource}:testIamPermissions":
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: 'Returns permissions that a caller has on the specified resource. If the
        resource does not exist, this will return an empty set of permissions,
        not a NOT_FOUND error.Note: This operation is designed to be used for
        building permission-aware UIs and command-line tools, not for
        authorization checking. This operation may "fail open" without warning.'
      operationId: dataproc.projects.locations.workflowTemplates.testIamPermissions
      parameters:
        - description: "REQUIRED: The resource for which the policy detail is being
            requested. See the operation documentation for the appropriate value
            for this field."
          in: path
          name: resource
          required: true
          x-reservedExpansion: true
          schema:
            type: string
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/TestIamPermissionsRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/TestIamPermissionsResponse"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
          Oauth2c:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - projects
servers:
  - url: https://dataproc.googleapis.com/
components:
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
        default: json
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: API key. Your API key identifies your project and provides you with API
        access, quota, and reports. Required unless you provide an OAuth 2.0
        token.
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
        default: true
    quotaUser:
      description: Available to use for quota purposes for server-side applications. Can be
        any arbitrary string assigned to a user, but should not exceed 40
        characters.
      in: query
      name: quotaUser
      schema:
        type: string
    uploadType:
      description: Legacy upload protocol for media (e.g. "media", "multipart").
      in: query
      name: uploadType
      schema:
        type: string
    upload_protocol:
      description: Upload protocol for media (e.g. "raw", "multipart").
      in: query
      name: upload_protocol
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - "1"
          - "2"
  requestBodies:
    Cluster:
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/Cluster"
    WorkflowTemplate:
      content:
        application/json:
          schema:
            $ref: "#/components/schemas/WorkflowTemplate"
  securitySchemes:
    Oauth2:
      description: Oauth 2.0 implicit authentication
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes:
            https://www.googleapis.com/auth/cloud-platform: View and manage your data across Google Cloud Platform services
    Oauth2c:
      description: Oauth 2.0 accessCode authentication
      type: oauth2
      flows:
        authorizationCode:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          tokenUrl: https://accounts.google.com/o/oauth2/token
          scopes:
            https://www.googleapis.com/auth/cloud-platform: View and manage your data across Google Cloud Platform services
  schemas:
    AcceleratorConfig:
      description: Specifies the type and number of accelerator cards attached to the
        instances of an instance. See GPUs on Compute Engine.
      properties:
        acceleratorCount:
          description: The number of the accelerator cards of this type exposed to this
            instance.
          format: int32
          type: integer
        acceleratorTypeUri:
          description: >-
            Full URL, partial URI, or short name of the accelerator type
            resource to expose to this instance. See Compute Engine
            AcceleratorTypes.Examples:

            https://www.googleapis.com/compute/beta/projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80

            projects/[project_id]/zones/us-east1-a/acceleratorTypes/nvidia-tesla-k80

            nvidia-tesla-k80Auto Zone Exception: If you are using the Cloud Dataproc Auto Zone Placement feature, you must use the short name of the accelerator type resource, for example, nvidia-tesla-k80.
          type: string
      type: object
    AutoscalingConfig:
      description: Autoscaling Policy config associated with the cluster.
      properties:
        policyUri:
          description: >-
            Optional. The autoscaling policy used by the cluster.Only resource
            names including projectid and location (region) are valid. Examples:

            https://www.googleapis.com/compute/v1/projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]

            projects/[project_id]/locations/[dataproc_region]/autoscalingPolicies/[policy_id]Note that the policy must be in the same project and Cloud Dataproc region.
          type: string
      type: object
    AutoscalingPolicy:
      description: Describes an autoscaling policy for Dataproc cluster autoscaler.
      properties:
        basicAlgorithm:
          $ref: "#/components/schemas/BasicAutoscalingAlgorithm"
        id:
          description: Required. The policy id.The id must contain only letters (a-z, A-Z),
            numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end
            with underscore or hyphen. Must consist of between 3 and 50
            characters.
          type: string
        name:
          description: >-
            Output only. The "resource name" of the autoscaling policy, as
            described in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.autoscalingPolicies, the resource name of the  policy has the following format:  projects/{project_id}/regions/{region}/autoscalingPolicies/{policy_id}

            For projects.locations.autoscalingPolicies, the resource name of the  policy has the following format:  projects/{project_id}/locations/{location}/autoscalingPolicies/{policy_id}
          type: string
        secondaryWorkerConfig:
          $ref: "#/components/schemas/InstanceGroupAutoscalingPolicyConfig"
        workerConfig:
          $ref: "#/components/schemas/InstanceGroupAutoscalingPolicyConfig"
      type: object
    BasicAutoscalingAlgorithm:
      description: Basic algorithm for autoscaling.
      properties:
        cooldownPeriod:
          description: "Optional. Duration between scaling events. A scaling period starts
            after the update operation from the previous event has
            completed.Bounds: 2m, 1d. Default: 2m."
          format: google-duration
          type: string
        yarnConfig:
          $ref: "#/components/schemas/BasicYarnAutoscalingConfig"
      type: object
    BasicYarnAutoscalingConfig:
      description: Basic autoscaling configurations for YARN.
      properties:
        gracefulDecommissionTimeout:
          description: "Required. Timeout for YARN graceful decommissioning of Node
            Managers. Specifies the duration to wait for jobs to complete before
            forcefully removing workers (and potentially interrupting jobs).
            Only applicable to downscaling operations.Bounds: 0s, 1d."
          format: google-duration
          type: string
        scaleDownFactor:
          description: "Required. Fraction of average pending memory in the last cooldown
            period for which to remove workers. A scale-down factor of 1 will
            result in scaling down so that there is no available memory
            remaining after the update (more aggressive scaling). A scale-down
            factor of 0 disables removing workers, which can be beneficial for
            autoscaling a single job.Bounds: 0.0, 1.0."
          format: double
          type: number
        scaleDownMinWorkerFraction:
          description: "Optional. Minimum scale-down threshold as a fraction of total
            cluster size before scaling occurs. For example, in a 20-worker
            cluster, a threshold of 0.1 means the autoscaler must recommend at
            least a 2 worker scale-down for the cluster to scale. A threshold of
            0 means the autoscaler will scale down on any recommended
            change.Bounds: 0.0, 1.0. Default: 0.0."
          format: double
          type: number
        scaleUpFactor:
          description: "Required. Fraction of average pending memory in the last cooldown
            period for which to add workers. A scale-up factor of 1.0 will
            result in scaling up so that there is no pending memory remaining
            after the update (more aggressive scaling). A scale-up factor closer
            to 0 will result in a smaller magnitude of scaling up (less
            aggressive scaling).Bounds: 0.0, 1.0."
          format: double
          type: number
        scaleUpMinWorkerFraction:
          description: "Optional. Minimum scale-up threshold as a fraction of total cluster
            size before scaling occurs. For example, in a 20-worker cluster, a
            threshold of 0.1 means the autoscaler must recommend at least a
            2-worker scale-up for the cluster to scale. A threshold of 0 means
            the autoscaler will scale up on any recommended change.Bounds: 0.0,
            1.0. Default: 0.0."
          format: double
          type: number
      type: object
    Binding:
      description: Associates members with a role.
      properties:
        condition:
          $ref: "#/components/schemas/Expr"
        members:
          description: >-
            Specifies the identities requesting access for a Cloud Platform
            resource. members can have the following values:

            allUsers: A special identifier that represents anyone who is  on the internet; with or without a Google account.

            allAuthenticatedUsers: A special identifier that represents anyone  who is authenticated with a Google account or a service account.

            user:{emailid}: An email address that represents a specific Google  account. For example, alice@example.com .

            serviceAccount:{emailid}: An email address that represents a service  account. For example, my-other-app@appspot.gserviceaccount.com.

            group:{emailid}: An email address that represents a Google group.  For example, admins@example.com.

            domain:{domain}: The G Suite domain (primary) that represents all the  users of that domain. For example, google.com or example.com.
          items:
            type: string
          type: array
        role:
          description: Role that is assigned to members. For example, roles/viewer,
            roles/editor, or roles/owner.
          type: string
      type: object
    CancelJobRequest:
      description: A request to cancel a job.
      properties: {}
      type: object
    Cluster:
      description: Describes the identifying information, config, and status of a cluster
        of Compute Engine instances.
      properties:
        clusterName:
          description: Required. The cluster name. Cluster names within a project must be
            unique. Names of deleted clusters can be reused.
          type: string
        clusterUuid:
          description: Output only. A cluster UUID (Unique Universal Identifier). Cloud
            Dataproc generates this value when it creates the cluster.
          type: string
        config:
          $ref: "#/components/schemas/ClusterConfig"
        labels:
          additionalProperties:
            type: string
          description: Optional. The labels to associate with this cluster. Label keys must
            contain 1 to 63 characters, and must conform to RFC 1035
            (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty,
            but, if present, must contain 1 to 63 characters, and must conform
            to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32
            labels can be associated with a cluster.
          type: object
        metrics:
          $ref: "#/components/schemas/ClusterMetrics"
        projectId:
          description: Required. The Google Cloud Platform project ID that the cluster
            belongs to.
          type: string
        status:
          $ref: "#/components/schemas/ClusterStatus"
        statusHistory:
          description: Output only. The previous cluster status.
          items:
            $ref: "#/components/schemas/ClusterStatus"
          type: array
      type: object
    ClusterConfig:
      description: The cluster config.
      properties:
        autoscalingConfig:
          $ref: "#/components/schemas/AutoscalingConfig"
        configBucket:
          description: Optional. A Google Cloud Storage bucket used to stage job
            dependencies, config files, and job driver console output. If you do
            not specify a staging bucket, Cloud Dataproc will determine a Cloud
            Storage location (US, ASIA, or EU) for your cluster's staging bucket
            according to the Google Compute Engine zone where your cluster is
            deployed, and then create and manage this project-level,
            per-location bucket (see Cloud Dataproc staging bucket).
          type: string
        encryptionConfig:
          $ref: "#/components/schemas/EncryptionConfig"
        gceClusterConfig:
          $ref: "#/components/schemas/GceClusterConfig"
        initializationActions:
          description: >
            Optional. Commands to execute on each node after config is
            completed. By default, executables are run on master and all worker
            nodes. You can test a node's role metadata to run an executable on a
            master or worker node, as shown below using curl (you can also use
            wget):

            ROLE=$(curl -H Metadata-Flavor:Google

            http://metadata/computeMetadata/v1/instance/attributes/dataproc-role)

            if [[ "${ROLE}" == 'Master' ]]; then
              ... master specific actions ...
            else
              ... worker specific actions ...
            fi
          items:
            $ref: "#/components/schemas/NodeInitializationAction"
          type: array
        lifecycleConfig:
          $ref: "#/components/schemas/LifecycleConfig"
        masterConfig:
          $ref: "#/components/schemas/InstanceGroupConfig"
        secondaryWorkerConfig:
          $ref: "#/components/schemas/InstanceGroupConfig"
        securityConfig:
          $ref: "#/components/schemas/SecurityConfig"
        softwareConfig:
          $ref: "#/components/schemas/SoftwareConfig"
        workerConfig:
          $ref: "#/components/schemas/InstanceGroupConfig"
      type: object
    ClusterMetrics:
      description: "Contains cluster daemon metrics, such as HDFS and YARN stats.Beta
        Feature: This report is available for testing purposes only. It may be
        changed before final release."
      properties:
        hdfsMetrics:
          additionalProperties:
            format: int64
            type: string
          description: The HDFS metrics.
          type: object
        yarnMetrics:
          additionalProperties:
            format: int64
            type: string
          description: The YARN metrics.
          type: object
      type: object
    ClusterOperation:
      description: The cluster operation triggered by a workflow.
      properties:
        done:
          description: Output only. Indicates the operation is done.
          type: boolean
        error:
          description: Output only. Error, if operation failed.
          type: string
        operationId:
          description: Output only. The id of the cluster operation.
          type: string
      type: object
    ClusterOperationMetadata:
      description: Metadata describing the operation.
      properties:
        clusterName:
          description: Output only. Name of the cluster for the operation.
          type: string
        clusterUuid:
          description: Output only. Cluster UUID for the operation.
          type: string
        description:
          description: Output only. Short description of operation.
          type: string
        labels:
          additionalProperties:
            type: string
          description: Output only. Labels associated with the operation
          type: object
        operationType:
          description: Output only. The operation type.
          type: string
        status:
          $ref: "#/components/schemas/ClusterOperationStatus"
        statusHistory:
          description: Output only. The previous operation status.
          items:
            $ref: "#/components/schemas/ClusterOperationStatus"
          type: array
        warnings:
          description: Output only. Errors encountered during operation execution.
          items:
            type: string
          type: array
      type: object
    ClusterOperationStatus:
      description: The status of the operation.
      properties:
        details:
          description: Output only. A message containing any operation metadata details.
          type: string
        innerState:
          description: Output only. A message containing the detailed operation state.
          type: string
        state:
          description: Output only. A message containing the operation state.
          enum:
            - UNKNOWN
            - PENDING
            - RUNNING
            - DONE
          type: string
        stateStartTime:
          description: Output only. The time this state was entered.
          format: google-datetime
          type: string
      type: object
    ClusterSelector:
      description: A selector that chooses target cluster for jobs based on metadata.
      properties:
        clusterLabels:
          additionalProperties:
            type: string
          description: Required. The cluster labels. Cluster must have all labels to match.
          type: object
        zone:
          description: Optional. The zone where workflow process executes. This parameter
            does not affect the selection of the cluster.If unspecified, the
            zone of the first cluster matching the selector is used.
          type: string
      type: object
    ClusterStatus:
      description: The status of a cluster and its instances.
      properties:
        detail:
          description: Output only. Optional details of cluster's state.
          type: string
        state:
          description: Output only. The cluster's state.
          enum:
            - UNKNOWN
            - CREATING
            - RUNNING
            - ERROR
            - DELETING
            - UPDATING
          type: string
        stateStartTime:
          description: Output only. Time when this state was entered.
          format: google-datetime
          type: string
        substate:
          description: Output only. Additional state information that includes status
            reported by the agent.
          enum:
            - UNSPECIFIED
            - UNHEALTHY
            - STALE_STATUS
          type: string
      type: object
    DiagnoseClusterRequest:
      description: A request to collect cluster diagnostic information.
      properties: {}
      type: object
    DiagnoseClusterResults:
      description: The location of diagnostic output.
      properties:
        outputUri:
          description: Output only. The Cloud Storage URI of the diagnostic output. The
            output report is a plain text file with a summary of collected
            diagnostics.
          type: string
      type: object
    DiskConfig:
      description: Specifies the config of disk options for a group of VM instances.
      properties:
        bootDiskSizeGb:
          description: Optional. Size in GB of the boot disk (default is 500GB).
          format: int32
          type: integer
        bootDiskType:
          description: 'Optional. Type of the boot disk (default is "pd-standard"). Valid
            values: "pd-ssd" (Persistent Disk Solid State Drive) or
            "pd-standard" (Persistent Disk Hard Disk Drive).'
          type: string
        numLocalSsds:
          description: Optional. Number of attached SSDs, from 0 to 4 (default is 0). If
            SSDs are not attached, the boot disk is used to store runtime logs
            and HDFS
            (https://hadoop.apache.org/docs/r1.2.1/hdfs_user_guide.html) data.
            If one or more SSDs are attached, this runtime bulk data is spread
            across them, and the boot disk contains only basic config and
            installed binaries.
          format: int32
          type: integer
      type: object
    Empty:
      description: >-
        A generic empty message that you can re-use to avoid defining duplicated
        empty messages in your APIs. A typical example is to use it as the
        request or the response type of an API method. For instance:

        service Foo {
          rpc Bar(google.protobuf.Empty) returns (google.protobuf.Empty);
        }

        The JSON representation for Empty is empty JSON object {}.
      properties: {}
      type: object
    EncryptionConfig:
      description: Encryption settings for the cluster.
      properties:
        gcePdKmsKeyName:
          description: Optional. The Cloud KMS key name to use for PD disk encryption for
            all instances in the cluster.
          type: string
      type: object
    Expr:
      description: |
        Represents an expression text. Example:
        title: "User account presence"
        description: "Determines whether the request has a user account"
        expression: "size(request.user) > 0"
      properties:
        description:
          description: An optional description of the expression. This is a longer text
            which describes the expression, e.g. when hovered over it in a UI.
          type: string
        expression:
          description: Textual representation of an expression in Common Expression
            Language syntax.The application context of the containing message
            determines which well-known feature set of CEL is supported.
          type: string
        location:
          description: An optional string indicating the location of the expression for
            error reporting, e.g. a file name and a position in the file.
          type: string
        title:
          description: An optional title for the expression, i.e. a short string describing
            its purpose. This can be used e.g. in UIs which allow to enter the
            expression.
          type: string
      type: object
    GceClusterConfig:
      description: Common config settings for resources of Compute Engine cluster
        instances, applicable to all instances in the cluster.
      properties:
        internalIpOnly:
          description: Optional. If true, all instances in the cluster will only have
            internal IP addresses. By default, clusters are not restricted to
            internal IP addresses, and will have ephemeral external IP addresses
            assigned to each instance. This internal_ip_only restriction can
            only be enabled for subnetwork enabled networks, and all off-cluster
            dependencies must be configured to be accessible without external IP
            addresses.
          type: boolean
        metadata:
          additionalProperties:
            type: string
          description: The Compute Engine metadata entries to add to all instances (see
            Project and instance metadata
            (https://cloud.google.com/compute/docs/storing-retrieving-metadata#project_and_instance_metadata)).
          type: object
        networkUri:
          description: >-
            Optional. The Compute Engine network to be used for machine
            communications. Cannot be specified with subnetwork_uri. If neither
            network_uri nor subnetwork_uri is specified, the "default" network
            of the project is used, if it exists. Cannot be a "Custom Subnet
            Network" (see Using Subnetworks for more information).A full URL,
            partial URI, or short name are valid. Examples:

            https://www.googleapis.com/compute/v1/projects/[project_id]/regions/global/default

            projects/[project_id]/regions/global/default

            default
          type: string
        serviceAccount:
          description: >-
            Optional. The service account of the instances. Defaults to the
            default Compute Engine service account. Custom service accounts need
            permissions equivalent to the following IAM roles:

            roles/logging.logWriter

            roles/storage.objectAdmin(see https://cloud.google.com/compute/docs/access/service-accounts#custom_service_accounts for more information). Example: [account_id]@[project_id].iam.gserviceaccount.com
          type: string
        serviceAccountScopes:
          description: >-
            Optional. The URIs of service account scopes to be included in
            Compute Engine instances. The following base set of scopes is always
            included:

            https://www.googleapis.com/auth/cloud.useraccounts.readonly

            https://www.googleapis.com/auth/devstorage.read_write

            https://www.googleapis.com/auth/logging.writeIf no scopes are specified, the following defaults are also provided:

            https://www.googleapis.com/auth/bigquery

            https://www.googleapis.com/auth/bigtable.admin.table

            https://www.googleapis.com/auth/bigtable.data

            https://www.googleapis.com/auth/devstorage.full_control
          items:
            type: string
          type: array
        subnetworkUri:
          description: >-
            Optional. The Compute Engine subnetwork to be used for machine
            communications. Cannot be specified with network_uri.A full URL,
            partial URI, or short name are valid. Examples:

            https://www.googleapis.com/compute/v1/projects/[project_id]/regions/us-east1/subnetworks/sub0

            projects/[project_id]/regions/us-east1/subnetworks/sub0

            sub0
          type: string
        tags:
          description: The Compute Engine tags to add to all instances (see Tagging
            instances).
          items:
            type: string
          type: array
        zoneUri:
          description: >-
            Optional. The zone where the Compute Engine cluster will be located.
            On a create request, it is required in the "global" region. If
            omitted in a non-global Cloud Dataproc region, the service will pick
            a zone in the corresponding Compute Engine region. On a get request,
            zone will always be present.A full URL, partial URI, or short name
            are valid. Examples:

            https://www.googleapis.com/compute/v1/projects/[project_id]/zones/[zone]

            projects/[project_id]/zones/[zone]

            us-central1-f
          type: string
      type: object
    GetIamPolicyRequest:
      description: Request message for GetIamPolicy method.
      properties:
        options:
          $ref: "#/components/schemas/GetPolicyOptions"
      type: object
    GetPolicyOptions:
      description: Encapsulates settings provided to GetIamPolicy.
      properties:
        requestedPolicyVersion:
          description: Optional. The policy format version to be returned.Valid values are
            0, 1, and 3. Requests specifying an invalid value will be
            rejected.Requests for policies with any conditional bindings must
            specify version 3. Policies without any conditional bindings may
            specify any valid value or leave the field unset.
          format: int32
          type: integer
      type: object
    HadoopJob:
      description: A Cloud Dataproc job for running Apache Hadoop MapReduce
        (https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html)
        jobs on Apache Hadoop YARN
        (https://hadoop.apache.org/docs/r2.7.1/hadoop-yarn/hadoop-yarn-site/YARN.html).
      properties:
        archiveUris:
          description: "Optional. HCFS URIs of archives to be extracted in the working
            directory of Hadoop drivers and tasks. Supported file types: .jar,
            .tar, .tar.gz, .tgz, or .zip."
          items:
            type: string
          type: array
        args:
          description: Optional. The arguments to pass to the driver. Do not include
            arguments, such as -libjars or -Dfoo=bar, that can be set as job
            properties, since a collision may occur that causes an incorrect job
            submission.
          items:
            type: string
          type: array
        fileUris:
          description: Optional. HCFS (Hadoop Compatible Filesystem) URIs of files to be
            copied to the working directory of Hadoop drivers and distributed
            tasks. Useful for naively parallel tasks.
          items:
            type: string
          type: array
        jarFileUris:
          description: Optional. Jar file URIs to add to the CLASSPATHs of the Hadoop
            driver and tasks.
          items:
            type: string
          type: array
        loggingConfig:
          $ref: "#/components/schemas/LoggingConfig"
        mainClass:
          description: The name of the driver's main class. The jar file containing the
            class must be in the default CLASSPATH or specified in
            jar_file_uris.
          type: string
        mainJarFileUri:
          description: "The HCFS URI of the jar file containing the main class.
            Examples:  'gs://foo-bucket/analytics-binaries/extract-useful-metri\
            cs-mr.jar'  'hdfs:/tmp/test-samples/custom-wordcount.jar'  'file://\
            /home/usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'"
          type: string
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names to values, used to configure
            Hadoop. Properties that conflict with values set by the Cloud
            Dataproc API may be overwritten. Can include properties set in
            /etc/hadoop/conf/*-site and classes in user code.
          type: object
      type: object
    HiveJob:
      description: A Cloud Dataproc job for running Apache Hive (https://hive.apache.org/)
        queries on YARN.
      properties:
        continueOnFailure:
          description: Optional. Whether to continue executing queries if a query fails.
            The default value is false. Setting to true can be useful when
            executing independent parallel queries.
          type: boolean
        jarFileUris:
          description: Optional. HCFS URIs of jar files to add to the CLASSPATH of the Hive
            server and Hadoop MapReduce (MR) tasks. Can contain Hive SerDes and
            UDFs.
          items:
            type: string
          type: array
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names and values, used to configure
            Hive. Properties that conflict with values set by the Cloud Dataproc
            API may be overwritten. Can include properties set in
            /etc/hadoop/conf/*-site.xml, /etc/hive/conf/hive-site.xml, and
            classes in user code.
          type: object
        queryFileUri:
          description: The HCFS URI of the script that contains Hive queries.
          type: string
        queryList:
          $ref: "#/components/schemas/QueryList"
        scriptVariables:
          additionalProperties:
            type: string
          description: 'Optional. Mapping of query variable names to values (equivalent to
            the Hive command: SET name="value";).'
          type: object
      type: object
    InstanceGroupAutoscalingPolicyConfig:
      description: Configuration for the size bounds of an instance group, including its
        proportional size to other groups.
      properties:
        maxInstances:
          description: "Optional. Maximum number of instances for this group. Required for
            primary workers. Note that by default, clusters will not use
            secondary workers. Required for secondary workers if the minimum
            secondary instances is set.Primary workers - Bounds: [min_instances,
            ). Required. Secondary workers - Bounds: [min_instances, ). Default:
            0."
          format: int32
          type: integer
        minInstances:
          description: "Optional. Minimum number of instances for this group.Primary
            workers - Bounds: 2, max_instances. Default: 2. Secondary workers -
            Bounds: 0, max_instances. Default: 0."
          format: int32
          type: integer
        weight:
          description: "Optional. Weight for the instance group, which is used to determine
            the fraction of total workers in the cluster from this instance
            group. For example, if primary workers have weight 2, and secondary
            workers have weight 1, the cluster will have approximately 2 primary
            workers for each secondary worker.The cluster may not reach the
            specified balance if constrained by min/max bounds or other
            autoscaling settings. For example, if max_instances for secondary
            workers is 0, then only primary workers will be added. The cluster
            can also be out of balance when created.If weight is not set on any
            instance group, the cluster will default to equal weight for all
            groups: the cluster will attempt to maintain an equal number of
            workers in each group within the configured size bounds for each
            group. If weight is set for one group only, the cluster will default
            to zero weight on the unset group. For example if weight is set only
            on primary workers, the cluster will use primary workers only and no
            secondary workers."
          format: int32
          type: integer
      type: object
    InstanceGroupConfig:
      description: Optional. The config settings for Compute Engine resources in an
        instance group, such as a master or worker group.
      properties:
        accelerators:
          description: "Optional. The Compute Engine accelerator configuration for these
            instances.Beta Feature: This feature is still under development. It
            may be changed before final release."
          items:
            $ref: "#/components/schemas/AcceleratorConfig"
          type: array
        diskConfig:
          $ref: "#/components/schemas/DiskConfig"
        imageUri:
          description: Optional. The Compute Engine image resource used for cluster
            instances. It can be specified or may be inferred from
            SoftwareConfig.image_version.
          type: string
        instanceNames:
          description: Output only. The list of instance names. Cloud Dataproc derives the
            names from cluster_name, num_instances, and the instance group.
          items:
            type: string
          type: array
        isPreemptible:
          description: Optional. Specifies that this instance group contains preemptible
            instances.
          type: boolean
        machineTypeUri:
          description: >-
            Optional. The Compute Engine machine type used for cluster
            instances.A full URL, partial URI, or short name are valid.
            Examples:

            https://www.googleapis.com/compute/v1/projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2

            projects/[project_id]/zones/us-east1-a/machineTypes/n1-standard-2

            n1-standard-2Auto Zone Exception: If you are using the Cloud Dataproc Auto Zone Placement feature, you must use the short name of the machine type resource, for example, n1-standard-2.
          type: string
        managedGroupConfig:
          $ref: "#/components/schemas/ManagedGroupConfig"
        numInstances:
          description: Optional. The number of VM instances in the instance group. For
            master instance groups, must be set to 1.
          format: int32
          type: integer
      type: object
    InstantiateWorkflowTemplateRequest:
      description: A request to instantiate a workflow template.
      properties:
        parameters:
          additionalProperties:
            type: string
          description: Optional. Map from parameter names to values that should be used for
            those parameters. Values may not exceed 100 characters.
          type: object
        requestId:
          description: Optional. A tag that prevents multiple concurrent workflow instances
            with the same tag from running. This mitigates risk of concurrent
            instances started due to retries.It is recommended to always set
            this value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The
            tag must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          type: string
        version:
          description: Optional. The version of workflow template to instantiate. If
            specified, the workflow will be instantiated only if the current
            version of the workflow template has the supplied version.This
            option cannot be used to instantiate a previous version of workflow
            template.
          format: int32
          type: integer
      type: object
    Job:
      description: A Cloud Dataproc job resource.
      properties:
        driverControlFilesUri:
          description: Output only. If present, the location of miscellaneous control files
            which may be used as part of job setup and handling. If not present,
            control files may be placed in the same location as
            driver_output_uri.
          type: string
        driverOutputResourceUri:
          description: Output only. A URI pointing to the location of the stdout of the
            job's driver program.
          type: string
        hadoopJob:
          $ref: "#/components/schemas/HadoopJob"
        hiveJob:
          $ref: "#/components/schemas/HiveJob"
        jobUuid:
          description: Output only. A UUID that uniquely identifies a job within the
            project over time. This is in contrast to a user-settable
            reference.job_id that may be reused over time.
          type: string
        labels:
          additionalProperties:
            type: string
          description: Optional. The labels to associate with this job. Label keys must
            contain 1 to 63 characters, and must conform to RFC 1035
            (https://www.ietf.org/rfc/rfc1035.txt). Label values may be empty,
            but, if present, must contain 1 to 63 characters, and must conform
            to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt). No more than 32
            labels can be associated with a job.
          type: object
        pigJob:
          $ref: "#/components/schemas/PigJob"
        placement:
          $ref: "#/components/schemas/JobPlacement"
        pysparkJob:
          $ref: "#/components/schemas/PySparkJob"
        reference:
          $ref: "#/components/schemas/JobReference"
        scheduling:
          $ref: "#/components/schemas/JobScheduling"
        sparkJob:
          $ref: "#/components/schemas/SparkJob"
        sparkSqlJob:
          $ref: "#/components/schemas/SparkSqlJob"
        status:
          $ref: "#/components/schemas/JobStatus"
        statusHistory:
          description: Output only. The previous job status.
          items:
            $ref: "#/components/schemas/JobStatus"
          type: array
        yarnApplications:
          description: "Output only. The collection of YARN applications spun up by this
            job.Beta Feature: This report is available for testing purposes
            only. It may be changed before final release."
          items:
            $ref: "#/components/schemas/YarnApplication"
          type: array
      type: object
    JobPlacement:
      description: Cloud Dataproc job config.
      properties:
        clusterName:
          description: Required. The name of the cluster where the job will be submitted.
          type: string
        clusterUuid:
          description: Output only. A cluster UUID generated by the Cloud Dataproc service
            when the job is submitted.
          type: string
      type: object
    JobReference:
      description: Encapsulates the full scoping used to reference a job.
      properties:
        jobId:
          description: Optional. The job ID, which must be unique within the project.The ID
            must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), or hyphens (-). The maximum length is 100 characters.If not
            specified by the caller, the job ID will be provided by the server.
          type: string
        projectId:
          description: Required. The ID of the Google Cloud Platform project that the job
            belongs to.
          type: string
      type: object
    JobScheduling:
      description: Job scheduling options.
      properties:
        maxFailuresPerHour:
          description: Optional. Maximum number of times per hour a driver may be restarted
            as a result of driver terminating with non-zero code before job is
            reported failed.A job may be reported as thrashing if driver exits
            with non-zero code 4 times within 10 minute window.Maximum value is
            10.
          format: int32
          type: integer
      type: object
    JobStatus:
      description: Cloud Dataproc job status.
      properties:
        details:
          description: Output only. Optional job state details, such as an error
            description if the state is <code>ERROR</code>.
          type: string
        state:
          description: Output only. A state message specifying the overall job state.
          enum:
            - STATE_UNSPECIFIED
            - PENDING
            - SETUP_DONE
            - RUNNING
            - CANCEL_PENDING
            - CANCEL_STARTED
            - CANCELLED
            - DONE
            - ERROR
            - ATTEMPT_FAILURE
          type: string
        stateStartTime:
          description: Output only. The time when this state was entered.
          format: google-datetime
          type: string
        substate:
          description: Output only. Additional state information, which includes status
            reported by the agent.
          enum:
            - UNSPECIFIED
            - SUBMITTED
            - QUEUED
            - STALE_STATUS
          type: string
      type: object
    KerberosConfig:
      description: Specifies Kerberos related configuration.
      properties:
        crossRealmTrustAdminServer:
          description: Optional. The admin server (IP or hostname) for the remote trusted
            realm in a cross realm trust relationship.
          type: string
        crossRealmTrustKdc:
          description: Optional. The KDC (IP or hostname) for the remote trusted realm in a
            cross realm trust relationship.
          type: string
        crossRealmTrustRealm:
          description: Optional. The remote realm the Dataproc on-cluster KDC will trust,
            should the user enable cross realm trust.
          type: string
        crossRealmTrustSharedPasswordUri:
          description: Optional. The Cloud Storage URI of a KMS encrypted file containing
            the shared password between the on-cluster Kerberos realm and the
            remote trusted realm, in a cross realm trust relationship.
          type: string
        enableKerberos:
          description: Optional. Flag to indicate whether to Kerberize the cluster.
          type: boolean
        kdcDbKeyUri:
          description: Optional. The Cloud Storage URI of a KMS encrypted file containing
            the master key of the KDC database.
          type: string
        keyPasswordUri:
          description: Optional. The Cloud Storage URI of a KMS encrypted file containing
            the password to the user provided key. For the self-signed
            certificate, this password is generated by Dataproc.
          type: string
        keystorePasswordUri:
          description: Optional. The Cloud Storage URI of a KMS encrypted file containing
            the password to the user provided keystore. For the self-signed
            certificate, this password is generated by Dataproc.
          type: string
        keystoreUri:
          description: Optional. The Cloud Storage URI of the keystore file used for SSL
            encryption. If not provided, Dataproc will provide a self-signed
            certificate.
          type: string
        kmsKeyUri:
          description: Required. The uri of the KMS key used to encrypt various sensitive
            files.
          type: string
        realm:
          description: Optional. The name of the on-cluster Kerberos realm. If not
            specified, the uppercased domain of hostnames will be the realm.
          type: string
        rootPrincipalPasswordUri:
          description: Required. The Cloud Storage URI of a KMS encrypted file containing
            the root principal password.
          type: string
        tgtLifetimeHours:
          description: Optional. The lifetime of the ticket granting ticket, in hours. If
            not specified, or user specifies 0, then default value 10 will be
            used.
          format: int32
          type: integer
        truststorePasswordUri:
          description: Optional. The Cloud Storage URI of a KMS encrypted file containing
            the password to the user provided truststore. For the self-signed
            certificate, this password is generated by Dataproc.
          type: string
        truststoreUri:
          description: Optional. The Cloud Storage URI of the truststore file used for SSL
            encryption. If not provided, Dataproc will provide a self-signed
            certificate.
          type: string
      type: object
    LifecycleConfig:
      description: Specifies the cluster auto-delete schedule configuration.
      properties:
        autoDeleteTime:
          description: Optional. The time when cluster will be auto-deleted.
          format: google-datetime
          type: string
        autoDeleteTtl:
          description: 'Optional. The lifetime duration of cluster. The cluster will be
            auto-deleted at the end of this period. Valid range: 10m,
            14d.Example: "1d", to delete the cluster 1 day after its creation..'
          format: google-duration
          type: string
        idleDeleteTtl:
          description: 'Optional. The duration to keep the cluster alive while idling.
            Passing this threshold will cause the cluster to be deleted. Valid
            range: 10m, 14d.Example: "10m", the minimum value, to delete the
            cluster when it has had no jobs running for 10 minutes.'
          format: google-duration
          type: string
        idleStartTime:
          description: Output only. The time when cluster became idle (most recent job
            finished) and became eligible for deletion due to idleness.
          format: google-datetime
          type: string
      type: object
    ListAutoscalingPoliciesResponse:
      description: A response to a request to list autoscaling policies in a project.
      properties:
        nextPageToken:
          description: Output only. This token is included in the response if there are
            more results to fetch.
          type: string
        policies:
          description: Output only. Autoscaling policies list.
          items:
            $ref: "#/components/schemas/AutoscalingPolicy"
          type: array
      type: object
    ListClustersResponse:
      description: The list of all clusters in a project.
      properties:
        clusters:
          description: Output only. The clusters in the project.
          items:
            $ref: "#/components/schemas/Cluster"
          type: array
        nextPageToken:
          description: Output only. This token is included in the response if there are
            more results to fetch. To fetch additional results, provide this
            value as the page_token in a subsequent ListClustersRequest.
          type: string
      type: object
    ListJobsResponse:
      description: A list of jobs in a project.
      properties:
        jobs:
          description: Output only. Jobs list.
          items:
            $ref: "#/components/schemas/Job"
          type: array
        nextPageToken:
          description: Optional. This token is included in the response if there are more
            results to fetch. To fetch additional results, provide this value as
            the page_token in a subsequent <code>ListJobsRequest</code>.
          type: string
      type: object
    ListOperationsResponse:
      description: The response message for Operations.ListOperations.
      properties:
        nextPageToken:
          description: The standard List next-page token.
          type: string
        operations:
          description: A list of operations that matches the specified filter in the
            request.
          items:
            $ref: "#/components/schemas/Operation"
          type: array
      type: object
    ListWorkflowTemplatesResponse:
      description: A response to a request to list workflow templates in a project.
      properties:
        nextPageToken:
          description: Output only. This token is included in the response if there are
            more results to fetch. To fetch additional results, provide this
            value as the page_token in a subsequent
            <code>ListWorkflowTemplatesRequest</code>.
          type: string
        templates:
          description: Output only. WorkflowTemplates list.
          items:
            $ref: "#/components/schemas/WorkflowTemplate"
          type: array
      type: object
    LoggingConfig:
      description: The runtime logging config of the job.
      properties:
        driverLogLevels:
          additionalProperties:
            enum:
              - LEVEL_UNSPECIFIED
              - ALL
              - TRACE
              - DEBUG
              - INFO
              - WARN
              - ERROR
              - FATAL
              - OFF
            type: string
          description: "The per-package log levels for the driver. This may include
            \"root\" package name to configure rootLogger.
            Examples:  'com.google = FATAL', 'root = INFO', 'org.apache =
            DEBUG'"
          type: object
      type: object
    ManagedCluster:
      description: Cluster that is managed by the workflow.
      properties:
        clusterName:
          description: Required. The cluster name prefix. A unique cluster name will be
            formed by appending a random suffix.The name must contain only
            lower-case letters (a-z), numbers (0-9), and hyphens (-). Must begin
            with a letter. Cannot begin or end with hyphen. Must consist of
            between 2 and 35 characters.
          type: string
        config:
          $ref: "#/components/schemas/ClusterConfig"
        labels:
          additionalProperties:
            type: string
          description: "Optional. The labels to associate with this cluster.Label keys must
            be between 1 and 63 characters long, and must conform to the
            following PCRE regular expression: \\p{Ll}\\p{Lo}{0,62}Label values
            must be between 1 and 63 characters long, and must conform to the
            following PCRE regular expression: \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No
            more than 32 labels can be associated with a given cluster."
          type: object
      type: object
    ManagedGroupConfig:
      description: Specifies the resources used to actively manage an instance group.
      properties:
        instanceGroupManagerName:
          description: Output only. The name of the Instance Group Manager for this group.
          type: string
        instanceTemplateName:
          description: Output only. The name of the Instance Template used for the Managed
            Instance Group.
          type: string
      type: object
    NodeInitializationAction:
      description: Specifies an executable to run on a fully configured node and a timeout
        period for executable completion.
      properties:
        executableFile:
          description: Required. Cloud Storage URI of executable file.
          type: string
        executionTimeout:
          description: Optional. Amount of time executable has to complete. Default is 10
            minutes. Cluster creation fails with an explanatory error message
            (the name of the executable that caused the error and the exceeded
            timeout period) if the executable is not completed at end of the
            timeout period.
          format: google-duration
          type: string
      type: object
    Operation:
      description: This resource represents a long-running operation that is the result of
        a network API call.
      properties:
        done:
          description: If the value is false, it means the operation is still in progress.
            If true, the operation is completed, and either error or response is
            available.
          type: boolean
        error:
          $ref: "#/components/schemas/Status"
        metadata:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: Service-specific metadata associated with the operation. It
            typically contains progress information and common metadata such as
            create time. Some services might not provide such metadata. Any
            method that returns a long-running operation should document the
            metadata type, if any.
          type: object
        name:
          description: The server-assigned name, which is only unique within the same
            service that originally returns it. If you use the default HTTP
            mapping, the name should be a resource name ending with
            operations/{unique_id}.
          type: string
        response:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: The normal response of the operation in case of success. If the
            original method returns no data on success, such as Delete, the
            response is google.protobuf.Empty. If the original method is
            standard Get/Create/Update, the response should be the resource. For
            other methods, the response should have the type XxxResponse, where
            Xxx is the original method name. For example, if the original method
            name is TakeSnapshot(), the inferred response type is
            TakeSnapshotResponse.
          type: object
      type: object
    OrderedJob:
      description: A job executed by the workflow.
      properties:
        hadoopJob:
          $ref: "#/components/schemas/HadoopJob"
        hiveJob:
          $ref: "#/components/schemas/HiveJob"
        labels:
          additionalProperties:
            type: string
          description: "Optional. The labels to associate with this job.Label keys must be
            between 1 and 63 characters long, and must conform to the following
            regular expression: \\p{Ll}\\p{Lo}{0,62}Label values must be between
            1 and 63 characters long, and must conform to the following regular
            expression: \\p{Ll}\\p{Lo}\\p{N}_-{0,63}No more than 32 labels can
            be associated with a given job."
          type: object
        pigJob:
          $ref: "#/components/schemas/PigJob"
        prerequisiteStepIds:
          description: Optional. The optional list of prerequisite job step_ids. If not
            specified, the job will start at the beginning of workflow.
          items:
            type: string
          type: array
        pysparkJob:
          $ref: "#/components/schemas/PySparkJob"
        scheduling:
          $ref: "#/components/schemas/JobScheduling"
        sparkJob:
          $ref: "#/components/schemas/SparkJob"
        sparkSqlJob:
          $ref: "#/components/schemas/SparkSqlJob"
        stepId:
          description: Required. The step id. The id must be unique among all jobs within
            the template.The step id is used as prefix for job id, as job
            goog-dataproc-workflow-step-id label, and in prerequisiteStepIds
            field from other steps.The id must contain only letters (a-z, A-Z),
            numbers (0-9), underscores (_), and hyphens (-). Cannot begin or end
            with underscore or hyphen. Must consist of between 3 and 50
            characters.
          type: string
      type: object
    ParameterValidation:
      description: Configuration for parameter validation.
      properties:
        regex:
          $ref: "#/components/schemas/RegexValidation"
        values:
          $ref: "#/components/schemas/ValueValidation"
      type: object
    PigJob:
      description: A Cloud Dataproc job for running Apache Pig (https://pig.apache.org/)
        queries on YARN.
      properties:
        continueOnFailure:
          description: Optional. Whether to continue executing queries if a query fails.
            The default value is false. Setting to true can be useful when
            executing independent parallel queries.
          type: boolean
        jarFileUris:
          description: Optional. HCFS URIs of jar files to add to the CLASSPATH of the Pig
            Client and Hadoop MapReduce (MR) tasks. Can contain Pig UDFs.
          items:
            type: string
          type: array
        loggingConfig:
          $ref: "#/components/schemas/LoggingConfig"
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names to values, used to configure
            Pig. Properties that conflict with values set by the Cloud Dataproc
            API may be overwritten. Can include properties set in
            /etc/hadoop/conf/*-site.xml, /etc/pig/conf/pig.properties, and
            classes in user code.
          type: object
        queryFileUri:
          description: The HCFS URI of the script that contains the Pig queries.
          type: string
        queryList:
          $ref: "#/components/schemas/QueryList"
        scriptVariables:
          additionalProperties:
            type: string
          description: "Optional. Mapping of query variable names to values (equivalent to
            the Pig command: name=[value])."
          type: object
      type: object
    Policy:
      description: >-
        Defines an Identity and Access Management (IAM) policy. It is used to
        specify access control policies for Cloud Platform resources.A Policy
        consists of a list of bindings. A binding binds a list of members to a
        role, where the members can be user accounts, Google groups, Google
        domains, and service accounts. A role is a named list of permissions
        defined by IAM.JSON Example

        {
          "bindings": [
            {
              "role": "roles/owner",
              "members": [
                "user:mike@example.com",
                "group:admins@example.com",
                "domain:google.com",
                "serviceAccount:my-other-app@appspot.gserviceaccount.com"
              ]
            },
            {
              "role": "roles/viewer",
              "members": ["user:sean@example.com"]
            }
          ]
        }

        YAML Example

        bindings:

        - members:
          - user:mike@example.com
          - group:admins@example.com
          - domain:google.com
          - serviceAccount:my-other-app@appspot.gserviceaccount.com
          role: roles/owner
        - members:
          - user:sean@example.com
          role: roles/viewer
        For a description of IAM and its features, see the IAM developer's guide (https://cloud.google.com/iam/docs).
      properties:
        bindings:
          description: Associates a list of members to a role. bindings with no members
            will result in an error.
          items:
            $ref: "#/components/schemas/Binding"
          type: array
        etag:
          description: "etag is used for optimistic concurrency control as a way to help
            prevent simultaneous updates of a policy from overwriting each
            other. It is strongly suggested that systems make use of the etag in
            the read-modify-write cycle to perform policy updates in order to
            avoid race conditions: An etag is returned in the response to
            getIamPolicy, and systems are expected to put that etag in the
            request to setIamPolicy to ensure that their change will be applied
            to the same version of the policy.If no etag is provided in the call
            to setIamPolicy, then the existing policy is overwritten."
          format: byte
          type: string
        version:
          description: Specifies the format of the policy.Valid values are 0, 1, and 3.
            Requests specifying an invalid value will be rejected.Policies with
            any conditional bindings must specify version 3. Policies without
            any conditional bindings may specify any valid value or leave the
            field unset.
          format: int32
          type: integer
      type: object
    PySparkJob:
      description: A Cloud Dataproc job for running Apache PySpark
        (https://spark.apache.org/docs/0.9.0/python-programming-guide.html)
        applications on YARN.
      properties:
        archiveUris:
          description: Optional. HCFS URIs of archives to be extracted in the working
            directory of .jar, .tar, .tar.gz, .tgz, and .zip.
          items:
            type: string
          type: array
        args:
          description: Optional. The arguments to pass to the driver. Do not include
            arguments, such as --conf, that can be set as job properties, since
            a collision may occur that causes an incorrect job submission.
          items:
            type: string
          type: array
        fileUris:
          description: Optional. HCFS URIs of files to be copied to the working directory
            of Python drivers and distributed tasks. Useful for naively parallel
            tasks.
          items:
            type: string
          type: array
        jarFileUris:
          description: Optional. HCFS URIs of jar files to add to the CLASSPATHs of the
            Python driver and tasks.
          items:
            type: string
          type: array
        loggingConfig:
          $ref: "#/components/schemas/LoggingConfig"
        mainPythonFileUri:
          description: Required. The HCFS URI of the main Python file to use as the driver.
            Must be a .py file.
          type: string
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names to values, used to configure
            PySpark. Properties that conflict with values set by the Cloud
            Dataproc API may be overwritten. Can include properties set in
            /etc/spark/conf/spark-defaults.conf and classes in user code.
          type: object
        pythonFileUris:
          description: "Optional. HCFS file URIs of Python files to pass to the PySpark
            framework. Supported file types: .py, .egg, and .zip."
          items:
            type: string
          type: array
      type: object
    QueryList:
      description: A list of queries to run on a cluster.
      properties:
        queries:
          description: >
            Required. The queries to execute. You do not need to terminate a
            query with a semicolon. Multiple queries can be specified in one
            string by separating each with a semicolon. Here is an example of an
            Cloud Dataproc API snippet that uses a QueryList to specify a
            HiveJob:

            "hiveJob": {
              "queryList": {
                "queries": [
                  "query1",
                  "query2",
                  "query3;query4",
                ]
              }
            }
          items:
            type: string
          type: array
      type: object
    RegexValidation:
      description: Validation based on regular expressions.
      properties:
        regexes:
          description: Required. RE2 regular expressions used to validate the parameter's
            value. The value must match the regex in its entirety (substring
            matches are not sufficient).
          items:
            type: string
          type: array
      type: object
    SecurityConfig:
      description: Security related configuration, including Kerberos.
      properties:
        kerberosConfig:
          $ref: "#/components/schemas/KerberosConfig"
      type: object
    SetIamPolicyRequest:
      description: Request message for SetIamPolicy method.
      properties:
        policy:
          $ref: "#/components/schemas/Policy"
      type: object
    SoftwareConfig:
      description: Specifies the selection and config of software inside the cluster.
      properties:
        imageVersion:
          description: Optional. The version of software inside the cluster. It must be one
            of the supported Cloud Dataproc Versions, such as "1.2" (including a
            subminor version, such as "1.2.29"), or the "preview" version. If
            unspecified, it defaults to the latest Debian version.
          type: string
        optionalComponents:
          description: The set of optional components to activate on the cluster.
          items:
            enum:
              - COMPONENT_UNSPECIFIED
              - ANACONDA
              - HIVE_WEBHCAT
              - JUPYTER
              - ZEPPELIN
            type: string
          type: array
        properties:
          additionalProperties:
            type: string
          description: >-
            Optional. The properties to set on daemon config files.Property keys
            are specified in prefix:property format, for example
            core:hadoop.tmp.dir. The following are supported prefixes and their
            mappings:

            capacity-scheduler: capacity-scheduler.xml

            core: core-site.xml

            distcp: distcp-default.xml

            hdfs: hdfs-site.xml

            hive: hive-site.xml

            mapred: mapred-site.xml

            pig: pig.properties

            spark: spark-defaults.conf

            yarn: yarn-site.xmlFor more information, see Cluster properties.
          type: object
      type: object
    SparkJob:
      description: A Cloud Dataproc job for running Apache Spark (http://spark.apache.org/)
        applications on YARN.
      properties:
        archiveUris:
          description: "Optional. HCFS URIs of archives to be extracted in the working
            directory of Spark drivers and tasks. Supported file types: .jar,
            .tar, .tar.gz, .tgz, and .zip."
          items:
            type: string
          type: array
        args:
          description: Optional. The arguments to pass to the driver. Do not include
            arguments, such as --conf, that can be set as job properties, since
            a collision may occur that causes an incorrect job submission.
          items:
            type: string
          type: array
        fileUris:
          description: Optional. HCFS URIs of files to be copied to the working directory
            of Spark drivers and distributed tasks. Useful for naively parallel
            tasks.
          items:
            type: string
          type: array
        jarFileUris:
          description: Optional. HCFS URIs of jar files to add to the CLASSPATHs of the
            Spark driver and tasks.
          items:
            type: string
          type: array
        loggingConfig:
          $ref: "#/components/schemas/LoggingConfig"
        mainClass:
          description: The name of the driver's main class. The jar file that contains the
            class must be in the default CLASSPATH or specified in
            jar_file_uris.
          type: string
        mainJarFileUri:
          description: The HCFS URI of the jar file that contains the main class.
          type: string
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names to values, used to configure
            Spark. Properties that conflict with values set by the Cloud
            Dataproc API may be overwritten. Can include properties set in
            /etc/spark/conf/spark-defaults.conf and classes in user code.
          type: object
      type: object
    SparkSqlJob:
      description: A Cloud Dataproc job for running Apache Spark SQL
        (http://spark.apache.org/sql/) queries.
      properties:
        jarFileUris:
          description: Optional. HCFS URIs of jar files to be added to the Spark CLASSPATH.
          items:
            type: string
          type: array
        loggingConfig:
          $ref: "#/components/schemas/LoggingConfig"
        properties:
          additionalProperties:
            type: string
          description: Optional. A mapping of property names to values, used to configure
            Spark SQL's SparkConf. Properties that conflict with values set by
            the Cloud Dataproc API may be overwritten.
          type: object
        queryFileUri:
          description: The HCFS URI of the script that contains SQL queries.
          type: string
        queryList:
          $ref: "#/components/schemas/QueryList"
        scriptVariables:
          additionalProperties:
            type: string
          description: 'Optional. Mapping of query variable names to values (equivalent to
            the Spark SQL command: SET name="value";).'
          type: object
      type: object
    Status:
      description: "The Status type defines a logical error model that is suitable for
        different programming environments, including REST APIs and RPC APIs. It
        is used by gRPC (https://github.com/grpc). Each Status message contains
        three pieces of data: error code, error message, and error details.You
        can find out more about this error model and how to work with it in the
        API Design Guide (https://cloud.google.com/apis/design/errors)."
      properties:
        code:
          description: The status code, which should be an enum value of google.rpc.Code.
          format: int32
          type: integer
        details:
          description: A list of messages that carry the error details. There is a common
            set of message types for APIs to use.
          items:
            additionalProperties:
              description: Properties of the object. Contains field @type with type URL.
            type: object
          type: array
        message:
          description: A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
          type: string
      type: object
    SubmitJobRequest:
      description: A request to submit a job.
      properties:
        job:
          $ref: "#/components/schemas/Job"
        requestId:
          description: Optional. A unique id used to identify the request. If the server
            receives two SubmitJobRequest requests with the same id, then the
            second request will be ignored and the first Job created and stored
            in the backend is returned.It is recommended to always set this
            value to a UUID
            (https://en.wikipedia.org/wiki/Universally_unique_identifier).The id
            must contain only letters (a-z, A-Z), numbers (0-9), underscores
            (_), and hyphens (-). The maximum length is 40 characters.
          type: string
      type: object
    TemplateParameter:
      description: "A configurable parameter that replaces one or more fields in the
        template. Parameterizable fields: - Labels - File uris - Job properties
        - Job arguments - Script variables - Main class (in HadoopJob and
        SparkJob) - Zone (in ClusterSelector)"
      properties:
        description:
          description: Optional. Brief description of the parameter. Must not exceed 1024
            characters.
          type: string
        fields:
          description: >-
            Required. Paths to all fields that the parameter replaces. A field
            is allowed to appear in at most one parameter's list of field
            paths.A field path is similar in syntax to a
            google.protobuf.FieldMask. For example, a field path that references
            the zone field of a workflow template's cluster selector would be
            specified as placement.clusterSelector.zone.Also, field paths can
            reference fields using the following syntax:

            Values in maps can be referenced by key:

            labels'key'

            placement.clusterSelector.clusterLabels'key'

            placement.managedCluster.labels'key'

            placement.clusterSelector.clusterLabels'key'

            jobs'step-id'.labels'key'

            Jobs in the jobs list can be referenced by step-id:

            jobs'step-id'.hadoopJob.mainJarFileUri

            jobs'step-id'.hiveJob.queryFileUri

            jobs'step-id'.pySparkJob.mainPythonFileUri

            jobs'step-id'.hadoopJob.jarFileUris0

            jobs'step-id'.hadoopJob.archiveUris0

            jobs'step-id'.hadoopJob.fileUris0

            jobs'step-id'.pySparkJob.pythonFileUris0

            Items in repeated fields can be referenced by a zero-based index:

            jobs'step-id'.sparkJob.args0

            Other examples:

            jobs'step-id'.hadoopJob.properties'key'

            jobs'step-id'.hadoopJob.args0

            jobs'step-id'.hiveJob.scriptVariables'key'

            jobs'step-id'.hadoopJob.mainJarFileUri

            placement.clusterSelector.zoneIt may not be possible to parameterize maps and repeated fields in their entirety since only individual map values and individual items in repeated fields can be referenced. For example, the following field paths are invalid:

            placement.clusterSelector.clusterLabels

            jobs'step-id'.sparkJob.args
          items:
            type: string
          type: array
        name:
          description: Required. Parameter name. The parameter name is used as the key, and
            paired with the parameter value, which are passed to the template
            when the template is instantiated. The name must contain only
            capital letters (A-Z), numbers (0-9), and underscores (_), and must
            not start with a number. The maximum length is 40 characters.
          type: string
        validation:
          $ref: "#/components/schemas/ParameterValidation"
      type: object
    TestIamPermissionsRequest:
      description: Request message for TestIamPermissions method.
      properties:
        permissions:
          description: The set of permissions to check for the resource. Permissions with
            wildcards (such as '*' or 'storage.*') are not allowed. For more
            information see IAM Overview
            (https://cloud.google.com/iam/docs/overview#permissions).
          items:
            type: string
          type: array
      type: object
    TestIamPermissionsResponse:
      description: Response message for TestIamPermissions method.
      properties:
        permissions:
          description: A subset of TestPermissionsRequest.permissions that the caller is
            allowed.
          items:
            type: string
          type: array
      type: object
    ValueValidation:
      description: Validation based on a list of allowed values.
      properties:
        values:
          description: Required. List of allowed values for the parameter.
          items:
            type: string
          type: array
      type: object
    WorkflowGraph:
      description: The workflow graph.
      properties:
        nodes:
          description: Output only. The workflow nodes.
          items:
            $ref: "#/components/schemas/WorkflowNode"
          type: array
      type: object
    WorkflowMetadata:
      description: A Cloud Dataproc workflow template resource.
      properties:
        clusterName:
          description: Output only. The name of the target cluster.
          type: string
        clusterUuid:
          description: Output only. The UUID of target cluster.
          type: string
        createCluster:
          $ref: "#/components/schemas/ClusterOperation"
        deleteCluster:
          $ref: "#/components/schemas/ClusterOperation"
        endTime:
          description: Output only. Workflow end time.
          format: google-datetime
          type: string
        graph:
          $ref: "#/components/schemas/WorkflowGraph"
        parameters:
          additionalProperties:
            type: string
          description: Map from parameter names to values that were used for those
            parameters.
          type: object
        startTime:
          description: Output only. Workflow start time.
          format: google-datetime
          type: string
        state:
          description: Output only. The workflow state.
          enum:
            - UNKNOWN
            - PENDING
            - RUNNING
            - DONE
          type: string
        template:
          description: >-
            Output only. The resource name of the workflow template as described
            in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          type: string
        version:
          description: Output only. The version of template at the time of workflow
            instantiation.
          format: int32
          type: integer
      type: object
    WorkflowNode:
      description: The workflow node.
      properties:
        error:
          description: Output only. The error detail.
          type: string
        jobId:
          description: Output only. The job id; populated after the node enters RUNNING
            state.
          type: string
        prerequisiteStepIds:
          description: Output only. Node's prerequisite nodes.
          items:
            type: string
          type: array
        state:
          description: Output only. The node state.
          enum:
            - NODE_STATE_UNSPECIFIED
            - BLOCKED
            - RUNNABLE
            - RUNNING
            - COMPLETED
            - FAILED
          type: string
        stepId:
          description: Output only. The name of the node.
          type: string
      type: object
    WorkflowTemplate:
      description: A Cloud Dataproc workflow template resource.
      properties:
        createTime:
          description: Output only. The time template was created.
          format: google-datetime
          type: string
        id:
          description: Required. The template id.The id must contain only letters (a-z,
            A-Z), numbers (0-9), underscores (_), and hyphens (-). Cannot begin
            or end with underscore or hyphen. Must consist of between 3 and 50
            characters.
          type: string
        jobs:
          description: Required. The Directed Acyclic Graph of Jobs to submit.
          items:
            $ref: "#/components/schemas/OrderedJob"
          type: array
        labels:
          additionalProperties:
            type: string
          description: Optional. The labels to associate with this template. These labels
            will be propagated to all jobs and clusters created by the workflow
            instance.Label keys must contain 1 to 63 characters, and must
            conform to RFC 1035 (https://www.ietf.org/rfc/rfc1035.txt).Label
            values may be empty, but, if present, must contain 1 to 63
            characters, and must conform to RFC 1035
            (https://www.ietf.org/rfc/rfc1035.txt).No more than 32 labels can be
            associated with a template.
          type: object
        name:
          description: >-
            Output only. The resource name of the workflow template, as
            described in https://cloud.google.com/apis/design/resource_names.

            For projects.regions.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/regions/{region}/workflowTemplates/{template_id}

            For projects.locations.workflowTemplates, the resource name of the  template has the following format:  projects/{project_id}/locations/{location}/workflowTemplates/{template_id}
          type: string
        parameters:
          description: Optional. Template parameters whose values are substituted into the
            template. Values for parameters must be provided when the template
            is instantiated.
          items:
            $ref: "#/components/schemas/TemplateParameter"
          type: array
        placement:
          $ref: "#/components/schemas/WorkflowTemplatePlacement"
        updateTime:
          description: Output only. The time template was last updated.
          format: google-datetime
          type: string
        version:
          description: Optional. Used to perform a consistent read-modify-write.This field
            should be left blank for a CreateWorkflowTemplate request. It is
            required for an UpdateWorkflowTemplate request, and must match the
            current server version. A typical update template flow would fetch
            the current template with a GetWorkflowTemplate request, which will
            return the current template with the version field filled in with
            the current server version. The user updates other fields in the
            template, then returns it as part of the UpdateWorkflowTemplate
            request.
          format: int32
          type: integer
      type: object
    WorkflowTemplatePlacement:
      description: Specifies workflow execution target.Either managed_cluster or
        cluster_selector is required.
      properties:
        clusterSelector:
          $ref: "#/components/schemas/ClusterSelector"
        managedCluster:
          $ref: "#/components/schemas/ManagedCluster"
      type: object
    YarnApplication:
      description: "A YARN application created by a job. Application information is a
        subset of
        <code>org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto</c\
        ode>.Beta Feature: This report is available for testing purposes only.
        It may be changed before final release."
      properties:
        name:
          description: Required. The application name.
          type: string
        progress:
          description: Required. The numerical progress of the application, from 1 to 100.
          format: float
          type: number
        state:
          description: Required. The application state.
          enum:
            - STATE_UNSPECIFIED
            - NEW
            - NEW_SAVING
            - SUBMITTED
            - ACCEPTED
            - RUNNING
            - FINISHED
            - FAILED
            - KILLED
          type: string
        trackingUrl:
          description: Optional. The HTTP URL of the ApplicationMaster, HistoryServer, or
            TimelineServer that provides application-specific information. The
            URL uses the internal hostname, and requires a proxy server for
            resolution and, possibly, access.
          type: string
      type: object
