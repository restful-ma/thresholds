openapi: 3.0.0
info:
  contact:
    name: Google
    url: https://google.com
  description: Cloud Video Intelligence API.
  title: Cloud Video Intelligence
  version: v1beta1
  x-apiClientRegistration:
    url: https://console.developers.google.com
  x-apisguru-categories:
    - media
  x-logo:
    url: https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png
  x-origin:
    - converter:
        url: https://github.com/lucybot/api-spec-converter
        version: 2.6.2
      format: google
      url: https://videointelligence.googleapis.com/$discovery/rest?version=v1beta1
      version: v1
  x-preferred: false
  x-providerName: googleapis.com
  x-serviceName: videointelligence
externalDocs:
  url: https://cloud.google.com/video-intelligence/docs/
tags:
  - name: videos
paths:
  /v1beta1/videos:annotate:
    parameters:
      - $ref: "#/components/parameters/_.xgafv"
      - $ref: "#/components/parameters/access_token"
      - $ref: "#/components/parameters/alt"
      - $ref: "#/components/parameters/bearer_token"
      - $ref: "#/components/parameters/callback"
      - $ref: "#/components/parameters/fields"
      - $ref: "#/components/parameters/key"
      - $ref: "#/components/parameters/oauth_token"
      - $ref: "#/components/parameters/pp"
      - $ref: "#/components/parameters/prettyPrint"
      - $ref: "#/components/parameters/quotaUser"
      - $ref: "#/components/parameters/uploadType"
      - $ref: "#/components/parameters/upload_protocol"
    post:
      description: |-
        Performs asynchronous video annotation. Progress and results can be
        retrieved through the `google.longrunning.Operations` interface.
        `Operation.metadata` contains `AnnotateVideoProgress` (progress).
        `Operation.response` contains `AnnotateVideoResponse` (results).
      operationId: videointelligence.videos.annotate
      requestBody:
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_Annot\
                ateVideoRequest"
      responses:
        "200":
          description: Successful response
          content:
            "*/*":
              schema:
                $ref: "#/components/schemas/GoogleLongrunning_Operation"
      security:
        - Oauth2:
            - https://www.googleapis.com/auth/cloud-platform
      tags:
        - videos
servers:
  - url: https://videointelligence.googleapis.com/
components:
  parameters:
    access_token:
      description: OAuth access token.
      in: query
      name: access_token
      schema:
        type: string
    alt:
      description: Data format for response.
      in: query
      name: alt
      schema:
        type: string
        enum:
          - json
          - media
          - proto
        default: json
    bearer_token:
      description: OAuth bearer token.
      in: query
      name: bearer_token
      schema:
        type: string
    callback:
      description: JSONP
      in: query
      name: callback
      schema:
        type: string
    fields:
      description: Selector specifying which fields to include in a partial response.
      in: query
      name: fields
      schema:
        type: string
    key:
      description: API key. Your API key identifies your project and provides you with API
        access, quota, and reports. Required unless you provide an OAuth 2.0
        token.
      in: query
      name: key
      schema:
        type: string
    oauth_token:
      description: OAuth 2.0 token for the current user.
      in: query
      name: oauth_token
      schema:
        type: string
    pp:
      description: Pretty-print response.
      in: query
      name: pp
      schema:
        type: boolean
        default: true
    prettyPrint:
      description: Returns response with indentations and line breaks.
      in: query
      name: prettyPrint
      schema:
        type: boolean
        default: true
    quotaUser:
      description: Available to use for quota purposes for server-side applications. Can be
        any arbitrary string assigned to a user, but should not exceed 40
        characters.
      in: query
      name: quotaUser
      schema:
        type: string
    uploadType:
      description: Legacy upload protocol for media (e.g. "media", "multipart").
      in: query
      name: uploadType
      schema:
        type: string
    upload_protocol:
      description: Upload protocol for media (e.g. "raw", "multipart").
      in: query
      name: upload_protocol
      schema:
        type: string
    _.xgafv:
      description: V1 error format.
      in: query
      name: $.xgafv
      schema:
        type: string
        enum:
          - "1"
          - "2"
  securitySchemes:
    Oauth2:
      description: Oauth 2.0 authentication
      type: oauth2
      flows:
        implicit:
          authorizationUrl: https://accounts.google.com/o/oauth2/auth
          scopes:
            https://www.googleapis.com/auth/cloud-platform: View and manage your data across Google Cloud Platform services
  schemas:
    GoogleCloudVideointelligenceV1_AnnotateVideoProgress:
      description: |-
        Video annotation progress. Included in the `metadata`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationProgress:
          description: Progress metadata for all videos specified in `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_VideoAnnotat\
              ionProgress"
          type: array
      type: object
    GoogleCloudVideointelligenceV1_AnnotateVideoResponse:
      description: |-
        Video annotation response. Included in the `response`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationResults:
          description: Annotation results for all videos specified in
            `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_VideoAnnotat\
              ionResults"
          type: array
      type: object
    GoogleCloudVideointelligenceV1_Entity:
      description: Detected entity from video analysis.
      properties:
        description:
          description: Textual description, e.g. `Fixed-gear bicycle`.
          type: string
        entityId:
          description: |-
            Opaque entity ID. Some IDs may be available in
            [Google Knowledge Graph Search
            API](https://developers.google.com/knowledge-graph/).
          type: string
        languageCode:
          description: Language code for `description` in BCP-47 format.
          type: string
      type: object
    GoogleCloudVideointelligenceV1_ExplicitContentAnnotation:
      description: |-
        Explicit content annotation (based on per-frame visual signals only).
        If no explicit content has been detected in a frame, no annotations are
        present for that frame.
      properties:
        frames:
          description: All video frames where explicit content was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_ExplicitCont\
              entFrame"
          type: array
      type: object
    GoogleCloudVideointelligenceV1_ExplicitContentFrame:
      description: Video frame level annotation results for explicit content.
      properties:
        pornographyLikelihood:
          description: Likelihood of the pornography content..
          enum:
            - LIKELIHOOD_UNSPECIFIED
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1_LabelAnnotation:
      description: Label annotation.
      properties:
        categoryEntities:
          description: >-
            Common categories for the detected entity.

            E.g. when the label is `Terrier` the category is likely `dog`. And in some

            cases there might be more than one categories e.g. `Terrier` could also be

            a `pet`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_Entity"
          type: array
        entity:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_Entity"
        frames:
          description: All video frames where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_LabelFrame"
          type: array
        segments:
          description: All video segments where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_LabelSegment"
          type: array
      type: object
    GoogleCloudVideointelligenceV1_LabelFrame:
      description: Video frame level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1_LabelSegment:
      description: Video segment level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        segment:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_VideoSegment"
      type: object
    GoogleCloudVideointelligenceV1_VideoAnnotationProgress:
      description: Annotation progress for a single video.
      properties:
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        progressPercent:
          description: >-
            Output only. Approximate percentage processed thus far. Guaranteed
            to be

            100 when fully processed.
          format: int32
          type: integer
        startTime:
          description: Output only. Time when the request was received.
          format: google-datetime
          type: string
        updateTime:
          description: Output only. Time of the most recent update.
          format: google-datetime
          type: string
      type: object
    GoogleCloudVideointelligenceV1_VideoAnnotationResults:
      description: Annotation results for a single video.
      properties:
        error:
          $ref: "#/components/schemas/GoogleRpc_Status"
        explicitAnnotation:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_ExplicitConten\
            tAnnotation"
        frameLabelAnnotations:
          description: |-
            Label annotations on frame level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_LabelAnnotat\
              ion"
          type: array
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        segmentLabelAnnotations:
          description: |-
            Label annotations on video level or user specified segment level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_LabelAnnotat\
              ion"
          type: array
        shotAnnotations:
          description: Shot annotations. Each shot is represented as a video segment.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_VideoSegment"
          type: array
        shotLabelAnnotations:
          description: |-
            Label annotations on shot level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1_LabelAnnotat\
              ion"
          type: array
      type: object
    GoogleCloudVideointelligenceV1_VideoSegment:
      description: Video segment.
      properties:
        endTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the end of the segment (inclusive).
          format: google-duration
          type: string
        startTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the start of the segment (inclusive).
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta1_AnnotateVideoProgress:
      description: |-
        Video annotation progress. Included in the `metadata`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationProgress:
          description: Progress metadata for all videos specified in `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoAn\
              notationProgress"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta1_AnnotateVideoRequest:
      description: Video annotation request.
      properties:
        features:
          description: Requested video annotation features.
          items:
            enum:
              - FEATURE_UNSPECIFIED
              - LABEL_DETECTION
              - SHOT_CHANGE_DETECTION
              - SAFE_SEARCH_DETECTION
            type: string
          type: array
        inputContent:
          description: >-
            The video data bytes. Encoding: base64. If unset, the input video(s)

            should be specified via `input_uri`. If set, `input_uri` should be unset.
          type: string
        inputUri:
          description: >-
            Input video location. Currently, only

            [Google Cloud Storage](https://cloud.google.com/storage/) URIs are

            supported, which must be specified in the following format:

            `gs://bucket-id/object-id` (other URI formats return

            google.rpc.Code.INVALID_ARGUMENT). For more information, see

            [Request URIs](/storage/docs/reference-uris).

            A video URI may include wildcards in `object-id`, and thus identify

            multiple videos. Supported wildcards: '*' to match 0 or more characters;

            '?' to match 1 character. If unset, the input video should be embedded

            in the request as `input_content`. If set, `input_content` should be unset.
          type: string
        locationId:
          description: >-
            Optional cloud region where annotation should take place. Supported
            cloud

            regions: `us-east1`, `us-west1`, `europe-west1`, `asia-east1`. If no region

            is specified, a region will be determined based on video file location.
          type: string
        outputUri:
          description: >-
            Optional location where the output (in JSON format) should be
            stored.

            Currently, only [Google Cloud Storage](https://cloud.google.com/storage/)

            URIs are supported, which must be specified in the following format:

            `gs://bucket-id/object-id` (other URI formats return

            google.rpc.Code.INVALID_ARGUMENT). For more information, see

            [Request URIs](/storage/docs/reference-uris).
          type: string
        videoContext:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoCont\
            ext"
      type: object
    GoogleCloudVideointelligenceV1beta1_AnnotateVideoResponse:
      description: |-
        Video annotation response. Included in the `response`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationResults:
          description: Annotation results for all videos specified in
            `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoAn\
              notationResults"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta1_LabelAnnotation:
      description: Label annotation.
      properties:
        description:
          description: Textual description, e.g. `Fixed-gear bicycle`.
          type: string
        languageCode:
          description: Language code for `description` in BCP-47 format.
          type: string
        locations:
          description: Where the label was detected and with what confidence.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_LabelLo\
              cation"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta1_LabelLocation:
      description: Label location.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        level:
          description: Label level.
          enum:
            - LABEL_LEVEL_UNSPECIFIED
            - VIDEO_LEVEL
            - SEGMENT_LEVEL
            - SHOT_LEVEL
            - FRAME_LEVEL
          type: string
        segment:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoSegm\
            ent"
      type: object
    GoogleCloudVideointelligenceV1beta1_SafeSearchAnnotation:
      description: |-
        Safe search annotation (based on per-frame visual signals only).
        If no unsafe content has been detected in a frame, no annotations
        are present for that frame. If only some types of unsafe content
        have been detected in a frame, the likelihood is set to `UNKNOWN`
        for all other types of unsafe content.
      properties:
        adult:
          description: Likelihood of adult content.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        medical:
          description: Likelihood of medical content.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        racy:
          description: Likelihood of racy content.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        spoof:
          description: |-
            Likelihood that an obvious modification was made to the original
            version to make it appear funny or offensive.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        timeOffset:
          description: Video time offset in microseconds.
          format: int64
          type: string
        violent:
          description: Likelihood of violent content.
          enum:
            - UNKNOWN
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta1_VideoAnnotationProgress:
      description: Annotation progress for a single video.
      properties:
        inputUri:
          description: |-
            Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        progressPercent:
          description: |-
            Approximate percentage processed thus far.
            Guaranteed to be 100 when fully processed.
          format: int32
          type: integer
        startTime:
          description: Time when the request was received.
          format: google-datetime
          type: string
        updateTime:
          description: Time of the most recent update.
          format: google-datetime
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta1_VideoAnnotationResults:
      description: Annotation results for a single video.
      properties:
        error:
          $ref: "#/components/schemas/GoogleRpc_Status"
        inputUri:
          description: |-
            Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        labelAnnotations:
          description: Label annotations. There is exactly one element for each unique
            label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_LabelAn\
              notation"
          type: array
        safeSearchAnnotations:
          description: Safe search annotations.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_SafeSea\
              rchAnnotation"
          type: array
        shotAnnotations:
          description: Shot annotations. Each shot is represented as a video segment.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoSe\
              gment"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta1_VideoContext:
      description: Video context and/or feature-specific parameters.
      properties:
        labelDetectionMode:
          description: >-
            If label detection has been requested, what labels should be
            detected

            in addition to video-level labels or segment-level labels. If unspecified,

            defaults to `SHOT_MODE`.
          enum:
            - LABEL_DETECTION_MODE_UNSPECIFIED
            - SHOT_MODE
            - FRAME_MODE
            - SHOT_AND_FRAME_MODE
          type: string
        labelDetectionModel:
          description: |-
            Model to use for label detection.
            Supported values: "latest" and "stable" (the default).
          type: string
        safeSearchDetectionModel:
          description: |-
            Model to use for safe search detection.
            Supported values: "latest" and "stable" (the default).
          type: string
        segments:
          description: >-
            Video segments to annotate. The segments may overlap and are not
            required

            to be contiguous or span the whole video. If unspecified, each video

            is treated as a single segment.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta1_VideoSe\
              gment"
          type: array
        shotChangeDetectionModel:
          description: |-
            Model to use for shot change detection.
            Supported values: "latest" and "stable" (the default).
          type: string
        stationaryCamera:
          description: >-
            Whether the video has been shot from a stationary (i.e. non-moving)
            camera.

            When set to true, might improve detection accuracy for moving objects.
          type: boolean
      type: object
    GoogleCloudVideointelligenceV1beta1_VideoSegment:
      description: Video segment.
      properties:
        endTimeOffset:
          description: End offset in microseconds (inclusive). Unset means 0.
          format: int64
          type: string
        startTimeOffset:
          description: Start offset in microseconds (inclusive). Unset means 0.
          format: int64
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta2_AnnotateVideoProgress:
      description: |-
        Video annotation progress. Included in the `metadata`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationProgress:
          description: Progress metadata for all videos specified in `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_VideoAn\
              notationProgress"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta2_AnnotateVideoResponse:
      description: |-
        Video annotation response. Included in the `response`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationResults:
          description: Annotation results for all videos specified in
            `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_VideoAn\
              notationResults"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta2_Entity:
      description: Detected entity from video analysis.
      properties:
        description:
          description: Textual description, e.g. `Fixed-gear bicycle`.
          type: string
        entityId:
          description: |-
            Opaque entity ID. Some IDs may be available in
            [Google Knowledge Graph Search
            API](https://developers.google.com/knowledge-graph/).
          type: string
        languageCode:
          description: Language code for `description` in BCP-47 format.
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta2_ExplicitContentAnnotation:
      description: |-
        Explicit content annotation (based on per-frame visual signals only).
        If no explicit content has been detected in a frame, no annotations are
        present for that frame.
      properties:
        frames:
          description: All video frames where explicit content was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_Explici\
              tContentFrame"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta2_ExplicitContentFrame:
      description: Video frame level annotation results for explicit content.
      properties:
        pornographyLikelihood:
          description: Likelihood of the pornography content..
          enum:
            - LIKELIHOOD_UNSPECIFIED
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta2_LabelAnnotation:
      description: Label annotation.
      properties:
        categoryEntities:
          description: >-
            Common categories for the detected entity.

            E.g. when the label is `Terrier` the category is likely `dog`. And in some

            cases there might be more than one categories e.g. `Terrier` could also be

            a `pet`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_Entity"
          type: array
        entity:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_Entity"
        frames:
          description: All video frames where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_LabelFr\
              ame"
          type: array
        segments:
          description: All video segments where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_LabelSe\
              gment"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta2_LabelFrame:
      description: Video frame level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta2_LabelSegment:
      description: Video segment level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        segment:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_VideoSegm\
            ent"
      type: object
    GoogleCloudVideointelligenceV1beta2_VideoAnnotationProgress:
      description: Annotation progress for a single video.
      properties:
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        progressPercent:
          description: >-
            Output only. Approximate percentage processed thus far. Guaranteed
            to be

            100 when fully processed.
          format: int32
          type: integer
        startTime:
          description: Output only. Time when the request was received.
          format: google-datetime
          type: string
        updateTime:
          description: Output only. Time of the most recent update.
          format: google-datetime
          type: string
      type: object
    GoogleCloudVideointelligenceV1beta2_VideoAnnotationResults:
      description: Annotation results for a single video.
      properties:
        error:
          $ref: "#/components/schemas/GoogleRpc_Status"
        explicitAnnotation:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_ExplicitC\
            ontentAnnotation"
        frameLabelAnnotations:
          description: |-
            Label annotations on frame level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_LabelAn\
              notation"
          type: array
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        segmentLabelAnnotations:
          description: |-
            Label annotations on video level or user specified segment level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_LabelAn\
              notation"
          type: array
        shotAnnotations:
          description: Shot annotations. Each shot is represented as a video segment.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_VideoSe\
              gment"
          type: array
        shotLabelAnnotations:
          description: |-
            Label annotations on shot level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1beta2_LabelAn\
              notation"
          type: array
      type: object
    GoogleCloudVideointelligenceV1beta2_VideoSegment:
      description: Video segment.
      properties:
        endTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the end of the segment (inclusive).
          format: google-duration
          type: string
        startTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the start of the segment (inclusive).
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_AnnotateVideoProgress:
      description: |-
        Video annotation progress. Included in the `metadata`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationProgress:
          description: Progress metadata for all videos specified in `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Video\
              AnnotationProgress"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_AnnotateVideoResponse:
      description: |-
        Video annotation response. Included in the `response`
        field of the `Operation` returned by the `GetOperation`
        call of the `google::longrunning::Operations` service.
      properties:
        annotationResults:
          description: Annotation results for all videos specified in
            `AnnotateVideoRequest`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Video\
              AnnotationResults"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_EmotionAttribute:
      description: Emotion attribute.
      properties:
        emotion:
          description: Emotion entry.
          enum:
            - EMOTION_UNSPECIFIED
            - AMUSEMENT
            - ANGER
            - CONCENTRATION
            - CONTENTMENT
            - DESIRE
            - DISAPPOINTMENT
            - DISGUST
            - ELATION
            - EMBARRASSMENT
            - INTEREST
            - PRIDE
            - SADNESS
            - SURPRISE
          type: string
        score:
          description: Confidence score.
          format: float
          type: number
      type: object
    GoogleCloudVideointelligenceV1p1beta1_Entity:
      description: Detected entity from video analysis.
      properties:
        description:
          description: Textual description, e.g. `Fixed-gear bicycle`.
          type: string
        entityId:
          description: |-
            Opaque entity ID. Some IDs may be available in
            [Google Knowledge Graph Search
            API](https://developers.google.com/knowledge-graph/).
          type: string
        languageCode:
          description: Language code for `description` in BCP-47 format.
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_ExplicitContentAnnotation:
      description: |-
        Explicit content annotation (based on per-frame visual signals only).
        If no explicit content has been detected in a frame, no annotations are
        present for that frame.
      properties:
        frames:
          description: All video frames where explicit content was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Expli\
              citContentFrame"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_ExplicitContentFrame:
      description: Video frame level annotation results for explicit content.
      properties:
        pornographyLikelihood:
          description: Likelihood of the pornography content..
          enum:
            - LIKELIHOOD_UNSPECIFIED
            - VERY_UNLIKELY
            - UNLIKELY
            - POSSIBLE
            - LIKELY
            - VERY_LIKELY
          type: string
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_FaceDetectionAnnotation:
      description: Face detection annotation.
      properties:
        frames:
          description: All video frames where a face was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_FaceD\
              etectionFrame"
          type: array
        segments:
          description: All video segments where a face was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_FaceS\
              egment"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_FaceDetectionAttribute:
      description: Face detection attribute.
      properties:
        emotions:
          description: Emotion attributes.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Emoti\
              onAttribute"
          type: array
        normalizedBoundingBox:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Normali\
            zedBoundingBox"
      type: object
    GoogleCloudVideointelligenceV1p1beta1_FaceDetectionFrame:
      description: Video frame level annotation results for face detection.
      properties:
        attributes:
          description: >-
            Face attributes in a frame.

            There can be more than one attributes if the same face is detected in

            multiple locations within the current frame.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_FaceD\
              etectionAttribute"
          type: array
        timeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_FaceSegment:
      description: Video segment level annotation results for face detection.
      properties:
        segment:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_VideoSe\
            gment"
      type: object
    GoogleCloudVideointelligenceV1p1beta1_LabelAnnotation:
      description: Label annotation.
      properties:
        categoryEntities:
          description: >-
            Common categories for the detected entity.

            E.g. when the label is `Terrier` the category is likely `dog`. And in some

            cases there might be more than one categories e.g. `Terrier` could also be

            a `pet`.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Entity"
          type: array
        entity:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Entity"
        frames:
          description: All video frames where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Label\
              Frame"
          type: array
        segments:
          description: All video segments where a label was detected.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Label\
              Segment"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_LabelFrame:
      description: Video frame level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        timeOffset:
          description: >-
            Time-offset, relative to the beginning of the video, corresponding
            to the

            video frame for this location.
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_LabelSegment:
      description: Video segment level annotation results for label detection.
      properties:
        confidence:
          description: "Confidence that the label is accurate. Range: [0, 1]."
          format: float
          type: number
        segment:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_VideoSe\
            gment"
      type: object
    GoogleCloudVideointelligenceV1p1beta1_NormalizedBoundingBox:
      description: |-
        Normalized bounding box.
        The normalized vertex coordinates are relative to the original image.
        Range: [0, 1].
      properties:
        bottom:
          description: Bottom Y coordinate.
          format: float
          type: number
        left:
          description: Left X coordinate.
          format: float
          type: number
        right:
          description: Right X coordinate.
          format: float
          type: number
        top:
          description: Top Y coordinate.
          format: float
          type: number
      type: object
    GoogleCloudVideointelligenceV1p1beta1_SpeechRecognitionAlternative:
      description: Alternative hypotheses (a.k.a. n-best list).
      properties:
        confidence:
          description: >-
            Output only. The confidence estimate between 0.0 and 1.0. A higher
            number

            indicates an estimated greater likelihood that the recognized words are

            correct. This field is typically provided only for the top hypothesis, and

            only for `is_final=true` results. Clients should not rely on the

            `confidence` field as it is not guaranteed to be accurate or consistent.

            The default of 0.0 is a sentinel value indicating `confidence` was not set.
          format: float
          type: number
        transcript:
          description: Output only. Transcript text representing the words that the user
            spoke.
          type: string
        words:
          description: Output only. A list of word-specific information for each recognized
            word.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_WordI\
              nfo"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_SpeechTranscription:
      description: A speech recognition result corresponding to a portion of the audio.
      properties:
        alternatives:
          description: >-
            Output only. May contain one or more recognition hypotheses (up to
            the

            maximum specified in `max_alternatives`).

            These alternatives are ordered in terms of accuracy, with the top (first)

            alternative being the most probable, as ranked by the recognizer.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Speec\
              hRecognitionAlternative"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_VideoAnnotationProgress:
      description: Annotation progress for a single video.
      properties:
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        progressPercent:
          description: >-
            Output only. Approximate percentage processed thus far. Guaranteed
            to be

            100 when fully processed.
          format: int32
          type: integer
        startTime:
          description: Output only. Time when the request was received.
          format: google-datetime
          type: string
        updateTime:
          description: Output only. Time of the most recent update.
          format: google-datetime
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_VideoAnnotationResults:
      description: Annotation results for a single video.
      properties:
        error:
          $ref: "#/components/schemas/GoogleRpc_Status"
        explicitAnnotation:
          $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Explici\
            tContentAnnotation"
        faceDetectionAnnotations:
          description: Face detection annotations.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_FaceD\
              etectionAnnotation"
          type: array
        frameLabelAnnotations:
          description: |-
            Label annotations on frame level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Label\
              Annotation"
          type: array
        inputUri:
          description: |-
            Output only. Video file location in
            [Google Cloud Storage](https://cloud.google.com/storage/).
          type: string
        segmentLabelAnnotations:
          description: |-
            Label annotations on video level or user specified segment level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Label\
              Annotation"
          type: array
        shotAnnotations:
          description: Shot annotations. Each shot is represented as a video segment.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Video\
              Segment"
          type: array
        shotLabelAnnotations:
          description: |-
            Label annotations on shot level.
            There is exactly one element for each unique label.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Label\
              Annotation"
          type: array
        speechTranscriptions:
          description: Speech transcription.
          items:
            $ref: "#/components/schemas/GoogleCloudVideointelligenceV1p1beta1_Speec\
              hTranscription"
          type: array
      type: object
    GoogleCloudVideointelligenceV1p1beta1_VideoSegment:
      description: Video segment.
      properties:
        endTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the end of the segment (inclusive).
          format: google-duration
          type: string
        startTimeOffset:
          description: |-
            Time-offset, relative to the beginning of the video,
            corresponding to the start of the segment (inclusive).
          format: google-duration
          type: string
      type: object
    GoogleCloudVideointelligenceV1p1beta1_WordInfo:
      description: |-
        Word-specific information for recognized words. Word information is only
        included in the response when certain request parameters are set, such
        as `enable_word_time_offsets`.
      properties:
        endTime:
          description: >-
            Output only. Time offset relative to the beginning of the audio, and

            corresponding to the end of the spoken word. This field is only set if

            `enable_word_time_offsets=true` and only in the top hypothesis. This is an

            experimental feature and the accuracy of the time offset can vary.
          format: google-duration
          type: string
        startTime:
          description: >-
            Output only. Time offset relative to the beginning of the audio, and

            corresponding to the start of the spoken word. This field is only set if

            `enable_word_time_offsets=true` and only in the top hypothesis. This is an

            experimental feature and the accuracy of the time offset can vary.
          format: google-duration
          type: string
        word:
          description: Output only. The word corresponding to this set of information.
          type: string
      type: object
    GoogleLongrunning_Operation:
      description: >-
        This resource represents a long-running operation that is the result of
        a

        network API call.
      properties:
        done:
          description: >-
            If the value is `false`, it means the operation is still in
            progress.

            If `true`, the operation is completed, and either `error` or `response` is

            available.
          type: boolean
        error:
          $ref: "#/components/schemas/GoogleRpc_Status"
        metadata:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: >-
            Service-specific metadata associated with the operation.  It
            typically

            contains progress information and common metadata such as create time.

            Some services might not provide such metadata.  Any method that returns a

            long-running operation should document the metadata type, if any.
          type: object
        name:
          description: >-
            The server-assigned name, which is only unique within the same
            service that

            originally returns it. If you use the default HTTP mapping, the

            `name` should have the format of `operations/some/unique/name`.
          type: string
        response:
          additionalProperties:
            description: Properties of the object. Contains field @type with type URL.
          description: >-
            The normal response of the operation in case of success.  If the
            original

            method returns no data on success, such as `Delete`, the response is

            `google.protobuf.Empty`.  If the original method is standard

            `Get`/`Create`/`Update`, the response should be the resource.  For other

            methods, the response should have the type `XxxResponse`, where `Xxx`

            is the original method name.  For example, if the original method name

            is `TakeSnapshot()`, the inferred response type is

            `TakeSnapshotResponse`.
          type: object
      type: object
    GoogleRpc_Status:
      description: >-
        The `Status` type defines a logical error model that is suitable for
        different

        programming environments, including REST APIs and RPC APIs. It is used by

        [gRPC](https://github.com/grpc). The error model is designed to be:


        - Simple to use and understand for most users

        - Flexible enough to meet unexpected needs


        # Overview


        The `Status` message contains three pieces of data: error code, error message,

        and error details. The error code should be an enum value of

        google.rpc.Code, but it may accept additional error codes if needed.  The

        error message should be a developer-facing English message that helps

        developers *understand* and *resolve* the error. If a localized user-facing

        error message is needed, put the localized message in the error details or

        localize it in the client. The optional error details may contain arbitrary

        information about the error. There is a predefined set of error detail types

        in the package `google.rpc` that can be used for common error conditions.


        # Language mapping


        The `Status` message is the logical representation of the error model, but it

        is not necessarily the actual wire format. When the `Status` message is

        exposed in different client libraries and different wire protocols, it can be

        mapped differently. For example, it will likely be mapped to some exceptions

        in Java, but more likely mapped to some error codes in C.


        # Other uses


        The error model and the `Status` message can be used in a variety of

        environments, either with or without APIs, to provide a

        consistent developer experience across different environments.


        Example uses of this error model include:


        - Partial errors. If a service needs to return partial errors to the client,
            it may embed the `Status` in the normal response to indicate the partial
            errors.

        - Workflow errors. A typical workflow has multiple steps. Each step may
            have a `Status` message for error reporting.

        - Batch operations. If a client uses batch request and batch response, the
            `Status` message should be used directly inside batch response, one for
            each error sub-response.

        - Asynchronous operations. If an API call embeds asynchronous operation
            results in its response, the status of those operations should be
            represented directly using the `Status` message.

        - Logging. If some API errors are stored in logs, the message `Status` could
            be used directly after any stripping needed for security/privacy reasons.
      properties:
        code:
          description: The status code, which should be an enum value of google.rpc.Code.
          format: int32
          type: integer
        details:
          description: >-
            A list of messages that carry the error details.  There is a common
            set of

            message types for APIs to use.
          items:
            additionalProperties:
              description: Properties of the object. Contains field @type with type URL.
            type: object
          type: array
        message:
          description: |-
            A developer-facing error message, which should be in English. Any
            user-facing error message should be localized and sent in the
            google.rpc.Status.details field, or localized by the client.
          type: string
      type: object
